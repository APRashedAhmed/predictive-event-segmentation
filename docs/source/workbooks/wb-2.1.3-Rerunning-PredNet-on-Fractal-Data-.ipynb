{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.3 Rerunning PredNet on Fractal Data\n",
    "\n",
    "The last results were only run for 25 epochs, so lets see if we get the expected behavior at 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 07 2020 21:32:54 \n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-112-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "host name  : serrep5\n",
      "Git hash   : 63debd6c1aae64186354ca82868f3dad80b7e525\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and other non-code related info\n",
    "%watermark -n -m -g -b -t -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prevseg           0+untagged.87.g63debd6.dirty\n",
      "PIL.Image         7.2.0\n",
      "numpy             1.19.1\n",
      "logging           0.5.1.2\n",
      "torch             1.4.0\n",
      "networkx          2.4\n",
      "pytorch_lightning 0.8.5\n",
      "CPython 3.8.5\n",
      "IPython 7.16.1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "%aimport prevseg.constants\n",
    "import prevseg.constants as const\n",
    "%aimport prevseg.index\n",
    "import prevseg.index as index\n",
    "%aimport prevseg.dataloaders.schapiro\n",
    "import prevseg.dataloaders.schapiro as sch\n",
    "%aimport prevseg.schapiro\n",
    "from prevseg.schapiro import walk, graph\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as pn\n",
    "\n",
    "# Keep track of versions of everything\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = const.DEFAULT_HPARAMS\n",
    "\n",
    "ModelClass = pn.PredNetTrackedSchapiro\n",
    "hparams.n_layers = 2\n",
    "hparams.batch_size = 256 + 128\n",
    "hparams.max_steps = 128\n",
    "hparams.n_paths = 16\n",
    "hparams.n_pentagons = 3\n",
    "hparams.time_steps = hparams.max_steps\n",
    "hparams.exp_name = 'schapiro_test'\n",
    "hparams.name = f'{ModelClass.name}_{hparams.exp_name}'\n",
    "hparams.debug = False\n",
    "hparams.n_workers = 1\n",
    "hparams.lr = 0.001\n",
    "hparams.n_epochs = 200\n",
    "hparams.seed = 1\n",
    "hparams.layer_loss_mode = 'first'\n",
    "\n",
    "train_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    model, trainer = None, None\n",
    "    train_dataloader, val_dataloader = None, None\n",
    "    errors, optimizer = None, None\n",
    "    ckpt = None\n",
    "    train_errors, val_errors = None, None\n",
    "    res = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "    if not log_dir.exists():\n",
    "        log_dir.mkdir(parents=True)\n",
    "    logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "    ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "    if not ckpt_dir.exists():\n",
    "        ckpt_dir.mkdir(parents=True)\n",
    "\n",
    "    ckpt = pl.callbacks.ModelCheckpoint(\n",
    "        filepath=str(ckpt_dir / (hparams.exp_name+'_{global_step:05d}_{epoch:03d}_{val_loss:.3f}')),\n",
    "        verbose=True,\n",
    "        save_top_k=1,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(checkpoint_callback=ckpt,\n",
    "                         max_epochs=hparams.n_epochs,\n",
    "                         logger=logger,\n",
    "                         gpus=1\n",
    "                         )\n",
    "\n",
    "    model = ModelClass(hparams)\n",
    "    model.ds = None\n",
    "    model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 384,\n",
      " 'debug': False,\n",
      " 'device': 'cuda',\n",
      " 'dir_checkpoints': '/home/abdullah/work/predictive-event-segmentation/models/checkpoints',\n",
      " 'dir_logs': '/home/abdullah/work/predictive-event-segmentation/logs/tensorboard',\n",
      " 'dir_weights': '/home/abdullah/work/predictive-event-segmentation/models/weights',\n",
      " 'exp_name': 'schapiro_test',\n",
      " 'input_size': 2048,\n",
      " 'layer_loss_mode': 'first',\n",
      " 'lr': 0.001,\n",
      " 'max_steps': 128,\n",
      " 'model_name': 'prednet',\n",
      " 'n_epochs': 200,\n",
      " 'n_layers': 2,\n",
      " 'n_paths': 16,\n",
      " 'n_pentagons': 3,\n",
      " 'n_test': 16,\n",
      " 'n_val': 256,\n",
      " 'n_workers': 1,\n",
      " 'name': 'prednet_tracked_schapiro_schapiro_test',\n",
      " 'output_mode': 'error',\n",
      " 'seed': 1,\n",
      " 'time_steps': 128}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(hparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                         | Type       | Params\n",
      "------------------------------------------------------------\n",
      "0 | predcell_tracked_0_recurrent | LSTM       | 67 M  \n",
      "1 | predcell_tracked_0_dense     | Sequential | 4 M   \n",
      "2 | predcell_tracked_0_update_a  | Sequential | 4 M   \n",
      "3 | predcell_tracked_1_recurrent | LSTM       | 12 M  \n",
      "4 | predcell_tracked_1_dense     | Sequential | 1 M   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '26', 1: '44', 2: '97', 3: '13', 4: '87', 5: '9', 6: '68', 7: '4', 8: '28', 9: '1', 10: '51', 11: '24', 12: '38', 13: '42', 14: '59'}\n",
      "Created mapping as follows:\n",
      "{0: '26', 1: '44', 2: '97', 3: '13', 4: '87', 5: '9', 6: '68', 7: '4', 8: '28', 9: '1', 10: '51', 11: '24', 12: '38', 13: '42', 14: '59'}\n",
      "Validation sanity check: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/abdullah/envs/sch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 0it [00:00, ?it/s]                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/abdullah/envs/sch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 16it [01:11,  4.46s/it, loss=0.176, v_num=5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: : 17it [01:12,  4.25s/it, loss=0.176, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00000: val_loss reached 0.15429 (best 0.15429), saving model to /home/abdullah/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_schapiro_test_v5/schapiro_test_global_step=00015_epoch=000_val_loss=0.154.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 17it [01:14,  4.36s/it, loss=0.176, v_num=5]\n",
      "Epoch 2: : 16it [01:11,  4.50s/it, loss=0.153, v_num=5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: : 17it [01:12,  4.28s/it, loss=0.153, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss reached 0.14991 (best 0.14991), saving model to /home/abdullah/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_schapiro_test_v5/schapiro_test_global_step=00031_epoch=001_val_loss=0.150.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 17it [01:14,  4.41s/it, loss=0.153, v_num=5]\n",
      "Epoch 3: : 16it [01:12,  4.55s/it, loss=0.149, v_num=5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: : 17it [01:13,  4.33s/it, loss=0.149, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss reached 0.14645 (best 0.14645), saving model to /home/abdullah/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_schapiro_test_v5/schapiro_test_global_step=00047_epoch=002_val_loss=0.146.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: : 17it [01:15,  4.46s/it, loss=0.149, v_num=5]\n",
      "Epoch 4: : 16it [01:12,  4.55s/it, loss=0.146, v_num=5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: : 17it [01:13,  4.33s/it, loss=0.146, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss reached 0.14500 (best 0.14500), saving model to /home/abdullah/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_schapiro_test_v5/schapiro_test_global_step=00063_epoch=003_val_loss=0.145.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: : 17it [01:15,  4.45s/it, loss=0.146, v_num=5]\n",
      "Epoch 5: : 4it [00:19,  4.94s/it, loss=0.146, v_num=5] "
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    trainer.fit(model)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_model:\n",
    "    # Get all the experiments with the name hparams.name*\n",
    "    experiments = index.DIR_CHECKPOINTS.glob(f'{hparams.name}*')\n",
    "    # Get the newest exp by v number\n",
    "    experiment_newest = sorted(experiments, \n",
    "                               key=lambda path: int(path.stem.split('_')[-1][1:]))[-1]\n",
    "    # Get the model with the best (lowest) val_loss\n",
    "    experiment_newest_best_val = sorted(experiment_newest.iterdir(),\n",
    "                                        key=lambda path: float(path.stem.split('val_loss=')[-1]))[0]\n",
    "    experiment_newest_best_val\n",
    "    \n",
    "    model, trainer = None, None\n",
    "    train_dataloader, val_dataloader = None, None\n",
    "    errors, optimizer = None, None\n",
    "    ckpt = None\n",
    "    train_errors, val_errors = None, None\n",
    "    res = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = LSTMStacked.load_from_checkpoint(str(experiment_newest_best_val))\n",
    "    model.prepare_data()\n",
    "    model.cuda()\n",
    "    hparams = model.hparams\n",
    "\n",
    "    log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "    if not log_dir.exists():\n",
    "        log_dir.mkdir(parents=True)\n",
    "    logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), \n",
    "                                          name=hparams.name,\n",
    "                                          version=0)\n",
    "    model.logger = logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ds = sch.ShapiroResnetEmbeddingDataset(\n",
    "    batch_size=1, \n",
    "    max_steps=hparams.max_steps, \n",
    "    n_paths=1,\n",
    "    mapping=model.ds.mapping,\n",
    "    mode='euclidean')\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "\n",
    "for data, nodes in loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = torch.cat((data, torch.flip(data, (0,1))[:,1:,:]), 1)\n",
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model.forward(data_all, output_mode='eval', run_num='fwd_rev', \n",
    "                     tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.array(nodes).reshape(30)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_all = np.concatenate((nodes, np.flip(nodes)[1:]))\n",
    "nodes_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(nodes_all):\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph.schapiro_graph(n_pentagons=3)\n",
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = [9, 19, 29, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden State Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs['hidden_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(outs['hidden_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(59)[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs['hidden_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs['representation_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(outs['representation_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(59)[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs['representation_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Within vs Between Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nodes = [6,8,9,\n",
    "              10,9,10,\n",
    "              13,12,14,\n",
    "              0,14,0,\n",
    "              1,2,4,\n",
    "              5,4,5]\n",
    "test_data = np.array([iter_ds.array_data[n] \n",
    "                      for n in test_nodes]).reshape((1,len(test_nodes),2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_outs = model.forward(torch.Tensor(test_data), \n",
    "                            output_mode='eval', \n",
    "                            run_num='border_walk_3', \n",
    "                            tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(border_outs['hidden_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(border_outs['hidden_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(len(test_nodes))[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    if i == len(border_outs['hidden_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
