{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.0 Running the CoxLab PredNet\n",
    "\n",
    "The original PredNet wasn't straight forward to  get working. See [note-1.0](https://github.com/apra93/predictive-event-segmentation/blob/master/docs/source/notes/note-1.0-Running-the-CoxLab-PredNet.md) for details on getting their scripts running. This WB is for meesing with those scripts' innards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 27 2020 15:12:55 \n",
      "\n",
      "compiler   : GCC 7.5.0\n",
      "system     : Linux\n",
      "release    : 5.4.0-42-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : apra-x3\n",
      "Git hash   : 4a276e8b21f39b812271fa7087ff1bd6d130e11d\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and other non-code related info\n",
    "%watermark -n -m -g -b -t -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conda Env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/apra/miniconda3/envs/prednet:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
      "_openmp_mutex             4.5                       1_gnu    conda-forge\n",
      "_tflow_select             2.1.0                       gpu    anaconda\n",
      "absl-py                   0.9.0            py37hc8dfbb8_1    conda-forge\n",
      "argon2-cffi               20.1.0                   pypi_0    pypi\n",
      "astor                     0.8.1              pyh9f0ad1d_0    conda-forge\n",
      "async-generator           1.10                     pypi_0    pypi\n",
      "attrs                     20.1.0             pyh9f0ad1d_0    conda-forge\n",
      "babel                     2.8.0                    pypi_0    pypi\n",
      "backcall                  0.2.0                    pypi_0    pypi\n",
      "beautifulsoup4            4.9.1                      py_1    conda-forge\n",
      "bleach                    3.1.5                    pypi_0    pypi\n",
      "brotlipy                  0.7.0           py37h8f50634_1000    conda-forge\n",
      "c-ares                    1.16.1               h516909a_2    conda-forge\n",
      "ca-certificates           2020.6.20            hecda079_0    conda-forge\n",
      "certifi                   2020.6.20        py37hc8dfbb8_0    conda-forge\n",
      "cffi                      1.14.1           py37h2b28604_0    conda-forge\n",
      "chardet                   3.0.4           py37hc8dfbb8_1006    conda-forge\n",
      "codecov                   2.1.9              pyh9f0ad1d_0    conda-forge\n",
      "coloredlogs               14.0             py37hc8dfbb8_1    conda-forge\n",
      "coverage                  5.2.1            py37h8f50634_0    conda-forge\n",
      "cryptography              3.0              py37hb09aad4_0    conda-forge\n",
      "cudatoolkit               10.0.130                      0    anaconda\n",
      "cudnn                     7.6.5                cuda10.0_0    anaconda\n",
      "cupti                     10.0.130                      0    anaconda\n",
      "cycler                    0.10.0                     py_2    conda-forge\n",
      "decorator                 4.4.2                    pypi_0    pypi\n",
      "defusedxml                0.7.0rc1                 pypi_0    pypi\n",
      "dill                      0.3.2                    pypi_0    pypi\n",
      "entrypoints               0.3                      pypi_0    pypi\n",
      "ffmpeg-python             0.2.0                    pypi_0    pypi\n",
      "flake8                    3.8.3                      py_1    conda-forge\n",
      "freetype                  2.10.2               he06d7ca_0    conda-forge\n",
      "future                    0.18.2                   pypi_0    pypi\n",
      "gast                      0.2.2                      py_0    conda-forge\n",
      "google-pasta              0.2.0              pyh8c360ce_0    conda-forge\n",
      "grpcio                    1.31.0           py37hb0870dc_0    conda-forge\n",
      "h5py                      2.10.0          nompi_py37h90cd8ad_104    conda-forge\n",
      "hdf5                      1.10.6          nompi_h3c11f04_101    conda-forge\n",
      "hickle                    2.1.0                    pypi_0    pypi\n",
      "humanfriendly             8.2              py37hc8dfbb8_0    conda-forge\n",
      "idna                      2.10               pyh9f0ad1d_0    conda-forge\n",
      "imageio                   2.9.0                      py_0    conda-forge\n",
      "imageio-ffmpeg            0.4.2                    pypi_0    pypi\n",
      "importlib-metadata        1.7.0            py37hc8dfbb8_0    conda-forge\n",
      "importlib_metadata        1.7.0                         0    conda-forge\n",
      "iniconfig                 1.0.1              pyh9f0ad1d_0    conda-forge\n",
      "ipykernel                 5.3.4                    pypi_0    pypi\n",
      "ipython                   7.17.0                   pypi_0    pypi\n",
      "ipython-genutils          0.2.0                    pypi_0    pypi\n",
      "ipython_genutils          0.2.0                    py37_0    defaults\n",
      "jedi                      0.17.2                   pypi_0    pypi\n",
      "jinja2                    3.0.0a1                  pypi_0    pypi\n",
      "jpeg                      9d                   h516909a_0    conda-forge\n",
      "json5                     0.9.5                    pypi_0    pypi\n",
      "jsonschema                3.2.0                    pypi_0    pypi\n",
      "jupyter-client            6.1.6                    pypi_0    pypi\n",
      "jupyter-core              4.6.3                    pypi_0    pypi\n",
      "jupyter-server            1.0.0rc7                 pypi_0    pypi\n",
      "jupyter_client            6.1.6                      py_0    defaults\n",
      "jupyter_core              4.6.3                    py37_0    defaults\n",
      "jupyterlab                3.0.0a14                 pypi_0    pypi\n",
      "jupyterlab-pygments       0.1.1                    pypi_0    pypi\n",
      "jupyterlab-server         2.0.0b2                  pypi_0    pypi\n",
      "jupyterlab_server         1.2.0                      py_0    defaults\n",
      "keras                     2.3.1                    py37_0    conda-forge\n",
      "keras-applications        1.0.8                      py_1    conda-forge\n",
      "keras-preprocessing       1.1.0                      py_0    conda-forge\n",
      "kiwisolver                1.2.0            py37h99015e2_0    conda-forge\n",
      "lcms2                     2.11                 hbd6801e_0    conda-forge\n",
      "ld_impl_linux-64          2.34                 hc38a660_9    conda-forge\n",
      "libblas                   3.8.0               17_openblas    conda-forge\n",
      "libcblas                  3.8.0               17_openblas    conda-forge\n",
      "libffi                    3.2.1             he1b5a44_1007    conda-forge\n",
      "libgcc-ng                 9.3.0               h24d8f2e_16    conda-forge\n",
      "libgfortran-ng            7.5.0               hdf63c60_16    conda-forge\n",
      "libgomp                   9.3.0               h24d8f2e_16    conda-forge\n",
      "libgpuarray               0.7.6             h14c3975_1003    conda-forge\n",
      "liblapack                 3.8.0               17_openblas    conda-forge\n",
      "libopenblas               0.3.10          pthreads_hb3c22a3_4    conda-forge\n",
      "libpng                    1.6.37               hed695b0_2    conda-forge\n",
      "libprotobuf               3.13.0               h8b12597_0    conda-forge\n",
      "libsodium                 1.0.18               h7b6447c_0    defaults\n",
      "libstdcxx-ng              9.3.0               hdf63c60_16    conda-forge\n",
      "libtiff                   4.1.0                hc7e4089_6    conda-forge\n",
      "libwebp-base              1.1.0                h516909a_3    conda-forge\n",
      "lz4-c                     1.9.2                he1b5a44_3    conda-forge\n",
      "mako                      1.1.3              pyh9f0ad1d_0    conda-forge\n",
      "markdown                  3.2.2                      py_0    conda-forge\n",
      "markupsafe                1.1.1            py37h8f50634_1    conda-forge\n",
      "matplotlib                3.3.1                         1    conda-forge\n",
      "matplotlib-base           3.3.1            py37hd478181_1    conda-forge\n",
      "mccabe                    0.6.1                      py_1    conda-forge\n",
      "mistune                   0.8.4                    pypi_0    pypi\n",
      "more-itertools            8.4.0                      py_0    conda-forge\n",
      "nbclassic                 0.2.0rc4                 pypi_0    pypi\n",
      "nbclient                  0.4.1                    pypi_0    pypi\n",
      "nbconvert                 6.0.0b7                  pypi_0    pypi\n",
      "nbformat                  5.0.7                    pypi_0    pypi\n",
      "ncurses                   6.2                  he1b5a44_1    conda-forge\n",
      "nest-asyncio              1.4.0                    pypi_0    pypi\n",
      "notebook                  6.1.3                    pypi_0    pypi\n",
      "numpy                     1.19.1           py37h7ea13bd_2    conda-forge\n",
      "olefile                   0.46                       py_0    conda-forge\n",
      "openssl                   1.1.1g               h516909a_1    conda-forge\n",
      "opt-einsum                3.3.0                    pypi_0    pypi\n",
      "opt_einsum                3.3.0                      py_0    conda-forge\n",
      "packaging                 20.4               pyh9f0ad1d_0    conda-forge\n",
      "pandoc                    2.10.1                        0    defaults\n",
      "pandocfilters             1.4.2                    py37_1    defaults\n",
      "parso                     0.7.1                    pypi_0    pypi\n",
      "pexpect                   4.8.0                    pypi_0    pypi\n",
      "pickleshare               0.7.5                    pypi_0    pypi\n",
      "pillow                    7.2.0            py37h718be6c_1    conda-forge\n",
      "pip                       20.2.2                     py_0    conda-forge\n",
      "pluggy                    0.13.1           py37hc8dfbb8_2    conda-forge\n",
      "predictive-event-segmentation 0+untagged.51.gcb26ef6.dirty           dev_0    <develop>\n",
      "prednet                   0+untagged.69.g843b452.dirty           dev_0    <develop>\n",
      "prometheus-client         0.8.0                    pypi_0    pypi\n",
      "prometheus_client         0.8.0                      py_0    defaults\n",
      "prompt-toolkit            3.0.6                    pypi_0    pypi\n",
      "protobuf                  3.13.0           py37h3340039_0    conda-forge\n",
      "ptyprocess                0.6.0                    pypi_0    pypi\n",
      "py                        1.9.0              pyh9f0ad1d_0    conda-forge\n",
      "pycodestyle               2.6.0              pyh9f0ad1d_0    conda-forge\n",
      "pycparser                 2.20               pyh9f0ad1d_2    conda-forge\n",
      "pyflakes                  2.2.0              pyh9f0ad1d_0    conda-forge\n",
      "pygments                  2.6.1                    pypi_0    pypi\n",
      "pygpu                     0.7.6           py37h03ebfcd_1001    conda-forge\n",
      "pyopenssl                 19.1.0                     py_1    conda-forge\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\n",
      "pyrsistent                0.16.0                   pypi_0    pypi\n",
      "pysocks                   1.7.1            py37hc8dfbb8_1    conda-forge\n",
      "pytest                    6.0.1            py37hc8dfbb8_0    conda-forge\n",
      "python                    3.7.8           h6f2ec95_1_cpython    conda-forge\n",
      "python-dateutil           2.8.1                      py_0    conda-forge\n",
      "python_abi                3.7                     1_cp37m    conda-forge\n",
      "pytz                      2020.1                   pypi_0    pypi\n",
      "pyyaml                    5.3.1            py37h8f50634_0    conda-forge\n",
      "pyzmq                     19.0.2                   pypi_0    pypi\n",
      "readline                  8.0                  he28a2e2_2    conda-forge\n",
      "requests                  2.24.0             pyh9f0ad1d_0    conda-forge\n",
      "scikit-video              1.1.11                   pypi_0    pypi\n",
      "scipy                     1.5.2            py37hb14ef9d_0    conda-forge\n",
      "send2trash                1.6.0b1                  pypi_0    pypi\n",
      "setuptools                49.6.0           py37hc8dfbb8_0    conda-forge\n",
      "six                       1.15.0             pyh9f0ad1d_0    conda-forge\n",
      "soupsieve                 2.0.1                      py_1    conda-forge\n",
      "sqlite                    3.33.0               h4cf870e_0    conda-forge\n",
      "tensorboard               1.15.0                   py37_0    conda-forge\n",
      "tensorflow                1.15.0          gpu_py37h0f0df58_0    anaconda\n",
      "tensorflow-base           1.15.0          gpu_py37h9dcbed7_0    anaconda\n",
      "tensorflow-estimator      1.15.1             pyh2649769_0    anaconda\n",
      "tensorflow-gpu            1.15.3                   pypi_0    pypi\n",
      "termcolor                 1.1.0                      py_2    conda-forge\n",
      "terminado                 0.8.3                    pypi_0    pypi\n",
      "testpath                  0.4.4                    pypi_0    pypi\n",
      "theano                    1.0.3            py37hfc679d8_1    conda-forge\n",
      "tk                        8.6.10               hed695b0_0    conda-forge\n",
      "toml                      0.10.1             pyh9f0ad1d_0    conda-forge\n",
      "toolchain                 2.4.0                         0    anaconda\n",
      "toolchain_c_linux-64      2.4.0                         0    anaconda\n",
      "toolchain_cxx_linux-64    2.4.0                         0    anaconda\n",
      "tornado                   6.0.4            py37h8f50634_1    conda-forge\n",
      "traitlets                 5.0.0rc2                 pypi_0    pypi\n",
      "urllib3                   1.25.10                    py_0    conda-forge\n",
      "versioneer                0.18                       py_1    conda-forge\n",
      "watermark                 2.0.2                      py_0    conda-forge\n",
      "wcwidth                   0.2.5                    pypi_0    pypi\n",
      "webencodings              0.5.1                    pypi_0    pypi\n",
      "werkzeug                  0.16.1                     py_0    conda-forge\n",
      "wheel                     0.35.1                   pypi_0    pypi\n",
      "wrapt                     1.12.1           py37h8f50634_1    conda-forge\n",
      "xz                        5.2.5                h516909a_1    conda-forge\n",
      "yaml                      0.2.5                h516909a_0    conda-forge\n",
      "zeromq                    4.3.2                he6710b0_2    defaults\n",
      "zipp                      3.1.0                      py_0    conda-forge\n",
      "zlib                      1.2.11            h516909a_1007    conda-forge\n",
      "zstd                      1.4.5                h6597ccf_2    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prevseg    0+untagged.52.g4a276e8.dirty\n",
      "numpy      1.19.1\n",
      "prednet    0+untagged.70.gc5532a0.dirty\n",
      "matplotlib 3.3.1\n",
      "PIL.Image  7.2.0\n",
      "CPython 3.7.8\n",
      "IPython 7.17.0\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "%aimport prevseg.index\n",
    "import prevseg.index as index\n",
    "\n",
    "%aimport prednet.kitti_settings\n",
    "import prednet.kitti_settings as ks\n",
    "%aimport prednet.prednet_base\n",
    "import prednet.prednet_base as pn\n",
    "%aimport prednet.data_utils\n",
    "import prednet.data_utils as utils\n",
    "\n",
    "# Keep track of versions of everything\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Evaluate Kitti Code\n",
    "\n",
    "See `prednet.kitti_evaluate.py` for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 40\n",
    "batch_size = 10\n",
    "nt = 10\n",
    "weights_file = str(ks.WEIGHTS_DIR / 'tensorflow_weights/prednet_kitti_weights.hdf5')\n",
    "json_file = str(ks.WEIGHTS_DIR / 'prednet_kitti_model.json')\n",
    "test_file = str(ks.DATA_DIR / 'X_test.hkl')\n",
    "test_sources = str(ks.DATA_DIR / 'sources_test.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\"class_name\": \"Model\", \"keras_version\": \"2.0.6\", \"config\": {\"layers\": '\n",
      " '[{\"class_name\": \"InputLayer\", \"config\": {\"dtype\": \"float32\", '\n",
      " '\"batch_input_shape\": [null, 10, 3, 128, 160], \"name\": \"input_1\", \"sparse\": '\n",
      " 'false}, \"inbound_nodes\": [], \"name\": \"input_1\"}, {\"class_name\": \"PredNet\", '\n",
      " '\"config\": {\"dtype\": \"float32\", \"trainable\": true, \"pixel_max\": 1.0, '\n",
      " '\"Ahat_filt_sizes\": [3, 3, 3, 3], \"return_state\": false, \"R_filt_sizes\": [3, '\n",
      " '3, 3, 3], \"unroll\": false, \"batch_input_shape\": [null, null, null], '\n",
      " '\"LSTM_inner_activation\": \"hard_sigmoid\", \"output_mode\": \"error\", \"stateful\": '\n",
      " 'false, \"error_activation\": \"relu\", \"A_activation\": \"relu\", \"A_filt_sizes\": '\n",
      " '[3, 3, 3], \"stack_sizes\": [3, 48, 96, 192], \"name\": \"prednet_1\", '\n",
      " '\"R_stack_sizes\": [3, 48, 96, 192], \"data_format\": \"channels_first\", '\n",
      " '\"implementation\": 0, \"extrap_start_time\": null, \"go_backwards\": false, '\n",
      " '\"return_sequences\": true, \"LSTM_activation\": \"tanh\"}, \"inbound_nodes\": '\n",
      " '[[[\"input_1\", 0, 0, {}]]], \"name\": \"prednet_1\"}, {\"class_name\": '\n",
      " '\"TimeDistributed\", \"config\": {\"layer\": {\"class_name\": \"Dense\", \"config\": '\n",
      " '{\"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": '\n",
      " '{\"distribution\": \"uniform\", \"scale\": 1.0, \"seed\": null, \"mode\": \"fan_avg\"}}, '\n",
      " '\"name\": \"dense_1\", \"kernel_constraint\": null, \"bias_regularizer\": null, '\n",
      " '\"bias_constraint\": null, \"dtype\": \"float32\", \"activation\": \"linear\", '\n",
      " '\"trainable\": false, \"kernel_regularizer\": null, \"bias_initializer\": '\n",
      " '{\"class_name\": \"Zeros\", \"config\": {}}, \"units\": 1, \"batch_input_shape\": '\n",
      " '[null, null], \"use_bias\": true, \"activity_regularizer\": null}}, \"trainable\": '\n",
      " 'false, \"name\": \"timedistributed_1\"}, \"inbound_nodes\": [[[\"prednet_1\", 0, 0, '\n",
      " '{}]]], \"name\": \"timedistributed_1\"}, {\"class_name\": \"Flatten\", \"config\": '\n",
      " '{\"trainable\": true, \"name\": \"flatten_1\"}, \"inbound_nodes\": '\n",
      " '[[[\"timedistributed_1\", 0, 0, {}]]], \"name\": \"flatten_1\"}, {\"class_name\": '\n",
      " '\"Dense\", \"config\": {\"kernel_initializer\": {\"class_name\": \"VarianceScaling\", '\n",
      " '\"config\": {\"distribution\": \"uniform\", \"scale\": 1.0, \"seed\": null, \"mode\": '\n",
      " '\"fan_avg\"}}, \"name\": \"dense_2\", \"kernel_constraint\": null, '\n",
      " '\"bias_regularizer\": null, \"bias_constraint\": null, \"dtype\": \"float32\", '\n",
      " '\"activation\": \"linear\", \"trainable\": false, \"kernel_regularizer\": null, '\n",
      " '\"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"units\": 1, '\n",
      " '\"batch_input_shape\": [null, null], \"use_bias\": true, \"activity_regularizer\": '\n",
      " 'null}, \"inbound_nodes\": [[[\"flatten_1\", 0, 0, {}]]], \"name\": \"dense_2\"}], '\n",
      " '\"input_layers\": [[\"input_1\", 0, 0]], \"output_layers\": [[\"dense_2\", 0, 0]], '\n",
      " '\"name\": \"model_1\"}, \"backend\": \"theano\"}')\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "f = open(json_file, 'r')\n",
    "json_string = f.read()\n",
    "f.close()\n",
    "pprint(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apra/miniconda3/envs/prednet/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/apra/miniconda3/envs/prednet/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model = model_from_json(json_string, custom_objects = {'PredNet': pn.PredNet})\n",
    "train_model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing model (to output predictions)\n",
    "layer_config = train_model.layers[1].get_config()\n",
    "layer_config['output_mode'] = 'prediction'\n",
    "data_format = layer_config['data_format'] if 'data_format' in layer_config \\\n",
    "    else layer_config['dim_ordering']\n",
    "test_prednet = pn.PredNet(weights=train_model.layers[1].get_weights(), \n",
    "                          **layer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = list(train_model.layers[0].batch_input_shape[1:])\n",
    "input_shape[0] = nt\n",
    "inputs = Input(shape=tuple(input_shape))\n",
    "predictions = test_prednet(inputs)\n",
    "test_model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/apra/work/prednet/prednet/kitti_data/X_test.hkl\n",
      "/home/apra/work/prednet/prednet/kitti_data/sources_test.hkl\n",
      "10\n",
      "channels_first\n"
     ]
    }
   ],
   "source": [
    "print(test_file, test_sources, nt, data_format, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = utils.SequenceGenerator(test_file, \n",
    "                                         test_sources, \n",
    "                                         nt, \n",
    "                                         sequence_start_mode='unique', \n",
    "                                         data_format=data_format)\n",
    "X_test = test_generator.create_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 10, 3, 128, 160)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apra/miniconda3/envs/prednet/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_hat = test_model.predict(X_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presumably for plotting?\n",
    "if data_format == 'channels_first':\n",
    "    X_test = np.transpose(X_test, (0, 1, 3, 4, 2))\n",
    "    X_hat = np.transpose(X_hat, (0, 1, 3, 4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 10, 128, 160, 3)\n",
      "(83, 10, 128, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, X_hat.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = np.mean((X_test[:, 1:] - X_hat[:, 1:])**2)  # look at all timesteps except the first\n",
    "mse_prev = np.mean((X_test[:, :-1] - X_test[:, 1:])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: 0.006995\n",
      "Previous Frame MSE: 0.021246\n"
     ]
    }
   ],
   "source": [
    "print(\"Model MSE: %f\" % mse_model)\n",
    "print(\"Previous Frame MSE: %f\" % mse_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Model Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'prednet_1',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None, None, None),\n",
       " 'dtype': 'float32',\n",
       " 'return_sequences': True,\n",
       " 'return_state': False,\n",
       " 'go_backwards': False,\n",
       " 'stateful': False,\n",
       " 'unroll': False,\n",
       " 'implementation': 0,\n",
       " 'stack_sizes': [3, 48, 96, 192],\n",
       " 'R_stack_sizes': [3, 48, 96, 192],\n",
       " 'A_filt_sizes': [3, 3, 3],\n",
       " 'Ahat_filt_sizes': [3, 3, 3, 3],\n",
       " 'R_filt_sizes': [3, 3, 3, 3],\n",
       " 'pixel_max': 1.0,\n",
       " 'error_activation': 'relu',\n",
       " 'A_activation': 'relu',\n",
       " 'LSTM_activation': 'tanh',\n",
       " 'LSTM_inner_activation': 'hard_sigmoid',\n",
       " 'data_format': 'channels_first',\n",
       " 'extrap_start_time': None,\n",
       " 'output_mode': 'prediction'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing model (to output predictions)\n",
    "layer_config = train_model.layers[1].get_config()\n",
    "X_Rs = []\n",
    "\n",
    "test_generator = utils.SequenceGenerator(test_file, \n",
    "                                         test_sources, \n",
    "                                         nt, \n",
    "                                         sequence_start_mode='unique', \n",
    "                                         data_format=data_format)\n",
    "X_test = test_generator.create_all()\n",
    "\n",
    "for i in range(len(layer_config['R_stack_sizes'])):\n",
    "\n",
    "    layer_config['output_mode'] = 'R' + str(i)\n",
    "    data_format = layer_config['data_format'] if 'data_format' in layer_config \\\n",
    "        else layer_config['dim_ordering']\n",
    "    test_prednet = pn.PredNet(weights=train_model.layers[1].get_weights(), \n",
    "                              **layer_config)\n",
    "\n",
    "    input_shape = list(train_model.layers[0].batch_input_shape[1:])\n",
    "    input_shape[0] = nt\n",
    "    inputs = Input(shape=tuple(input_shape))\n",
    "    R_outs = test_prednet(inputs)\n",
    "    test_model = Model(inputs=inputs, outputs=R_outs)\n",
    "\n",
    "    X_Rs.append(test_model.predict(X_test, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 10, 192, 16, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Rs[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching the Schapiro Images to CoxLabs PredNet Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 10, 3, 128, 160)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image needs to be of shape (3, 128, 160)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowing some code from ``prevseg/schapiro/resnet_embedding.py``\n",
    "\n",
    "sch_shape = (128, 128)\n",
    "pn_shape = (128, 160)\n",
    "\n",
    "# Load and Resize\n",
    "paths_fractals = list(index.DIR_SCH_FRACTALS.iterdir())\n",
    "list_fractals = [Image.open(str(path)) for path in paths_fractals]\n",
    "_ = [img.load() for img in list_fractals]\n",
    "\n",
    "# Remove the alpha channel\n",
    "list_fractals_no_alpha = [Image.new(\"RGB\", pn_shape, (0,0,0))\n",
    "                          for _ in range(len(list_fractals))]\n",
    "_ = [bk.paste(img, (0, int((pn_shape[1]-sch_shape[1])/2 - 1)), mask=img.split()[3])\n",
    "     for bk, img in zip(list_fractals_no_alpha, list_fractals)]\n",
    "\n",
    "list_arrays = [np.moveaxis(np.array(img), (0,1,2), (2,1,0))\n",
    "               for img in list_fractals_no_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings\n",
    "save_path = index.DIR_SCH / 'abstract_discs_resized_128_160/'\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir()\n",
    "\n",
    "for arr, path in zip(list_arrays, paths_fractals):\n",
    "    # Turn to an array and reorder the dims\n",
    "    np.save(str(save_path / path.stem), arr)\n",
    "    arr2 = np.load(str(save_path / (path.stem + '.npy')))\n",
    "\n",
    "    assert arr.shape == arr2.shape\n",
    "    assert arr.mean() == arr2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was made into the script `prevseg/schapiro/coxlab_resize.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
