{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0.1 Creating Pytorch Datastructures\n",
    "\n",
    "Turning the Schapiro graph and walking algorithms into code amenable to pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Tue Aug 18 2020 22:00:18 \n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.4.0-42-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : apra-x3\n",
      "Git hash   : 9dcef66145f8f506529041f0eb7a84a740a26a16\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and other non-code related info\n",
    "%watermark -n -m -g -b -t -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networkx  2.4\n",
      "prevseg   0+untagged.30.g179141d.dirty\n",
      "PIL.Image 7.2.0\n",
      "torch     1.6.0\n",
      "numpy     1.19.1\n",
      "CPython 3.8.5\n",
      "IPython 7.16.1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "\n",
    "%aimport prevseg.index\n",
    "import prevseg.index as index\n",
    "%aimport prevseg.schapiro\n",
    "from prevseg.schapiro import walk, graph\n",
    "\n",
    "# Keep track of versions of everything\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fractal Dataloader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "class ShapiroFractalsDataset(IterableDataset):\n",
    "    def __init__(self, batch_size=8, n_pentagons=3, max_steps=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_pentagons = n_pentagons\n",
    "        self.max_steps = max_steps\n",
    "        \n",
    "        self.G = graph.schapiro_graph(n_pentagons=n_pentagons)\n",
    "        \n",
    "        self.load_node_stimuli()\n",
    "        \n",
    "    def load_node_stimuli(self):\n",
    "        # Load the fractal images into memory\n",
    "        assert index.DIR_SCH_FRACTALS.exists()\n",
    "        paths_data = list(pes.index.DIR_SCH_FRACTALS.iterdir())\n",
    "        np.random.shuffle(paths_data)\n",
    "        self.paths_data = paths_data[:5*self.n_pentagons]\n",
    "        self.array_data = np.array(\n",
    "            [np.array(ImageOps.grayscale(Image.open(str(path))))\n",
    "             for path in self.paths_data])\n",
    "        \n",
    "    def iter_single_sample(self):\n",
    "        for sample in walk.walk_random(self.G, steps=self.max_steps):\n",
    "            yield self.array_data[sample[0]]\n",
    "        \n",
    "    def iter_batch_dataset(self):\n",
    "        batch = zip(*[self.iter_single_sample() for _ in range(self.batch_size)])\n",
    "        while True:\n",
    "            yield np.array(next(batch))\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self.iter_batch_dataset()\n",
    "    \n",
    "iter_ds = ShapiroFractalsDataset()\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "for batch in loader:\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2048])\n"
     ]
    }
   ],
   "source": [
    "class ShapiroResnetEmbeddingDataset(ShapiroFractalsDataset):\n",
    "    def load_node_stimuli(self):\n",
    "        # Load the fractal images into memory\n",
    "        assert index.DIR_SCH_FRACTALS.exists()\n",
    "        paths_data = list(pes.index.DIR_SCH_FRACTALS_EMB.iterdir())\n",
    "        np.random.shuffle(paths_data)\n",
    "        self.paths_data = paths_data[:5*self.n_pentagons]\n",
    "        self.array_data = np.array(\n",
    "            [np.array(np.load(str(path)))\n",
    "             for path in self.paths_data])\n",
    "\n",
    "iter_ds = ShapiroResnetEmbeddingDataset()\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "for batch in loader:\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
