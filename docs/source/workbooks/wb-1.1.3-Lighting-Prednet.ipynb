{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.3 Lighting Prednet\n",
    "\n",
    "In an effort to make things more streamlined, this notebook goes through the process of moving and handling the model using `pytorch-lightning` as shown [here](https://github.com/PyTorchLightning/pytorch-lightning). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 10 2020 10:50:35 \n",
      "\n",
      "CPython 3.8.2\n",
      "IPython 7.13.0\n",
      "\n",
      "torch 1.4.0\n",
      "torchvision 0.5.0\n",
      "pytorch_lightning 0.7.1\n",
      "jupyterlab 2.0.1\n",
      "lab 0+untagged.46.gd571ca0.dirty\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-88-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "Git hash   : d571ca0b446908408dcf53afb9389b2207d3a0dd\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and packages. Add more as necessary.\n",
    "%watermark -v -n -m -g -b -t -p torch,torchvision,pytorch_lightning,jupyterlab,lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the GPU\n",
    "\n",
    "Make sure we aren't greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 10 10:51:26 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   26C    P8     7W / 250W |   1656MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 42%   67C    P2   117W / 250W |   2599MiB / 12196MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN Xp            Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 53%   84C    P2   267W / 250W |   6677MiB / 12196MiB |     91%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN Xp            Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 54%   84C    P2   253W / 250W |   7011MiB / 12196MiB |     95%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN Xp            Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 47%   73C    P2   110W / 250W |   5189MiB / 12196MiB |     24%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN Xp            Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 54%   83C    P2   206W / 250W |   7351MiB / 12196MiB |     93%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     10262      C   ...4/miniconda3/envs/brainscore/bin/python  1125MiB |\n",
      "|    0     32596      C   ...azerroug/anaconda3/envs/py36/bin/python   521MiB |\n",
      "|    2     18814      C   python                                      2589MiB |\n",
      "|    4     26381      C   python                                      6667MiB |\n",
      "|    5     26381      C   python                                      7001MiB |\n",
      "|    6     24678      C   python                                      5179MiB |\n",
      "|    7     24678      C   python                                      7341MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Pytorch-Lightning\n",
    "\n",
    "This was done in an earlier instantiation of the notebook and is kept for book-keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Using cached pytorch-lightning-0.7.1.tar.gz (6.0 MB)\n",
      "Requirement already satisfied: tqdm>=4.35.0 in /media/data_cifs2/apra/_envs/bk2/lib/python3.8/site-packages (from pytorch-lightning) (4.43.0)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /media/data_cifs2/apra/_envs/bk2/lib/python3.8/site-packages (from pytorch-lightning) (1.18.1)\n",
      "Requirement already satisfied: torch>=1.1 in /media/data_cifs2/apra/_envs/bk2/lib/python3.8/site-packages (from pytorch-lightning) (1.4.0)\n",
      "Collecting tensorboard>=1.14\n",
      "  Using cached tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Collecting future>=0.17.1\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /media/data_cifs2/apra/_envs/bk2/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (0.34.2)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.0-py2.py3-none-any.whl (298 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.27.2-cp38-cp38-manylinux2010_x86_64.whl (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.11.2-py2.py3-none-any.whl (76 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.11.3-cp38-cp38-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 39.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /media/data_cifs2/apra/_envs/bk2/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (45.3.0.post20200307)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /media/data_cifs2/apra/_envs/bk2/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.14.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl-py-0.9.0.tar.gz (104 kB)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/data_cifs2/apra/_envs/bk2/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2019.11.28)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: pytorch-lightning, future, absl-py\n",
      "  Building wheel for pytorch-lightning (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytorch-lightning: filename=pytorch_lightning-0.7.1-py3-none-any.whl size=145307 sha256=3bd959fbace8e846d4f4d2713081fd9c9f0eeaf8dcabb40e6efb64ba44811eab\n",
      "  Stored in directory: /home/abdullah/.cache/pip/wheels/d7/cc/74/2cdbeb448fe0be9c8fbb540083575a9371623217e6b9287150\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=749c476ec096bf1a9cb7048c3ec42cfde4a124346e04a85ccae9a6886ffd321f\n",
      "  Stored in directory: /home/abdullah/.cache/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=bdb444ab798900afe32704b95ef88ce4592539067e697ee39e47ba6cadc7965c\n",
      "  Stored in directory: /home/abdullah/.cache/pip/wheels/1d/10/8e/2f79b924179ff1e6510933d63eb851bea01054fff262343b7a\n",
      "Successfully built pytorch-lightning future absl-py\n",
      "Installing collected packages: werkzeug, grpcio, urllib3, chardet, idna, requests, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, markdown, absl-py, tensorboard, future, pytorch-lightning\n",
      "Successfully installed absl-py-0.9.0 cachetools-4.0.0 chardet-3.0.4 future-0.18.2 google-auth-1.11.2 google-auth-oauthlib-0.4.1 grpcio-1.27.2 idna-2.9 markdown-3.2.1 oauthlib-3.1.0 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-0.7.1 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.1.1 urllib3-1.25.8 werkzeug-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to be used throughout the package\n",
    "%aimport lab\n",
    "import lab\n",
    "%aimport lab.index\n",
    "from lab import index\n",
    "%aimport lab.breakfast\n",
    "import lab.breakfast as bk\n",
    "%aimport lab.breakfast.constants\n",
    "from lab.breakfast.constants import SEED\n",
    "# Import the data subdirectories\n",
    "%aimport lab.breakfast.index\n",
    "from lab.breakfast.index import (DIR_BREAKFAST, \n",
    "                                 DIR_BREAKFAST_DATA, \n",
    "                                 DIR_COARSE_SEG, \n",
    "                                 DIR_FINE_SEG,\n",
    "                                 DIR_BK_WEIGHTS,\n",
    "                                 DIR_BK_CHECKPOINTS,\n",
    "                                 DIR_BK_LOGS_TB,\n",
    "                                )\n",
    "%aimport lab.breakfast.prednet\n",
    "from lab.breakfast.prednet import PredNet\n",
    "%aimport lab.breakfast.dataloader\n",
    "from lab.breakfast.dataloader import Breakfast64DimFVDataset, BreakfastI3DFVDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Pytorch Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `wb-4.1.2` for the outputs of the code cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader et al\n",
    "\n",
    "Loading the Dataloader which now has all the I3D data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "ds = BreakfastI3DFVDataset()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "np.random.seed(SEED)\n",
    "\n",
    "ds_length = len(ds)\n",
    "indices = list(range(ds_length))\n",
    "batch_size = 256\n",
    "n_test = np.maximum(batch_size, 128)\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[n_test:], indices[:n_test]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = DataLoader(ds, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader = DataLoader(ds, batch_size=batch_size, sampler=test_sampler)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "\n",
    "num_epochs = 50\n",
    "n_layers = 4\n",
    "input_size = 2048\n",
    "nt = 64 # num of time steps\n",
    "A_channels = tuple(input_size // (2**i) for i in range(n_layers))\n",
    "R_channels = tuple(input_size // (2**i) for i in range(n_layers))\n",
    "lr = 0.000333 # if epoch < 75 else 0.0001\n",
    "\n",
    "path_checkpoint = DIR_BK_CHECKPOINTS / 'i3d_checkpoint.tar'\n",
    "path_weights = DIR_BK_WEIGHTS / 'i3d_training.pt'\n",
    "\n",
    "layer_loss_weights = Variable(torch.FloatTensor([[1.]] + [[0.]]*(n_layers-1)).cuda())\n",
    "time_loss_weights = 1./(nt - 1) * torch.ones(nt, 1)\n",
    "time_loss_weights[0] = 0\n",
    "time_loss_weights = Variable(time_loss_weights.cuda())\n",
    "\n",
    "model = PredNet(R_channels, A_channels, output_mode='error')\n",
    "print(model)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU.')\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def lr_scheduler(optimizer, epoch):\n",
    "    if epoch < num_epochs // 2:\n",
    "        return optimizer\n",
    "    else:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.0001\n",
    "        return optimizer\n",
    "    \n",
    "train_errors = []\n",
    "\n",
    "print(f'Running with batch size {batch_size} ({ds_length//batch_size} iterations / epoch)')\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    optimizer = lr_scheduler(optimizer, epoch)\n",
    "    for batch_idx, (data, path) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        errors = model(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, nt), time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        train_errors.append(errors.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        errors.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        test_errors = []\n",
    "        for data, path in test_loader:\n",
    "            data = Variable(data)\n",
    "            errors = model(data) # batch x n_layers x nt\n",
    "            loc_batch = errors.size(0)\n",
    "            errors = torch.mm(errors.view(-1, nt), time_loss_weights) # batch*n_layers x 1\n",
    "            errors = torch.mm(errors.view(loc_batch, -1), layer_loss_weights)\n",
    "            test_errors.append(torch.mean(errors, axis=0).item())\n",
    "            \n",
    "        test_error = np.mean(test_errors)\n",
    "        train_error = np.mean(train_errors)\n",
    "        print(f'Epoch: {epoch}/{num_epochs}, train_error: {train_error}, '\n",
    "              f'test error: {test_error}')\n",
    "        train_errors = []\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'errors': errors,\n",
    "        }, str(path_checkpoint))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "torch.save(model.state_dict(), str(path_weights))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch-Lightning\n",
    "\n",
    "The code below will follow the setup shown on the [intro](https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html) documentation page for `pytorch-lightning`. Additionally, the actual model code is lifted from `lab.breakfast.prednet.PredNet` at commit `ab1302580aa631970eac815e335d124a8029ae41`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# parametrize the network\n",
    "# parser.add_argument('--n_layers', type=int, default=4)\n",
    "# parser.add_argument('--input_size', type=int, default=2048)\n",
    "# parser.add_argument('--time_steps', type=int, default=64)\n",
    "# parser.add_argument('--path_checkpoints', type=str, default=str(DIR_BK_CHECKPOINTS / 'i3d_checkpoint.tar'))\n",
    "# parser.add_argument('--path_weights', type=str, default=str(DIR_BK_WEIGHTS / 'i3d_training.pt'))\n",
    "# parser.add_argument('--lr', type=float, default=0.000333)\n",
    "# parser.add_argument('--output_mode', type=str, default='error')\n",
    "# parser.add_argument('--n_val', type=int, default=256)\n",
    "# parser.add_argument('--device', type=str, default='cuda')\n",
    "# parser.add_argument('--seed', type=int, default=117)\n",
    "# parser.add_argument('--batch_size', type=int, default=256)\n",
    "\n",
    "# # add all the available options to the trainer\n",
    "# parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "hps = {\n",
    "    'n_layers' : 4,\n",
    "    'input_size' : 2048,\n",
    "    'time_steps' : 64,\n",
    "    'path_checkpoints' : DIR_BK_CHECKPOINTS / 'i3d_checkpoint.tar',\n",
    "    'path_weights' : DIR_BK_WEIGHTS / 'i3d_training.pt',\n",
    "    'lr' : 0.000333,\n",
    "    'output_mode' : 'error',\n",
    "    'device' : 'cuda',\n",
    "    'n_val' : 256,\n",
    "    'seed' : 117,\n",
    "    'batch_size' : 256,\n",
    "    'n_epochs' : 10,\n",
    "    'n_workers' : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 1min 54s, total: 2min 4s\n",
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = BreakfastI3DFVDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from functools import wraps\n",
    "from lab.utils import flatten\n",
    "from lab.torch.lstm import LSTM\n",
    "from lab.torch.activations import SatLU\n",
    "\n",
    "\n",
    "class PredCell(object):\n",
    "    def __init__(self, parent, layer_num, hps, a_channels, r_channels):\n",
    "        super().__init__()\n",
    "        self.parent = parent\n",
    "        self.layer_num = layer_num\n",
    "        self.hps = hps\n",
    "        self.a_channels = a_channels\n",
    "        self.r_channels = r_channels\n",
    "        \n",
    "        # Reccurent\n",
    "        self.recurrent = LSTM(2 * self.a_channels[self.layer_num],\n",
    "                              self.r_channels[self.layer_num])\n",
    "        self.recurrent.reset_parameters()\n",
    "        \n",
    "        # Dense\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(self.r_channels[self.layer_num],\n",
    "                      self.a_channels[self.layer_num]),\n",
    "            nn.ReLU())\n",
    "        if self.layer_num == 0:\n",
    "            self.dense.add_module('satlu', SatLU())\n",
    "            \n",
    "        # Update\n",
    "        if self.layer_num < self.hps['n_layers'] - 1:\n",
    "            self.update_a = nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    2 * self.a_channels[self.layer_num],\n",
    "                    self.a_channels[self.layer_num + 1]),\n",
    "                nn.ReLU())\n",
    "        \n",
    "        # Build E, R, and H\n",
    "        self.reset()\n",
    "        \n",
    "        # Book keeping\n",
    "        self.modules = {'recurrent' : self.recurrent, 'dense' : self.dense}\n",
    "        if hasattr(self, 'update_a'):\n",
    "            self.modules['update_a'] = self.update_a\n",
    "        # Hack to appease the pytorch-gods\n",
    "        for name, module in self.modules.items():\n",
    "            setattr(self.parent, f'predcell_{self.layer_num}_{name}', module)\n",
    "            \n",
    "    def reset(self, batch_size=None):\n",
    "        batch_size = batch_size or self.hps['batch_size']\n",
    "        # E, R, and H variables\n",
    "        self.E = Variable(torch.zeros(\n",
    "            1,                  # Single time step\n",
    "            batch_size,\n",
    "            2 * self.a_channels[self.layer_num])).cuda()\n",
    "        self.R = Variable(torch.zeros(\n",
    "            1,                  # Single time step\n",
    "            batch_size,\n",
    "            self.r_channels[self.layer_num])).cuda()\n",
    "        self.H = None\n",
    "        \n",
    "class LitPredNet(pl.LightningModule):\n",
    "    def __init__(self, hps, ds=None):\n",
    "        super().__init__()\n",
    "        # Attribute definitions\n",
    "        self.hps = hps\n",
    "        self.ds = ds\n",
    "        self.n_layers = self.hps['n_layers']\n",
    "        self.output_mode = self.hps['output_mode']\n",
    "        self.input_size = self.hps['input_size']\n",
    "        self.time_steps = self.hps['time_steps']\n",
    "        self.batch_size = self.hps['batch_size']\n",
    "        \n",
    "        # Channel sizes\n",
    "        self.r_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)] + [0,] # Convenience\n",
    "        self.a_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)]\n",
    "        \n",
    "        # Make sure everything checks out\n",
    "        default_output_modes = ['prediction', 'error']\n",
    "        assert self.output_mode in default_output_modes, \\\n",
    "            'Invalid output_mode: ' + str(output_mode)\n",
    "\n",
    "        # Make all the pred cells\n",
    "        self.predcells = [PredCell(self,\n",
    "                                   layer_num,\n",
    "                                   self.hps,\n",
    "                                   self.a_channels,\n",
    "                                   self.r_channels)\n",
    "                          for layer_num in range(self.n_layers)]\n",
    "        \n",
    "        #nn.ParameterList([param for predcell in self.predcells for param in predcell.parameters])\n",
    "\n",
    "        # How to weight the errors\n",
    "        # 1 followed by zeros means just minimize error at lowest layer\n",
    "        self.layer_loss_weights = Variable(torch.FloatTensor(\n",
    "            [[1.]] + [[0.]]*(self.n_layers-1)).cuda())\n",
    "        # How much to weight errors at each timestep\n",
    "        self.time_loss_weights = 1. / (self.time_steps - 1) \\\n",
    "                                 * torch.ones(self.time_steps, 1)\n",
    "        # Dont count first time step\n",
    "        self.time_loss_weights[0] = 0\n",
    "        self.time_loss_weights = Variable(self.time_loss_weights.cuda())\n",
    "        \n",
    "        if self.hps['device'] == 'cuda' and torch.cuda.is_available():\n",
    "            print('Using GPU', flush=True)\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        total_error = []\n",
    "        # Set the expected batch size\n",
    "        for cell in self.predcells:\n",
    "            cell.reset(input.size(0))\n",
    "\n",
    "        for t in range(self.time_steps):\n",
    "            A = input[:,t,:].unsqueeze(0)\n",
    "            A = A.type(torch.cuda.FloatTensor)\n",
    "\n",
    "            # Loop backwards\n",
    "            for cell in reversed(self.predcells):\n",
    "                E, R = cell.E, cell.R\n",
    "                # First time step\n",
    "                if t == 0:\n",
    "                    hx = (R, R)\n",
    "                else:\n",
    "                    hx = cell.H\n",
    "\n",
    "                cell.R, cell.H = cell.recurrent(E, hx)\n",
    "\n",
    "            for cell in self.predcells:\n",
    "                # Go from R to A_hat\n",
    "                A_hat = cell.dense(cell.R)\n",
    "\n",
    "                # Convenience\n",
    "                if cell.layer_num == 0:\n",
    "                    frame_prediction = A_hat\n",
    "\n",
    "                # Split to 2 Es\n",
    "                pos = F.relu(A_hat - A)\n",
    "                neg = F.relu(A - A_hat)\n",
    "                E = torch.cat([pos, neg], 2)\n",
    "                cell.E = E\n",
    "\n",
    "                # If not last layer, update stored A\n",
    "                if cell.layer_num < self.n_layers - 1:\n",
    "                    A = cell.update_a(E)\n",
    "\n",
    "            if self.output_mode == 'error':\n",
    "                mean_error = torch.cat(\n",
    "                    [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                                1, keepdim=True)\n",
    "                     for cell in self.predcells], 1)\n",
    "\n",
    "                # batch x n_layers\n",
    "                total_error.append(mean_error)\n",
    "        \n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return frame_prediction\n",
    "\n",
    "    def timeit(method):\n",
    "        \"\"\"Combination of https://stackoverflow.com/questions/51503672/decorator-for-timeit-timeit-method/51503837#51503837,\n",
    "        and https://www.geeksforgeeks.org/python-program-to-convert-seconds-into-hours-minutes-and-seconds/\"\"\"\n",
    "        @wraps(method)\n",
    "        def _time_it(self, *args, **kwargs):\n",
    "            start = int(round(time.time() * 1000))\n",
    "            try:\n",
    "                return method(self, *args, **kwargs)\n",
    "            finally:\n",
    "                end_ = int(round(time.time() * 1000)) - start\n",
    "                if end_ > 1000:\n",
    "                    time_str = time.strftime(\"%H:%M:%S\", time.gmtime(end_ // 1000))\n",
    "                    print(f\"Total execution time: {time_str}\", flush=True)\n",
    "                \n",
    "        return _time_it\n",
    "\n",
    "    @timeit\n",
    "    def prepare_data(self):\n",
    "        if self.ds is None:\n",
    "            print('Loading the i3d data from disk. This can take '\n",
    "                  'several minutes...', flush=True)\n",
    "        self.ds = self.ds or BreakfastI3DFVDataset()\n",
    "        self.ds_length = len(self.ds)\n",
    "        np.random.seed(self.hps['seed'])\n",
    "        self.indices = list(range(self.ds_length))\n",
    "        self.train_sampler = SubsetRandomSampler(self.indices[self.hps['n_val']:])\n",
    "        self.val_sampler = SubsetRandomSampler(self.indices[:self.hps['n_val']])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.train_sampler,\n",
    "                          num_workers=self.hps['n_workers'])\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.val_sampler,\n",
    "                          num_workers=self.hps['n_workers'])\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hps['lr'])\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data, path = batch\n",
    "        data = Variable(data)\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        logs = {f'{prefix}loss' : errors}\n",
    "        return {f'{prefix}loss' : errors, 'log' : logs}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'train')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'val')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Old-Fashioned Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "batch = None\n",
    "train_errors, val_errors = None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Running with batch size 256 (168 iterations / epoch)\n",
      "Epoch: 1, Iteration: 0, train_error: 5.090212821960449\n",
      "Epoch: 1, Iteration: 56, train_error: 3.1931983871119365\n",
      "Epoch: 1, Iteration: 112, train_error: 1.4628551240478243\n",
      "Epoch: 1/1, train_error: 0.9116474173285745, val error: 0.8152002096176147\n"
     ]
    }
   ],
   "source": [
    "model = LitPredNet(hps, ds=ds)\n",
    "model.prepare_data()\n",
    "hps['n_epochs'] = 1\n",
    "num_epochs = hps['n_epochs']\n",
    "\n",
    "train_errors, val_errors = [], []\n",
    "n_iters_per_epoch = model.ds_length // model.batch_size\n",
    "\n",
    "print(f'Running with batch size {model.batch_size} ({n_iters_per_epoch} iterations / epoch)')\n",
    "\n",
    "optimizer = model.configure_optimizers()\n",
    "\n",
    "train_dataloader = model.train_dataloader()\n",
    "val_dataloader = model.val_dataloader()\n",
    "\n",
    "for epoch in range(num_epochs):    \n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        errors = model.training_step(batch, batch_idx)\n",
    "        train_errors.append(errors['loss'].item())\n",
    "        optimizer.zero_grad()\n",
    "        errors['loss'].backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % (n_iters_per_epoch // 3) == 0:\n",
    "            train_error = np.mean(train_errors)\n",
    "            print(f'Epoch: {epoch+1}, Iteration: {batch_idx}, train_error: {train_error}')\n",
    "            train_errors = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(val_dataloader):\n",
    "        errors = model.val_step(batch, batch_idx)\n",
    "        val_errors.append(errors['val_loss'].item())\n",
    "\n",
    "    val_error = np.mean(val_errors)n_epochs\n",
    "    train_error = np.mean(train_errors)\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, train_error: {train_error}, '\n",
    "          f'val error: {val_error}')\n",
    "    train_errors = []\n",
    "    val_errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is backwards compatible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lighting API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/abdullah/envs/bk2/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:199: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, trainer = NonModelCheckpointne\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "batch = None\n",
    "train_errors, val_errors = None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hps['n_epochs'] = 1\n",
    "\n",
    "model = LitPredNet(hps, ds=ds)\n",
    "trainer = pl.Trainer(max_epochs=hps['n_epochs'])\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Intermediate Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "batch = None\n",
    "train_errors, val_errors = None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(str(DIR_BK_LOGS_TB), name='litprednet')\n",
    "model = LitPredNet(hps, ds=ds)\n",
    "trainer = pl.Trainer(logger=logger,\n",
    "                     max_epochs=1, \n",
    "                   )\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7c3417ade8434a9cf1829969016407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/abdullah/envs/bk2/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:199: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=logger,\n",
    "                     max_epochs=3, \n",
    "                   )\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBLitPredNet(LitPredNet):\n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data, path = batch\n",
    "        data = Variable(data)\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        self.logger.experiment.add_scalar(f'{prefix.replace(\"_\", \"/\")}loss', \n",
    "                                          errors, self.global_step)\n",
    "        return {f'{prefix}loss' : errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b064d67cc644ba1b0b9d556183e9217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "batch = None\n",
    "train_errors, val_errors = None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(str(DIR_BK_LOGS_TB), name='tblitprednet')\n",
    "model = TBLitPredNet(hps, ds=ds)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5,\n",
    "                     train_percent_check=.1, \n",
    "                     logger=logger, \n",
    "                    )\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "class CPLitPredNet(LitPredNet):\n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data, path = batch\n",
    "        data = Variable(data)\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        self.logger.experiment.add_scalar(f'{prefix}loss', \n",
    "                                          errors, self.global_step)\n",
    "        return {f'{prefix}loss' : errors}\n",
    "\n",
    "    def validation_epoch_end(self, output):\n",
    "        out = output[0]\n",
    "        out['global_step'] = self.global_step\n",
    "        return out\n",
    "    \n",
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = CPLitPredNet(hps, ds=ds)\n",
    "model.name = 'ckpt_test_litprednet'\n",
    "logger = pl.loggers.TensorBoardLogger(str(DIR_BK_LOGS_TB), name=model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = DIR_BK_CHECKPOINTS / f'{model.name}_v{logger.version}'\n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / 'bk_i3d_{global_step:05d}_{epoch:03d}_{val_loss:.3f}'),\n",
    "    verbose=True,\n",
    "    save_top_k=10,\n",
    "    period=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(default_save_path=str(DIR_BK_CHECKPOINTS),\n",
    "                     checkpoint_callback=ckpt,\n",
    "                     epochs=5,\n",
    "                     logger=logger,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to remember to use`max_epochs` not `epochs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hparams + Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = {\n",
    "    'model_name' : 'hparams_litprednet',\n",
    "    'n_layers' : 4,\n",
    "    'input_size' : 2048,\n",
    "    'time_steps' : 64,\n",
    "    'dir_checkpoints' : str(DIR_BK_CHECKPOINTS),\n",
    "    'dir_weights' : str(DIR_BK_WEIGHTS),\n",
    "    'dir_logs' : str(DIR_BK_LOGS_TB),\n",
    "    'lr' : 0.000333,\n",
    "    'output_mode' : 'error',\n",
    "    'device' : 'cuda',\n",
    "    'n_val' : 256,\n",
    "    'seed' : 117,\n",
    "    'batch_size' : 256,\n",
    "    'n_epochs' : 10,\n",
    "    'n_workers' : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from functools import wraps\n",
    "from lab.utils import flatten\n",
    "from lab.torch.lstm import LSTM\n",
    "from lab.torch.activations import SatLU\n",
    "\n",
    "\n",
    "class PredCell(object):\n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels):\n",
    "        super().__init__()\n",
    "        self.parent = parent\n",
    "        self.layer_num = layer_num        \n",
    "        if isinstance(hparams, dict):\n",
    "            self.hparams = Namespace(**hparams)\n",
    "        else:\n",
    "            self.hparams = hparams\n",
    "        self.a_channels = a_channels\n",
    "        self.r_channels = r_channels\n",
    "        \n",
    "        # Reccurent\n",
    "        self.recurrent = LSTM(2 * self.a_channels[self.layer_num],\n",
    "                              self.r_channels[self.layer_num])\n",
    "        self.recurrent.reset_parameters()\n",
    "        \n",
    "        # Dense\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(self.r_channels[self.layer_num],\n",
    "                      self.a_channels[self.layer_num]),\n",
    "            nn.ReLU())\n",
    "        if self.layer_num == 0:\n",
    "            self.dense.add_module('satlu', SatLU())\n",
    "            \n",
    "        # Update\n",
    "        if self.layer_num < self.hparams.n_layers - 1:\n",
    "            self.update_a = nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    2 * self.a_channels[self.layer_num],\n",
    "                    self.a_channels[self.layer_num + 1]),\n",
    "                nn.ReLU())\n",
    "        \n",
    "        # Build E, R, and H\n",
    "        self.reset()\n",
    "        \n",
    "        # Book keeping\n",
    "        self.modules = {'recurrent' : self.recurrent, 'dense' : self.dense}\n",
    "        if hasattr(self, 'update_a'):\n",
    "            self.modules['update_a'] = self.update_a\n",
    "        # Hack to appease the pytorch-gods\n",
    "        for name, module in self.modules.items():\n",
    "            setattr(self.parent, f'predcell_{self.layer_num}_{name}', module)\n",
    "            \n",
    "    def reset(self, batch_size=None):\n",
    "        batch_size = batch_size or self.hparams.batch_size\n",
    "        # E, R, and H variables\n",
    "        self.E = Variable(torch.zeros(\n",
    "            1,                  # Single time step\n",
    "            batch_size,\n",
    "            2 * self.a_channels[self.layer_num])).cuda()\n",
    "        self.R = Variable(torch.zeros(\n",
    "            1,                  # Single time step\n",
    "            batch_size,\n",
    "            self.r_channels[self.layer_num])).cuda()\n",
    "        self.H = None\n",
    "        \n",
    "class LitPredNet(pl.LightningModule):\n",
    "    def __init__(self, hparams, ds=None):\n",
    "        super().__init__()\n",
    "        # Attribute definitions\n",
    "        self.hparams = hparams\n",
    "        self.n_layers = self.hparams.n_layers\n",
    "        self.output_mode = self.hparams.output_mode\n",
    "        self.input_size = self.hparams.input_size\n",
    "        self.time_steps = self.hparams.time_steps\n",
    "        self.batch_size = self.hparams.batch_size\n",
    "        self.ds = ds\n",
    "        \n",
    "        # Channel sizes\n",
    "        self.r_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)] + [0,] # Convenience\n",
    "        self.a_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)]\n",
    "        \n",
    "        # Make sure everything checks out\n",
    "        default_output_modes = ['prediction', 'error']\n",
    "        assert self.output_mode in default_output_modes, \\\n",
    "            'Invalid output_mode: ' + str(output_mode)\n",
    "\n",
    "        # Make all the pred cells\n",
    "        self.predcells = [PredCell(self,\n",
    "                                   layer_num,\n",
    "                                   self.hparams,\n",
    "                                   self.a_channels,\n",
    "                                   self.r_channels)\n",
    "                          for layer_num in range(self.n_layers)]\n",
    "        \n",
    "        #nn.ParameterList([param for predcell in self.predcells for param in predcell.parameters])\n",
    "\n",
    "        # How to weight the errors\n",
    "        # 1 followed by zeros means just minimize error at lowest layer\n",
    "        self.layer_loss_weights = Variable(torch.FloatTensor(\n",
    "            [[1.]] + [[0.]]*(self.n_layers-1)).cuda())\n",
    "        # How much to weight errors at each timestep\n",
    "        self.time_loss_weights = 1. / (self.time_steps - 1) \\\n",
    "                                 * torch.ones(self.time_steps, 1)\n",
    "        # Dont count first time step\n",
    "        self.time_loss_weights[0] = 0\n",
    "        self.time_loss_weights = Variable(self.time_loss_weights.cuda())\n",
    "        \n",
    "        if self.hparams.device == 'cuda' and torch.cuda.is_available():\n",
    "            print('Using GPU', flush=True)\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        total_error = []\n",
    "        # Set the expected batch size\n",
    "        for cell in self.predcells:\n",
    "            cell.reset(input.size(0))\n",
    "\n",
    "        for t in range(self.time_steps):\n",
    "            A = input[:,t,:].unsqueeze(0)\n",
    "            A = A.type(torch.cuda.FloatTensor)\n",
    "\n",
    "            # Loop backwards\n",
    "            for cell in reversed(self.predcells):\n",
    "                E, R = cell.E, cell.R\n",
    "                # First time step\n",
    "                if t == 0:\n",
    "                    hx = (R, R)\n",
    "                else:\n",
    "                    hx = cell.H\n",
    "\n",
    "                cell.R, cell.H = cell.recurrent(E, hx)\n",
    "\n",
    "            for cell in self.predcells:\n",
    "                # Go from R to A_hat\n",
    "                A_hat = cell.dense(cell.R)\n",
    "\n",
    "                # Convenience\n",
    "                if cell.layer_num == 0:\n",
    "                    frame_prediction = A_hat\n",
    "\n",
    "                # Split to 2 Es\n",
    "                pos = F.relu(A_hat - A)\n",
    "                neg = F.relu(A - A_hat)\n",
    "                E = torch.cat([pos, neg], 2)\n",
    "                cell.E = E\n",
    "\n",
    "                # If not last layer, update stored A\n",
    "                if cell.layer_num < self.n_layers - 1:\n",
    "                    A = cell.update_a(E)\n",
    "\n",
    "            if self.output_mode == 'error':\n",
    "                mean_error = torch.cat(\n",
    "                    [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                                1, keepdim=True)\n",
    "                     for cell in self.predcells], 1)\n",
    "\n",
    "                # batch x n_layers\n",
    "                total_error.append(mean_error)\n",
    "        \n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return frame_prediction\n",
    "\n",
    "    def timeit(method):\n",
    "        \"\"\"Combination of https://stackoverflow.com/questions/51503672/decorator-for-timeit-timeit-method/51503837#51503837,\n",
    "        and https://www.geeksforgeeks.org/python-program-to-convert-seconds-into-hours-minutes-and-seconds/\"\"\"\n",
    "        @wraps(method)\n",
    "        def _time_it(self, *args, **kwargs):\n",
    "            start = int(round(time.time() * 1000))\n",
    "            try:\n",
    "                return method(self, *args, **kwargs)\n",
    "            finally:\n",
    "                end_ = int(round(time.time() * 1000)) - start\n",
    "                if end_ > 1000:\n",
    "                    time_str = time.strftime(\"%H:%M:%S\", time.gmtime(end_ // 1000))\n",
    "                    print(f\"Total execution time: {time_str}\", flush=True)\n",
    "                \n",
    "        return _time_it\n",
    "\n",
    "    @timeit\n",
    "    def prepare_data(self):\n",
    "        if self.ds is None:\n",
    "            print('Loading the i3d data from disk. This can take '\n",
    "                  'several minutes...', flush=True)\n",
    "        self.ds = self.ds or BreakfastI3DFVDataset()\n",
    "        self.ds_length = len(self.ds)\n",
    "        np.random.seed(self.hparams.seed)\n",
    "        self.indices = list(range(self.ds_length))\n",
    "        self.train_sampler = SubsetRandomSampler(self.indices[self.hparams.n_val:])\n",
    "        self.val_sampler = SubsetRandomSampler(self.indices[:self.hparams.n_val])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.train_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.val_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data, path = batch\n",
    "        data = Variable(data)\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        self.logger.experiment.add_scalar(f'{prefix}loss', \n",
    "                                          errors, self.global_step)\n",
    "        return {f'{prefix}loss' : errors}\n",
    "\n",
    "    def validation_epoch_end(self, output):\n",
    "        out_dict = {}\n",
    "        out_dict['val_loss'] = np.mean([out['val_loss'].item() for out in output])\n",
    "        out_dict['global_step'] = self.global_step\n",
    "        return out_dict\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'train')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hparams = Namespace(**hps)\n",
    "hparams.name = 'hparams_litprednet'\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / 'bk_i3d_{global_step:05d}_{epoch:03d}_{val_loss:.3f}'),\n",
    "    verbose=True,\n",
    "    save_top_k=2,\n",
    "    period=.25\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(default_save_path=str(DIR_BK_CHECKPOINTS),\n",
    "                     checkpoint_callback=ckpt,\n",
    "                     max_epochs=1,\n",
    "                     logger=logger,\n",
    "                     val_check_interval=0.25,\n",
    "                     )\n",
    "\n",
    "model = LitPredNet(hparams)\n",
    "model.ds = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d06c92b0344485bb87aa2c79ca2113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = LitPredNet.load_from_checkpoint(\n",
    "    str(ckpt_dir / 'bk_i3d_global_step=00167_epoch=000_val_loss=0.872.ckpt'))\n",
    "model.ds = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7941b5153e94ef0891a6c0f2fda7bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.max_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3e19e2b9954b97a8b9663e66938a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hparams = Namespace(**hps)\n",
    "hparams.name = 'hparams_litprednet'\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name, version=2)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / 'bk_i3d_{global_step:05d}_{epoch:03d}_{val_loss:.3f}'),\n",
    "    verbose=True,\n",
    "    save_top_k=2,\n",
    "    period=.25\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(default_save_path=str(DIR_BK_CHECKPOINTS),\n",
    "                     checkpoint_callback=ckpt,\n",
    "                     max_epochs=1,\n",
    "                     logger=logger,\n",
    "                     val_check_interval=0.25,\n",
    "                     )\n",
    "\n",
    "model = LitPredNet.load_from_checkpoint(\n",
    "    str(ckpt_dir / 'bk_i3d_global_step=00671_epoch=001_val_loss=0.329.ckpt'))\n",
    "model.ds = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425b5e2e3432490eaf7a3f49d807ea76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02abb9bb4738462bb18768c35ded000a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b630180fa9ff4041a4d61dc0b5e6f422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.current_epoch = 0\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
