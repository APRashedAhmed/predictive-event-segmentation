{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.2 Running Prednet on Full I3D Data\n",
    "\n",
    "The previous notebook was only running on some of the I3D data. This one will use all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 06 2020 17:26:58 \n",
      "\n",
      "CPython 3.6.10\n",
      "IPython 7.12.0\n",
      "\n",
      "torch 1.2.0\n",
      "torchvision 0.1.8\n",
      "cv2 3.4.2\n",
      "h5py 2.8.0\n",
      "pandas 1.0.1\n",
      "matplotlib 3.1.3\n",
      "seaborn 0.10.0\n",
      "jupyterlab 1.2.6\n",
      "lab 0+untagged.38.g6a19aca.dirty\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-76-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "Git hash   : 6a19aca9e16ed91aaf852f0914eb45b18ea68d92\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and packages. Add more as necessary.\n",
    "%watermark -v -n -m -g -b -t -p torch,torchvision,cv2,h5py,pandas,matplotlib,seaborn,jupyterlab,lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the GPU\n",
    "\n",
    "Make sure we aren't greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar  6 17:27:10 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 28%   48C    P2    69W / 250W |   9399MiB / 12196MiB |     31%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 39%   64C    P2   126W / 250W |  12037MiB / 12196MiB |     40%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 43%   70C    P2   110W / 250W |  12037MiB / 12196MiB |     34%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 37%   51C    P8    11W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN Xp            Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 23%   31C    P8     8W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN Xp            Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 36%   58C    P2    82W / 250W |  12037MiB / 12196MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN Xp            Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 27%   47C    P2    61W / 250W |   9399MiB / 12196MiB |      8%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN Xp            Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 32%   51C    P2    65W / 250W |   3309MiB / 12196MiB |     21%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     13544      C   python                                      9389MiB |\n",
      "|    1     26564      C   python                                     12027MiB |\n",
      "|    2      7023      C   python                                     12027MiB |\n",
      "|    5      8557      C   python                                     12027MiB |\n",
      "|    6      9519      C   python                                      9389MiB |\n",
      "|    7     27219      C   python                                      3299MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to be used throughout the package\n",
    "%aimport lab\n",
    "import lab\n",
    "%aimport lab.index\n",
    "from lab.index import DIR_DATA_INT, DIR_DATA_RAW\n",
    "%aimport lab.breakfast\n",
    "import lab.breakfast as bk\n",
    "%aimport lab.breakfast.constants\n",
    "from lab.breakfast.constants import SEED\n",
    "# Import the data subdirectories\n",
    "%aimport lab.breakfast.index\n",
    "from lab.breakfast.index import (DIR_BREAKFAST, \n",
    "                                 DIR_BREAKFAST_DATA, \n",
    "                                 DIR_COARSE_SEG, \n",
    "                                 DIR_FINE_SEG,\n",
    "                                 DIR_BK_WEIGHTS,\n",
    "                                 DIR_BK_CHECKPOINTS,\n",
    "                                )\n",
    "%aimport lab.breakfast.prednet\n",
    "from lab.breakfast.prednet import PredNet\n",
    "%aimport lab.breakfast.dataloader\n",
    "from lab.breakfast.dataloader import Breakfast64DimFVDataset, BreakfastI3DFVDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set [seaborn defaults](https://seaborn.pydata.org/generated/seaborn.set.html) for matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running with I3D Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader et al\n",
    "\n",
    "Loading the Dataloader which now has all the I3D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 2min 7s, total: 2min 18s\n",
      "Wall time: 8min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = BreakfastI3DFVDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "\n",
    "ds_length = len(ds)\n",
    "indices = list(range(ds_length))\n",
    "batch_size = 256\n",
    "n_test = np.maximum(batch_size, 128)\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[n_test:], indices[:n_test]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = DataLoader(ds, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader = DataLoader(ds, batch_size=batch_size, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, layer_loss_weights, time_loss_weights\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredNet(\n",
      "  (cell0): LSTM(\n",
      "    (i2h): Linear(in_features=4096, out_features=8192, bias=True)\n",
      "    (h2h): Linear(in_features=2048, out_features=8192, bias=True)\n",
      "  )\n",
      "  (cell1): LSTM(\n",
      "    (i2h): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "    (h2h): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  )\n",
      "  (cell2): LSTM(\n",
      "    (i2h): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    (h2h): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  )\n",
      "  (cell3): LSTM(\n",
      "    (i2h): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (h2h): Linear(in_features=256, out_features=1024, bias=True)\n",
      "  )\n",
      "  (dense0): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (satlu): SatLU (min_val=0, max_val=255)\n",
      "  )\n",
      "  (dense1): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (dense2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (dense3): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  (update_A0): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  )\n",
      "  (update_A1): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (update_A2): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "Using GPU.\n",
      "Running with batch size 256 (168 iterations / epoch)\n",
      "Epoch: 0/50, train_error: 1.9074725334843, test error: 0.773500382900238\n",
      "Epoch: 2/50, train_error: 0.4720642301475718, test error: 0.3122563660144806\n",
      "Epoch: 4/50, train_error: 0.24911149138850824, test error: 0.208693265914917\n",
      "Epoch: 6/50, train_error: 0.18568881991363706, test error: 0.17032761871814728\n",
      "Epoch: 8/50, train_error: 0.1571921913308047, test error: 0.1495024859905243\n",
      "Epoch: 10/50, train_error: 0.17457022548963627, test error: 0.1684287190437317\n",
      "Epoch: 12/50, train_error: 0.1567716719582677, test error: 0.15046148002147675\n",
      "Epoch: 14/50, train_error: 0.14447580898801485, test error: 0.14102992415428162\n",
      "Epoch: 16/50, train_error: 0.13680942782333919, test error: 0.134347602725029\n",
      "Epoch: 18/50, train_error: 0.13110451265016482, test error: 0.1292082965373993\n",
      "Epoch: 20/50, train_error: 0.12677834351502715, test error: 0.12539497017860413\n",
      "Epoch: 22/50, train_error: 0.12322344406995744, test error: 0.12183395028114319\n",
      "Epoch: 24/50, train_error: 0.1202163825343762, test error: 0.11942336708307266\n",
      "Epoch: 26/50, train_error: 0.11705443750889528, test error: 0.11727509647607803\n",
      "Epoch: 28/50, train_error: 0.11617913904289405, test error: 0.11647845804691315\n",
      "Epoch: 30/50, train_error: 0.1153341602933194, test error: 0.11561155319213867\n",
      "Epoch: 32/50, train_error: 0.11447358104799475, test error: 0.11482332646846771\n",
      "Epoch: 34/50, train_error: 0.11361247749023494, test error: 0.11396307498216629\n",
      "Epoch: 36/50, train_error: 0.11278041190512124, test error: 0.11321256309747696\n",
      "Epoch: 38/50, train_error: 0.11195805877269734, test error: 0.11253185570240021\n",
      "Epoch: 40/50, train_error: 0.11119560145639948, test error: 0.11171168088912964\n",
      "Epoch: 42/50, train_error: 0.11045544146604482, test error: 0.1112091913819313\n",
      "Epoch: 44/50, train_error: 0.10977093480704796, test error: 0.1104920357465744\n",
      "Epoch: 46/50, train_error: 0.10914476936505664, test error: 0.11001738160848618\n",
      "Epoch: 48/50, train_error: 0.10852465563498083, test error: 0.10960065573453903\n",
      "CPU times: user 11h 26min 22s, sys: 11h 20min 43s, total: 22h 47min 5s\n",
      "Wall time: 4h 11min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_epochs = 50\n",
    "n_layers = 4\n",
    "input_size = 2048\n",
    "nt = 64 # num of time steps\n",
    "A_channels = tuple(input_size // (2**i) for i in range(n_layers))\n",
    "R_channels = tuple(input_size // (2**i) for i in range(n_layers))\n",
    "lr = 0.000333 # if epoch < 75 else 0.0001\n",
    "\n",
    "path_checkpoint = DIR_BK_CHECKPOINTS / 'i3d_checkpoint.tar'\n",
    "path_weights = DIR_BK_WEIGHTS / 'i3d_training.pt'\n",
    "\n",
    "layer_loss_weights = Variable(torch.FloatTensor([[1.]] + [[0.]]*(n_layers-1)).cuda())\n",
    "time_loss_weights = 1./(nt - 1) * torch.ones(nt, 1)\n",
    "time_loss_weights[0] = 0\n",
    "time_loss_weights = Variable(time_loss_weights.cuda())\n",
    "\n",
    "model = PredNet(R_channels, A_channels, output_mode='error')\n",
    "print(model)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU.')\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def lr_scheduler(optimizer, epoch):\n",
    "    if epoch < num_epochs // 2:\n",
    "        return optimizer\n",
    "    else:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.0001\n",
    "        return optimizer\n",
    "    \n",
    "train_errors = []\n",
    "\n",
    "print(f'Running with batch size {batch_size} ({ds_length//batch_size} iterations / epoch)')\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    optimizer = lr_scheduler(optimizer, epoch)\n",
    "    for batch_idx, (data, path) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, nt), self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        train_errors.append(errors.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        errors.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        test_errors = []\n",
    "        for data, path in test_loader:\n",
    "            data = Variable(data)\n",
    "            errors = model(data) # batch x n_layers x nt\n",
    "            loc_batch = errors.size(0)\n",
    "            errors = torch.mm(errors.view(-1, nt), time_loss_weights) # batch*n_layers x 1\n",
    "            errors = torch.mm(errors.view(loc_batch, -1), layer_loss_weights)\n",
    "            test_errors.append(torch.mean(errors, axis=0).item())\n",
    "            \n",
    "        test_error = np.mean(test_errors)\n",
    "        train_error = np.mean(train_errors)\n",
    "        print(f'Epoch: {epoch}/{num_epochs}, train_error: {train_error}, '\n",
    "              f'test error: {test_error}')\n",
    "        train_errors = []\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'errors': errors,\n",
    "        }, str(path_checkpoint))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), str(path_weights))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
