{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.1 Evaluating Hidden States\n",
    "\n",
    "Adding functionality to view hidden state activity through a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 14 2020 17:03:24 \n",
      "\n",
      "CPython 3.8.2\n",
      "IPython 7.13.0\n",
      "\n",
      "torch 1.4.0\n",
      "torchvision 0.5.0\n",
      "pytorch_lightning 0.7.1\n",
      "jupyterlab 2.0.1\n",
      "prevseg 0+untagged.3.g0d5d858.dirty\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.3.0-40-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 0d5d85837d960f44f051813577e82bb2fc4fea9b\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and packages. Add more as necessary.\n",
    "%watermark -v -n -m -g -b -t -p torch,torchvision,pytorch_lightning,jupyterlab,prevseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from functools import wraps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F, GRU\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to be used throughout the package\n",
    "%aimport prevseg\n",
    "import prevseg as pes\n",
    "%aimport prevseg.index\n",
    "from prevseg import index\n",
    "# Import the data subdirectories\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as prednet\n",
    "%aimport prevseg.dataloaders.breakfast\n",
    "import prevseg.dataloaders.breakfast as bk\n",
    "from prevseg.torch.lstm import LSTM\n",
    "from prevseg.torch.activations import SatLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the GPU\n",
    "\n",
    "Make sure we aren't greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvidia-smi: not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model as it Stands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = {\n",
    "    'model_name' : 'prednet',\n",
    "    'n_layers' : 4,\n",
    "    'input_size' : 2048,\n",
    "    'time_steps' : 64,\n",
    "    'dir_checkpoints' : str(index.DIR_CHECKPOINTS),\n",
    "    'dir_weights' : str(index.DIR_WEIGHTS),\n",
    "    'dir_logs' : str(index.DIR_LOGS_TB),\n",
    "    'lr' : 0.000333,\n",
    "    'output_mode' : 'error',\n",
    "    'device' : 'cuda',\n",
    "    'n_val' : 256,\n",
    "    'seed' : 117,\n",
    "    'batch_size' : 256,\n",
    "    'n_epochs' : 10,\n",
    "    'n_workers' : 4,\n",
    "    'layer_loss_mode' : 'first',\n",
    "}\n",
    "hparams = Namespace(**hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "model = prednet.PredNet(Namespace(**hps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `wb-1.2.0` for the implementation at work, but below is the relevant portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "class PredCell(object):\n",
    "    \"\"\"Organizational class.\"\"\"\n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels, \n",
    "                 RecurrentClass=LSTM):\n",
    "        super().__init__()\n",
    "        self.parent = parent\n",
    "        self.layer_num = layer_num\n",
    "        self.hparams = hparams\n",
    "        self.a_channels = a_channels\n",
    "        self.r_channels = r_channels\n",
    "        self.RecurrentClass = RecurrentClass\n",
    "        \n",
    "        # Reccurent\n",
    "        self.recurrent = self.build_recurrent()\n",
    "        # Dense\n",
    "        self.dense = self.build_dense()\n",
    "        # Update\n",
    "        self.update_a = self.build_update()\n",
    "        # upsample - set at cell level for future\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        # Build E, R, and H\n",
    "        self.reset()\n",
    "        # Book-keeping\n",
    "        self.update_parent()\n",
    "            \n",
    "    def build_recurrent(self):\n",
    "        recurrent = self.RecurrentClass(\n",
    "            2 * (self.a_channels[self.layer_num] +\n",
    "                 self.r_channels[self.layer_num+1]),\n",
    "            #+ self.r_channels[self.layer_num+1],\n",
    "            self.r_channels[self.layer_num])\n",
    "        recurrent.reset_parameters()\n",
    "        return recurrent\n",
    "    \n",
    "    def build_dense(self):\n",
    "        dense = nn.Sequential(\n",
    "            nn.Linear(self.r_channels[self.layer_num],\n",
    "                      self.a_channels[self.layer_num]),\n",
    "            nn.ReLU())\n",
    "        if self.layer_num == 0:\n",
    "            dense.add_module('satlu', SatLU())\n",
    "        return dense\n",
    "        \n",
    "    def build_update(self):\n",
    "        if self.layer_num < self.hparams.n_layers - 1:\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    2 * self.a_channels[self.layer_num],\n",
    "                    self.a_channels[self.layer_num + 1]),\n",
    "                nn.ReLU())\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def reset(self, batch_size=None):\n",
    "        batch_size = batch_size or self.hparams.batch_size\n",
    "        # E, R, and H variables\n",
    "        self.E = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             2*self.a_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.R = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             self.r_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.H = None\n",
    "        \n",
    "    def update_parent(self):\n",
    "        self.modules = {'recurrent' : self.recurrent, 'dense' : self.dense}\n",
    "        if hasattr(self, 'update_a') and self.update_a is not None:\n",
    "            self.modules['update_a'] = self.update_a\n",
    "        # Hack to appease the pytorch-gods\n",
    "        for name, module in self.modules.items():\n",
    "            setattr(self.parent, f'predcell_{self.layer_num}_{name}', module)\n",
    "\n",
    "\n",
    "class PredNet(pl.LightningModule):\n",
    "    name = 'prednet'\n",
    "    def __init__(self, hparams, ds=None, CellClass=PredCell):\n",
    "        super().__init__()\n",
    "        # Attribute definitions\n",
    "        self.hparams = hparams\n",
    "        self.n_layers = self.hparams.n_layers\n",
    "        self.output_mode = self.hparams.output_mode\n",
    "        self.input_size = self.hparams.input_size\n",
    "        self.time_steps = self.hparams.time_steps\n",
    "        self.batch_size = self.hparams.batch_size\n",
    "        self.layer_loss_mode = self.hparams.layer_loss_mode\n",
    "        self.ds = ds\n",
    "        self.CellClass = CellClass\n",
    "        \n",
    "        if self.hparams.device == 'cuda' and torch.cuda.is_available():\n",
    "            print('Using GPU', flush=True)\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            print('Using CPU', flush=True)\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        # Put together the model\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):        \n",
    "        # Channel sizes\n",
    "        self.r_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)] + [0,] # Convenience\n",
    "        self.a_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)]\n",
    "        \n",
    "        # Make sure everything checks out\n",
    "        default_output_modes = ['prediction', 'error']\n",
    "        assert self.output_mode in default_output_modes, \\\n",
    "            'Invalid output_mode: ' + str(output_mode)\n",
    "\n",
    "        # Make all the pred cells\n",
    "        self.predcells = [self.CellClass(self,\n",
    "                                         layer_num,\n",
    "                                         self.hparams,\n",
    "                                         self.a_channels,\n",
    "                                         self.r_channels)\n",
    "                          for layer_num in range(self.n_layers)]\n",
    "        \n",
    "        # How to weight the errors\n",
    "        # 1 followed by zeros means just minimize error at lowest layer\n",
    "        self.layer_loss_weights = self.build_layer_loss_weights(\n",
    "            self.layer_loss_mode)\n",
    "        # How much to weight errors at each timestep\n",
    "        self.time_loss_weights = self.build_time_loss_weights()\n",
    "        \n",
    "    def build_layer_loss_weights(self, mode='first'):\n",
    "        if mode == 'first':\n",
    "            first = torch.zeros(self.n_layers, 1, device=self.device)\n",
    "            first[0][0] = 1\n",
    "            return first\n",
    "        elif mode == 'all':\n",
    "            return 1. / (self.n_layer-1) * torch.ones(self.n_layer, 1,\n",
    "                                                      device=self.device)\n",
    "        else:\n",
    "            raise Exception(f'Invalid layer loss mode \"{mode}\".')\n",
    "            \n",
    "    def build_time_loss_weights(self, time_steps=None):\n",
    "        time_steps = time_steps or self.time_steps\n",
    "        # How much to weight errors at each timestep\n",
    "        time_loss_weights = 1. / (time_steps-1) * torch.ones(time_steps, 1,\n",
    "                                                             device=self.device)\n",
    "        # Dont count first time step\n",
    "        time_loss_weights[0] = 0\n",
    "        return time_loss_weights\n",
    "    \n",
    "    def check_input_shape(self, input):\n",
    "        batch_size, time_steps, *input_size = input.shape\n",
    "        \n",
    "        # Reset batch_size-dependent things\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "            for cell in self.predcells:\n",
    "                cell.reset(self.batch_size)\n",
    "                \n",
    "        # Reset time_step-dependent things\n",
    "        if time_steps != self.time_steps:\n",
    "            self.time_steps = time_steps\n",
    "            self.time_loss_weights = self.build_time_loss_weights(\n",
    "                self.time_steps)\n",
    "            \n",
    "        return batch_size, time_steps, *input_size\n",
    "    \n",
    "    def top_down_pass(self, t):\n",
    "        # Loop backwards\n",
    "        for l, cell in reversed(list(enumerate(self.predcells))):\n",
    "            E, R = cell.E, cell.R\n",
    "            # First time step\n",
    "            if t == 0:\n",
    "                hx = (R, R)\n",
    "            else:\n",
    "                hx = cell.H\n",
    "\n",
    "            # If not in the last layer, upsample R and\n",
    "            if l < self.n_layers - 1:\n",
    "                E = torch.cat((E,  cell.upsample(self.predcells[l+1].R)), 2)\n",
    "\n",
    "            cell.R, cell.H = cell.recurrent(E, hx)\n",
    "            \n",
    "    def bottom_up_pass(self):\n",
    "        for cell in self.predcells:\n",
    "            # Go from R to A_hat\n",
    "            A_hat = cell.dense(cell.R)\n",
    "\n",
    "            # Convenience\n",
    "            if self.output_mode == 'prediction' and cell.layer_num == 0:\n",
    "                self.frame_prediction = A_hat\n",
    "\n",
    "            # Split to 2 Es\n",
    "            pos = F.relu(A_hat - self.A)\n",
    "            neg = F.relu(self.A - A_hat)\n",
    "            E = torch.cat([pos, neg], 2)\n",
    "            cell.E = E\n",
    "\n",
    "            # If not last layer, update stored A\n",
    "            if cell.layer_num < self.n_layers - 1:\n",
    "                self.A = cell.update_a(E)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        total_error = []\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            self.A = input[:,t,:].unsqueeze(0).to(self.device, torch.float)\n",
    "            \n",
    "            # Loop from top layer to update R and H\n",
    "            self.top_down_pass(t)\n",
    "            # Loop bottom up to get E and A\n",
    "            self.bottom_up_pass()\n",
    "            \n",
    "            if self.output_mode == 'error':\n",
    "                mean_error = torch.cat(\n",
    "                    [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                                1, keepdim=True)\n",
    "                     for cell in self.predcells], 1)\n",
    "                # batch x n_layers\n",
    "                total_error.append(mean_error)\n",
    "        \n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return self.frame_prediction\n",
    "\n",
    "    def timeit(method):\n",
    "        \"\"\"Combination of https://stackoverflow.com/questions/51503672/decorator-for-timeit-timeit-method/51503837#51503837,\n",
    "        and https://www.geeksforgeeks.org/python-program-to-convert-seconds-into-hours-minutes-and-seconds/\"\"\"\n",
    "        @wraps(method)\n",
    "        def _time_it(self, *args, **kwargs):\n",
    "            start = int(round(time.time() * 1000))\n",
    "            try:\n",
    "                return method(self, *args, **kwargs)\n",
    "            finally:\n",
    "                end_ = int(round(time.time() * 1000)) - start\n",
    "                if end_ > 1000:\n",
    "                    time_str = time.strftime(\"%H:%M:%S\",\n",
    "                                             time.gmtime(end_ // 1000))\n",
    "                    print(f\"Total execution time: {time_str}\", flush=True)\n",
    "                \n",
    "        return _time_it\n",
    "\n",
    "    @timeit\n",
    "    def prepare_data(self):\n",
    "        if self.ds is None:\n",
    "            print('Loading the i3d data from disk. This can take '\n",
    "                  'several minutes...', flush=True)\n",
    "        self.ds = self.ds or BreakfastI3DFVDataset()\n",
    "        self.ds_length = len(self.ds)\n",
    "        np.random.seed(self.hparams.seed)\n",
    "        self.indices = list(range(self.ds_length))\n",
    "        self.train_sampler = SubsetRandomSampler(\n",
    "            self.indices[self.hparams.n_val:])\n",
    "        self.val_sampler = SubsetRandomSampler(\n",
    "            self.indices[:self.hparams.n_val])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.train_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.val_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data, path = batch\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        self.logger.experiment.add_scalar(f'{prefix}loss', \n",
    "                                          errors, self.global_step)\n",
    "        return {f'{prefix}loss' : errors}\n",
    "\n",
    "    def validation_epoch_end(self, output):\n",
    "        out_dict = {}\n",
    "        out_dict['val_loss'] = np.mean([out['val_loss'].item()\n",
    "                                        for out in output])\n",
    "        out_dict['global_step'] = self.global_step\n",
    "        return out_dict\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'train')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'val')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Hidden State Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-e6468eba09b8>, line 84)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-e6468eba09b8>\"\u001b[0;36m, line \u001b[0;32m84\u001b[0m\n\u001b[0;31m    self..hidden_full_list.append(cell.H.view(1, 0, 2))\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class PredCellTracked(prednet.Predcell):\n",
    "    \"\"\"Organizational class.\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Tracking\n",
    "        self.hidden_full_list = []\n",
    "        self.hidden_diff_list = []\n",
    "        self.previous_hidden = None\n",
    "        self.previous_error = None\n",
    "            \n",
    "    def update_hidden_tracking(self, output_mode, H):\n",
    "        # Track hidden states if desired\n",
    "        if output_mode == 'hidden_full':\n",
    "            self.hidden_full_list.append(cell.H.view(1, 0, 2))\n",
    "        elif output_mode == 'hidden_diff':\n",
    "            self.hidden_diff_list.append()\n",
    "            \n",
    "    def update_error_tracking(self, output_mode, E):\n",
    "        # Track hidden states if desired\n",
    "        if output_mode == 'error_full':\n",
    "            self.error_full_list.append(cell.H.view(1, 0, 2))\n",
    "        elif output_mode == 'error_diff':\n",
    "            self.error_diff_list.append()\n",
    "\n",
    "            \n",
    "\n",
    "class PredNetTracked(prednet.PredNet):\n",
    "    def top_down_pass(self, t):\n",
    "        # Loop backwards\n",
    "        for l, cell in reversed(list(enumerate(self.predcells))):\n",
    "            E, R = cell.E, cell.R\n",
    "            # First time step\n",
    "            if t == 0:\n",
    "                hx = (R, R)\n",
    "            else:\n",
    "                hx = cell.H\n",
    "\n",
    "            # If not in the last layer, upsample R and\n",
    "            if l < self.n_layers - 1:\n",
    "                E = torch.cat((E,  cell.upsample(self.predcells[l+1].R)), 2)\n",
    "\n",
    "            # Update the values of R and H\n",
    "            cell.R, cell.H = cell.recurrent(E, hx)\n",
    "\n",
    "            # Optional tracking\n",
    "            cell.update_tracking(self.output_mode)\n",
    "            \n",
    "    def bottom_up_pass(self):\n",
    "        for cell in self.predcells:\n",
    "            # Go from R to A_hat\n",
    "            A_hat = cell.dense(cell.R)\n",
    "\n",
    "            # Convenience\n",
    "            if self.output_mode == 'prediction' and cell.layer_num == 0:\n",
    "                self.frame_prediction = A_hat\n",
    "\n",
    "            # Split to 2 Es\n",
    "            pos = F.relu(A_hat - self.A)\n",
    "            neg = F.relu(self.A - A_hat)\n",
    "            E = torch.cat([pos, neg], 2)\n",
    "            \n",
    "            # Optional Error tracking\n",
    "            self.update_error_tracking(self.output_mode, E)\n",
    "            cell.E = E\n",
    "\n",
    "            # If not last layer, update stored A\n",
    "            if cell.layer_num < self.n_layers - 1:\n",
    "                self.A = cell.update_a(E)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        self.total_error = []\n",
    "        \n",
    "        for t in range(time_steps):\n",
    "            self.A = input[:,t,:].unsqueeze(0).to(self.device, torch.float)\n",
    "            \n",
    "            # Loop from top layer to update R and H\n",
    "            self.top_down_pass(t)\n",
    "            # Loop bottom up to get E and A\n",
    "            self.bottom_up_pass()\n",
    "            \n",
    "            # Track desired outputs\n",
    "            self.track_outputs(self.output_mode)\n",
    "        \n",
    "        return self.return_output(self.output_mode)\n",
    "        \n",
    "    def track_outputs(self, output_mode):\n",
    "        if output_mode == 'error_mean':\n",
    "            mean_error = torch.cat(\n",
    "                [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                            1, keepdim=True)\n",
    "                 for cell in self.predcells], 1)\n",
    "            # batch x n_layers\n",
    "            self.total_error.append(mean_error)\n",
    "            \n",
    "    def return_output(self, output_mode):\n",
    "        if self.output_mode == 'error_mean':\n",
    "            return torch.stack(self.total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return self.frame_prediction\n",
    "        elif self.output_mdoe == 'hidden_full':\n",
    "            return [torch.cat(cell.hidden_full_list, 1)\n",
    "                   for cell in self.predcells]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "model = PredNet(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 2048])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predcells[1].E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
