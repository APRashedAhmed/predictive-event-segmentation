{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.1 Evaluating Hidden States\n",
    "\n",
    "Adding functionality to view hidden state activity through a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 15 2020 23:18:16 \n",
      "\n",
      "CPython 3.8.2\n",
      "IPython 7.13.0\n",
      "\n",
      "torch 1.4.0\n",
      "torchvision 0.5.0\n",
      "pytorch_lightning 0.7.1\n",
      "jupyterlab 2.0.1\n",
      "prevseg 0+untagged.5.g87a1cd1.dirty\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.4.0-174-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "Git hash   : 87a1cd1b781a87ca8be0c3d8bb6d617914da51c7\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and packages. Add more as necessary.\n",
    "%watermark -v -n -m -g -b -t -p torch,torchvision,pytorch_lightning,jupyterlab,prevseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from functools import wraps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F, GRU\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to be used throughout the package\n",
    "%aimport prevseg\n",
    "import prevseg as pes\n",
    "%aimport prevseg.index\n",
    "from prevseg import index\n",
    "# Import the data subdirectories\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as prednet\n",
    "%aimport prevseg.dataloaders.breakfast\n",
    "import prevseg.dataloaders.breakfast as bk\n",
    "from prevseg.torch.lstm import LSTM\n",
    "from prevseg.torch.activations import SatLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the GPU\n",
    "\n",
    "Make sure we aren't greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 15 23:18:48 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   23C    P8     7W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN X (Pascal)    Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 41%   70C    P2   159W / 250W |   9465MiB / 12196MiB |     95%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN X (Pascal)    Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 51%   84C    P2   156W / 250W |   9407MiB / 12196MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN X (Pascal)    Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 51%   83C    P2   120W / 250W |   3715MiB / 12196MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN X (Pascal)    Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 51%   84C    P2   173W / 250W |   8325MiB / 12196MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN X (Pascal)    Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 51%   84C    P2   173W / 250W |  11511MiB / 12196MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN X (Pascal)    Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 37%   62C    P2    87W / 250W |   5421MiB / 12196MiB |     12%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN X (Pascal)    Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 51%   85C    P2   220W / 250W |  11589MiB / 12196MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1     17145      C   python                                      9455MiB |\n",
      "|    2      6809      C   python                                      9397MiB |\n",
      "|    3     20831      C   python                                      3705MiB |\n",
      "|    4      6809      C   python                                      8315MiB |\n",
      "|    5     28429      C   python                                     11501MiB |\n",
      "|    6       313      C   python                                      5411MiB |\n",
      "|    7     28429      C   python                                     11579MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model as it Stands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment  Defaults\n",
    "DEFAULT_MODEL_NAME = 'prednet'\n",
    "DEFAULT_N_LAYERS = 4\n",
    "DEFAULT_INPUT_SIZE = 2048\n",
    "DEFAULT_TIME_STEPS = 64\n",
    "DEFAULT_LR = 0.000333\n",
    "DEFAULT_OUTPUT_MODE = 'error'\n",
    "DEFAULT_DEVICE = 'cuda'\n",
    "DEFAULT_N_TEST = 2\n",
    "DEFAULT_N_VAL = 256\n",
    "DEFAULT_SEED = 117\n",
    "DEFAULT_BATCH_SIZE = 256\n",
    "DEFAULT_N_EPOCHS = 10\n",
    "DEFAULT_N_WORKERS = 4\n",
    "DEFAULT_LAYER_LOSS_MODE = 'first'\n",
    "\n",
    "from prevseg.dataloaders.breakfast import BreakfastI3DFVDataset\n",
    "DEFAULT_BK_DATALOADER = BreakfastI3DFVDataset\n",
    "\n",
    "hparams = Namespace(**{\n",
    "    'model_name' : DEFAULT_MODEL_NAME,\n",
    "    'n_layers' : DEFAULT_N_LAYERS,\n",
    "    'input_size' : DEFAULT_INPUT_SIZE,\n",
    "    'time_steps' : DEFAULT_TIME_STEPS,\n",
    "    'dir_checkpoints' : str(index.DIR_CHECKPOINTS),\n",
    "    'dir_weights' : str(index.DIR_WEIGHTS),\n",
    "    'dir_logs' : str(index.DIR_LOGS_TB),\n",
    "    'lr' : DEFAULT_LR,\n",
    "    'output_mode' : DEFAULT_OUTPUT_MODE,\n",
    "    'device' : DEFAULT_DEVICE,\n",
    "    'n_test' : DEFAULT_N_TEST,\n",
    "    'n_val' : DEFAULT_N_VAL,\n",
    "    'seed' : DEFAULT_SEED,\n",
    "    'batch_size' : DEFAULT_BATCH_SIZE,\n",
    "    'n_epochs' : DEFAULT_N_EPOCHS,\n",
    "    'n_workers' : DEFAULT_N_WORKERS,\n",
    "    'layer_loss_mode' : DEFAULT_LAYER_LOSS_MODE,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "model = prednet.PredNet(Namespace(**hps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 29min 4s, total: 29min 17s\n",
      "Wall time: 39min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = bk.BreakfastI3DFVDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `wb-1.2.0` for the implementation at work, but below is the relevant portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "class PredCell(object):\n",
    "    \"\"\"Organizational class.\"\"\"\n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels, \n",
    "                 RecurrentClass=LSTM):\n",
    "        super().__init__()\n",
    "        self.parent = parent\n",
    "        self.layer_num = layer_num\n",
    "        self.hparams = hparams\n",
    "        self.a_channels = a_channels\n",
    "        self.r_channels = r_channels\n",
    "        self.RecurrentClass = RecurrentClass\n",
    "        \n",
    "        # Reccurent\n",
    "        self.recurrent = self.build_recurrent()\n",
    "        # Dense\n",
    "        self.dense = self.build_dense()\n",
    "        # Update\n",
    "        self.update_a = self.build_update()\n",
    "        # upsample - set at cell level for future\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        # Build E, R, and H\n",
    "        self.reset()\n",
    "        # Book-keeping\n",
    "        self.update_parent()\n",
    "            \n",
    "    def build_recurrent(self):\n",
    "        recurrent = self.RecurrentClass(\n",
    "            2 * (self.a_channels[self.layer_num] +\n",
    "                 self.r_channels[self.layer_num+1]),\n",
    "            #+ self.r_channels[self.layer_num+1],\n",
    "            self.r_channels[self.layer_num])\n",
    "        recurrent.reset_parameters()\n",
    "        return recurrent\n",
    "    \n",
    "    def build_dense(self):\n",
    "        dense = nn.Sequential(\n",
    "            nn.Linear(self.r_channels[self.layer_num],\n",
    "                      self.a_channels[self.layer_num]),\n",
    "            nn.ReLU())\n",
    "        if self.layer_num == 0:\n",
    "            dense.add_module('satlu', SatLU())\n",
    "        return dense\n",
    "        \n",
    "    def build_update(self):\n",
    "        if self.layer_num < self.hparams.n_layers - 1:\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    2 * self.a_channels[self.layer_num],\n",
    "                    self.a_channels[self.layer_num + 1]),\n",
    "                nn.ReLU())\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def reset(self, batch_size=None):\n",
    "        batch_size = batch_size or self.hparams.batch_size\n",
    "        # E, R, and H variables\n",
    "        self.E = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             2*self.a_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.R = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             self.r_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.H = None\n",
    "        \n",
    "    def update_parent(self):\n",
    "        self.modules = {'recurrent' : self.recurrent, 'dense' : self.dense}\n",
    "        if hasattr(self, 'update_a') and self.update_a is not None:\n",
    "            self.modules['update_a'] = self.update_a\n",
    "        # Hack to appease the pytorch-gods\n",
    "        for name, module in self.modules.items():\n",
    "            setattr(self.parent, f'predcell_{self.layer_num}_{name}', module)\n",
    "\n",
    "\n",
    "class PredNet(pl.LightningModule):\n",
    "    name = 'prednet'\n",
    "    def __init__(self, hparams, ds=None, CellClass=PredCell):\n",
    "        super().__init__()\n",
    "        # Attribute definitions\n",
    "        self.hparams = hparams\n",
    "        self.n_layers = self.hparams.n_layers\n",
    "        self.output_mode = self.hparams.output_mode\n",
    "        self.input_size = self.hparams.input_size\n",
    "        self.time_steps = self.hparams.time_steps\n",
    "        self.batch_size = self.hparams.batch_size\n",
    "        self.layer_loss_mode = self.hparams.layer_loss_mode\n",
    "        self.ds = ds\n",
    "        self.CellClass = CellClass\n",
    "        \n",
    "        if self.hparams.device == 'cuda' and torch.cuda.is_available():\n",
    "            print('Using GPU', flush=True)\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            print('Using CPU', flush=True)\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        # Put together the model\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):        \n",
    "        # Channel sizes\n",
    "        self.r_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)] + [0,] # Convenience\n",
    "        self.a_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)]\n",
    "        \n",
    "        # Make sure everything checks out\n",
    "        default_output_modes = ['prediction', 'error']\n",
    "        assert self.output_mode in default_output_modes, \\\n",
    "            'Invalid output_mode: ' + str(output_mode)\n",
    "\n",
    "        # Make all the pred cells\n",
    "        self.predcells = [self.CellClass(self,\n",
    "                                         layer_num,\n",
    "                                         self.hparams,\n",
    "                                         self.a_channels,\n",
    "                                         self.r_channels)\n",
    "                          for layer_num in range(self.n_layers)]\n",
    "        \n",
    "        # How to weight the errors\n",
    "        # 1 followed by zeros means just minimize error at lowest layer\n",
    "        self.layer_loss_weights = self.build_layer_loss_weights(\n",
    "            self.layer_loss_mode)\n",
    "        # How much to weight errors at each timestep\n",
    "        self.time_loss_weights = self.build_time_loss_weights()\n",
    "        \n",
    "    def build_layer_loss_weights(self, mode='first'):\n",
    "        if mode == 'first':\n",
    "            first = torch.zeros(self.n_layers, 1, device=self.device)\n",
    "            first[0][0] = 1\n",
    "            return first\n",
    "        elif mode == 'all':\n",
    "            return 1. / (self.n_layer-1) * torch.ones(self.n_layer, 1,\n",
    "                                                      device=self.device)\n",
    "        else:\n",
    "            raise Exception(f'Invalid layer loss mode \"{mode}\".')\n",
    "            \n",
    "    def build_time_loss_weights(self, time_steps=None):\n",
    "        time_steps = time_steps or self.time_steps\n",
    "        # How much to weight errors at each timestep\n",
    "        time_loss_weights = 1. / (time_steps-1) * torch.ones(time_steps, 1,\n",
    "                                                             device=self.device)\n",
    "        # Dont count first time step\n",
    "        time_loss_weights[0] = 0\n",
    "        return time_loss_weights\n",
    "    \n",
    "    def check_input_shape(self, input):\n",
    "        batch_size, time_steps, *input_size = input.shape\n",
    "        \n",
    "        # Reset batch_size-dependent things\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "            for cell in self.predcells:\n",
    "                cell.reset(self.batch_size)\n",
    "                \n",
    "        # Reset time_step-dependent things\n",
    "        if time_steps != self.time_steps:\n",
    "            self.time_steps = time_steps\n",
    "            self.time_loss_weights = self.build_time_loss_weights(\n",
    "                self.time_steps)\n",
    "            \n",
    "        return batch_size, time_steps, *input_size\n",
    "    \n",
    "    def top_down_pass(self, t):\n",
    "        # Loop backwards\n",
    "        for l, cell in reversed(list(enumerate(self.predcells))):\n",
    "            E, R = cell.E, cell.R\n",
    "            # First time step\n",
    "            if t == 0:\n",
    "                hx = (R, R)\n",
    "            else:\n",
    "                hx = cell.H\n",
    "\n",
    "            # If not in the last layer, upsample R and\n",
    "            if l < self.n_layers - 1:\n",
    "                E = torch.cat((E,  cell.upsample(self.predcells[l+1].R)), 2)\n",
    "\n",
    "            cell.R, cell.H = cell.recurrent(E, hx)\n",
    "            \n",
    "    def bottom_up_pass(self):\n",
    "        for cell in self.predcells:\n",
    "            # Go from R to A_hat\n",
    "            A_hat = cell.dense(cell.R)\n",
    "\n",
    "            # Convenience\n",
    "            if self.output_mode == 'prediction' and cell.layer_num == 0:\n",
    "                self.frame_prediction = A_hat\n",
    "\n",
    "            # Split to 2 Es\n",
    "            pos = F.relu(A_hat - self.A)\n",
    "            neg = F.relu(self.A - A_hat)\n",
    "            E = torch.cat([pos, neg], 2)\n",
    "            cell.E = E\n",
    "\n",
    "            # If not last layer, update stored A\n",
    "            if cell.layer_num < self.n_layers - 1:\n",
    "                self.A = cell.update_a(E)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        total_error = []\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            self.A = input[:,t,:].unsqueeze(0).to(self.device, torch.float)\n",
    "            \n",
    "            # Loop from top layer to update R and H\n",
    "            self.top_down_pass(t)\n",
    "            # Loop bottom up to get E and A\n",
    "            self.bottom_up_pass()\n",
    "            \n",
    "            if self.output_mode == 'error':\n",
    "                mean_error = torch.cat(\n",
    "                    [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                                1, keepdim=True)\n",
    "                     for cell in self.predcells], 1)\n",
    "                # batch x n_layers\n",
    "                total_error.append(mean_error)\n",
    "        \n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return self.frame_prediction\n",
    "\n",
    "    def timeit(method):\n",
    "        \"\"\"Combination of https://stackoverflow.com/questions/51503672/decorator-for-timeit-timeit-method/51503837#51503837,\n",
    "        and https://www.geeksforgeeks.org/python-program-to-convert-seconds-into-hours-minutes-and-seconds/\"\"\"\n",
    "        @wraps(method)\n",
    "        def _time_it(self, *args, **kwargs):\n",
    "            start = int(round(time.time() * 1000))\n",
    "            try:\n",
    "                return method(self, *args, **kwargs)\n",
    "            finally:\n",
    "                end_ = int(round(time.time() * 1000)) - start\n",
    "                if end_ > 1000:\n",
    "                    time_str = time.strftime(\"%H:%M:%S\",\n",
    "                                             time.gmtime(end_ // 1000))\n",
    "                    print(f\"Total execution time: {time_str}\", flush=True)\n",
    "                \n",
    "        return _time_it\n",
    "\n",
    "    @timeit\n",
    "    def prepare_data(self):\n",
    "        if self.ds is None:\n",
    "            print('Loading the i3d data from disk. This can take '\n",
    "                  'several minutes...', flush=True)\n",
    "        self.ds = self.ds or BreakfastI3DFVDataset()\n",
    "        self.ds_length = len(self.ds)\n",
    "        np.random.seed(self.hparams.seed)\n",
    "        self.indices = list(range(self.ds_length))\n",
    "        self.train_sampler = SubsetRandomSampler(\n",
    "            self.indices[self.hparams.n_val:])\n",
    "        self.val_sampler = SubsetRandomSampler(\n",
    "            self.indices[:self.hparams.n_val])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.train_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.val_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data, path = batch\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        self.logger.experiment.add_scalar(f'{prefix}loss', \n",
    "                                          errors, self.global_step)\n",
    "        return {f'{prefix}loss' : errors}\n",
    "\n",
    "    def validation_epoch_end(self, output):\n",
    "        out_dict = {}\n",
    "        out_dict['val_loss'] = np.mean([out['val_loss'].item()\n",
    "                                        for out in output])\n",
    "        out_dict['global_step'] = self.global_step\n",
    "        return out_dict\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'train')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'val')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Hidden State Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PredCellTracked(prednet.PredCell):\n",
    "    \"\"\"Organizational class.\"\"\"\n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(parent, layer_num, hparams, a_channels, r_channels,\n",
    "                         *args, **kwargs)\n",
    "        # Tracking\n",
    "        self.hidden_full_list = []\n",
    "        self.hidden_diff_list = []\n",
    "        self.previous_hidden = None\n",
    "        self.previous_error = None\n",
    "\n",
    "    def track_hidden(self, output_mode, R):\n",
    "        # Track hidden states if desired\n",
    "        if 'hidden_full' in parent.track and parent.output_mode == 'eval':\n",
    "            self.hidden_full_list.append(R.view(1, 0, 2))\n",
    "        if 'hidden_diff' in parent.track and parent.output_mode == 'eval':\n",
    "            self.hidden_diff_list.append(torch.mean(\n",
    "                (R.view(1, 0, 2) - self.R.view(1, 0, 2))**2,\n",
    "                2))\n",
    "\n",
    "    def track_error(self, output_mode, E):\n",
    "        # Track hidden states if desired\n",
    "        if 'error_full' in parent.track and parent.output_mode == 'eval':\n",
    "            self.error_full_list.append(E.view(1, 0, 2))\n",
    "        if 'error_diff' in parent.track and parent.output_mode == 'eval':\n",
    "            self.error_diff_list.append(torch.mean(\n",
    "                (E.view(1, 0, 2) - self.E.view(1, 0, 2))**2,\n",
    "                2))\n",
    "            \n",
    "class PredNetTracked(prednet.PredNet):\n",
    "    name = 'prednet_tracked'\n",
    "    def __init__(self, hparams, track=None, CellClass=PredCellTracked, *args,\n",
    "                 **kwargs):\n",
    "        self.track = track or ['hidden_diff', 'error_diff']\n",
    "        super().__init__(hparams, CellClass=CellClass, *args, **kwargs)\n",
    "        \n",
    "    def top_down_pass(self, t):\n",
    "        # Loop backwards\n",
    "        for l, cell in reversed(list(enumerate(self.predcells))):\n",
    "            # First time step\n",
    "            if t == 0:\n",
    "                hx = (cell.R, cell.R)\n",
    "            else:\n",
    "                hx = cell.H\n",
    "\n",
    "            # If not in the last layer, upsample R and\n",
    "            if l < self.n_layers - 1:\n",
    "                cell.E = torch.cat((cell.E,  cell.upsample(\n",
    "                    self.predcells[l+1].R)), 2)\n",
    "\n",
    "            # Update the values of R and H\n",
    "            R, H = cell.recurrent(cell.E, hx)\n",
    "\n",
    "            # Optional tracking\n",
    "            cell.track_hidden(self.output_mode, R)\n",
    "\n",
    "            # Update cell state\n",
    "            cell.R, cell.H = R, H\n",
    "            \n",
    "    def bottom_up_pass(self):\n",
    "        for cell in self.predcells:\n",
    "            # Go from R to A_hat\n",
    "            A_hat = cell.dense(cell.R)\n",
    "\n",
    "            # Convenience\n",
    "            if self.output_mode == 'prediction' and cell.layer_num == 0:\n",
    "                self.frame_prediction = A_hat\n",
    "\n",
    "            # Split to 2 Es\n",
    "            pos = F.relu(A_hat - self.A)\n",
    "            neg = F.relu(self.A - A_hat)\n",
    "            E = torch.cat([pos, neg], 2)\n",
    "            \n",
    "            # Optional Error tracking\n",
    "            cell.track_error(self.output_mode, E)\n",
    "\n",
    "            # Update cell error\n",
    "            cell.E = E\n",
    "\n",
    "            # If not last layer, update stored A\n",
    "            if cell.layer_num < self.n_layers - 1:\n",
    "                self.A = cell.update_a(E)\n",
    "            \n",
    "    def forward(self, input, output_mode=None, track=None):\n",
    "        self.output_mode = output_mode or self.output_mode\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        self.total_error = []\n",
    "        \n",
    "        for t in range(time_steps):\n",
    "            self.A = input[:,t,:].unsqueeze(0).to(self.device, torch.float)\n",
    "            # Loop from top layer to update R and H\n",
    "            self.top_down_pass(t)\n",
    "            # Loop bottom up to get E and A\n",
    "            self.bottom_up_pass()\n",
    "            # Track desired outputs\n",
    "            self.track_outputs()\n",
    "        \n",
    "        return self.return_output()\n",
    "        \n",
    "    def track_outputs(self):\n",
    "        if self.output_mode == 'error':\n",
    "            mean_error = torch.cat(\n",
    "                [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                            1, keepdim=True)\n",
    "                 for cell in self.predcells], 1)\n",
    "            # batch x n_layers\n",
    "            self.total_error.append(mean_error)\n",
    "            \n",
    "    def return_output(self):\n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(self.total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return self.frame_prediction\n",
    "        elif self.output_mode == 'eval':\n",
    "            return self.eval_outputs()\n",
    "\n",
    "    def eval_outputs(self):\n",
    "        outputs = {}\n",
    "        for tracked in self.track:\n",
    "            outputs[tracked] = [getattr(cell, tracked+'_list')\n",
    "                                for cell in self.predcells]\n",
    "        return outputs\n",
    "\n",
    "    # def test_step(self, batch, batch_idx):\n",
    "    #     data, path = batch\n",
    "    #     tracked_states = self.forward(data, output_mode='eval')\n",
    "    #     return tracked_states\n",
    "\n",
    "    # def test_epoch_end(self, output):\n",
    "    #     for tracked in self.track:\n",
    "    #         for layer in self.n_layers:\n",
    "    #             for t in self.time_steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name, version=2)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / 'bk_i3d_{global_step:05d}_{epoch:03d}_{val_loss:.3f}'),\n",
    "    verbose=True,\n",
    "    save_top_k=2,\n",
    "    period=.25\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(default_save_path=str(DIR_BK_CHECKPOINTS),\n",
    "                     checkpoint_callback=ckpt,\n",
    "                     max_epochs=1,\n",
    "                     logger=logger,\n",
    "                     val_check_interval=0.25,\n",
    "                     )\n",
    "\n",
    "model = LitPredNet.load_from_checkpoint(\n",
    "    str(ckpt_dir / 'bk_i3d_global_step=00671_epoch=001_val_loss=0.329.ckpt'))\n",
    "model.ds = ds\n",
    "\n",
    "model = PredNetTracked(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
