{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.1 Tracking Hidden States\n",
    "\n",
    "Adding functionality to view hidden state activity through a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Wed Mar 18 2020 17:13:03 \n",
      "\n",
      "CPython 3.8.2\n",
      "IPython 7.13.0\n",
      "\n",
      "torch 1.4.0\n",
      "torchvision 0.5.0\n",
      "pytorch_lightning 0.7.1\n",
      "jupyterlab 2.0.1\n",
      "prevseg 0+untagged.11.g393f577.dirty\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-88-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "Git hash   : 393f5775d28aeec38742df7b2b394f0ae6179d2a\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and packages. Add more as necessary.\n",
    "%watermark -v -n -m -g -b -t -p torch,torchvision,pytorch_lightning,jupyterlab,prevseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from functools import wraps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F, GRU\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to be used throughout the package\n",
    "%aimport prevseg\n",
    "import prevseg as pes\n",
    "%aimport prevseg.index\n",
    "from prevseg import index\n",
    "# Import the data subdirectories\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as prednet\n",
    "%aimport prevseg.dataloaders.breakfast\n",
    "import prevseg.dataloaders.breakfast as bk\n",
    "%aimport prevseg.constants\n",
    "import prevseg.constants as const\n",
    "\n",
    "from prevseg.torch.lstm import LSTM\n",
    "from prevseg.torch.activations import SatLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the GPU\n",
    "\n",
    "Make sure we aren't greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 18 17:13:35 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 34%   57C    P2    84W / 250W |   9331MiB / 12196MiB |     14%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 26%   38C    P8     9W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 54%   84C    P2   246W / 250W |   8869MiB / 12196MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 44%   69C    P2    92W / 250W |   9493MiB / 12196MiB |      9%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN Xp            Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 53%   83C    P2   206W / 250W |  10425MiB / 12196MiB |     89%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN Xp            Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 35%   58C    P2    80W / 250W |   6405MiB / 12196MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN Xp            Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 46%   74C    P2   182W / 250W |   8875MiB / 12196MiB |     33%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN Xp            Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 54%   83C    P2   159W / 250W |  10473MiB / 12196MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4651      C   python                                      9321MiB |\n",
      "|    2     21522      C   python                                      8859MiB |\n",
      "|    3      1518      C   python                                      9483MiB |\n",
      "|    4     21522      C   python                                     10415MiB |\n",
      "|    5     14843      C   python                                      6395MiB |\n",
      "|    6     17508      C   python                                      8865MiB |\n",
      "|    7     17508      C   python                                     10463MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 8min 22s, total: 8min 36s\n",
      "Wall time: 15min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = bk.BreakfastI3DFVDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `wb-1.2.0` for the implementation at work, but below is the relevant portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "\n",
    "class PredCell(object):\n",
    "    \"\"\"Organizational class.\"\"\"\n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels, \n",
    "                 RecurrentClass=LSTM):\n",
    "        super().__init__()\n",
    "        self.parent = parent\n",
    "        self.layer_num = layer_num\n",
    "        self.hparams = hparams\n",
    "        self.a_channels = a_channels\n",
    "        self.r_channels = r_channels\n",
    "        self.RecurrentClass = RecurrentClass\n",
    "        \n",
    "        # Reccurent\n",
    "        self.recurrent = self.build_recurrent()\n",
    "        # Dense\n",
    "        self.dense = self.build_dense()\n",
    "        # Update\n",
    "        self.update_a = self.build_update()\n",
    "        # upsample - set at cell level for future\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        # Build E, R, and H\n",
    "        self.reset()\n",
    "        # Book-keeping\n",
    "        self.update_parent()\n",
    "            \n",
    "    def build_recurrent(self):\n",
    "        recurrent = self.RecurrentClass(\n",
    "            2 * (self.a_channels[self.layer_num] +\n",
    "                 self.r_channels[self.layer_num+1]),\n",
    "            #+ self.r_channels[self.layer_num+1],\n",
    "            self.r_channels[self.layer_num])\n",
    "        recurrent.reset_parameters()\n",
    "        return recurrent\n",
    "    \n",
    "    def build_dense(self):\n",
    "        dense = nn.Sequential(\n",
    "            nn.Linear(self.r_channels[self.layer_num],\n",
    "                      self.a_channels[self.layer_num]),\n",
    "            nn.ReLU())\n",
    "        if self.layer_num == 0:\n",
    "            dense.add_module('satlu', SatLU())\n",
    "        return dense\n",
    "        \n",
    "    def build_update(self):\n",
    "        if self.layer_num < self.hparams.n_layers - 1:\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    2 * self.a_channels[self.layer_num],\n",
    "                    self.a_channels[self.layer_num + 1]),\n",
    "                nn.ReLU())\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def reset(self, batch_size=None):\n",
    "        batch_size = batch_size or self.hparams.batch_size\n",
    "        # E, R, and H variables\n",
    "        self.E = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             2*self.a_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.R = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             self.r_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.H = None\n",
    "        \n",
    "    def update_parent(self):\n",
    "        self.modules = {'recurrent' : self.recurrent, 'dense' : self.dense}\n",
    "        if hasattr(self, 'update_a') and self.update_a is not None:\n",
    "            self.modules['update_a'] = self.update_a\n",
    "        # Hack to appease the pytorch-gods\n",
    "        for name, module in self.modules.items():\n",
    "            setattr(self.parent, f'predcell_{self.layer_num}_{name}', module)\n",
    "\n",
    "\n",
    "class PredNet(pl.LightningModule):\n",
    "    name = 'prednet'\n",
    "    def __init__(self, hparams, ds=None, CellClass=PredCell):\n",
    "        super().__init__()\n",
    "        # Attribute definitions\n",
    "        self.hparams = hparams\n",
    "        self.n_layers = self.hparams.n_layers\n",
    "        self.output_mode = self.hparams.output_mode\n",
    "        self.input_size = self.hparams.input_size\n",
    "        self.time_steps = self.hparams.time_steps\n",
    "        self.batch_size = self.hparams.batch_size\n",
    "        self.layer_loss_mode = self.hparams.layer_loss_mode\n",
    "        self.ds = ds\n",
    "        self.CellClass = CellClass\n",
    "        \n",
    "        if self.hparams.device == 'cuda' and torch.cuda.is_available():\n",
    "            print('Using GPU', flush=True)\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            print('Using CPU', flush=True)\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        # Put together the model\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):        \n",
    "        # Channel sizes\n",
    "        self.r_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)] + [0,] # Convenience\n",
    "        self.a_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)]\n",
    "        \n",
    "        # Make sure everything checks out\n",
    "        default_output_modes = ['prediction', 'error']\n",
    "        assert self.output_mode in default_output_modes, \\\n",
    "            'Invalid output_mode: ' + str(output_mode)\n",
    "\n",
    "        # Make all the pred cells\n",
    "        self.predcells = [self.CellClass(self,\n",
    "                                         layer_num,\n",
    "                                         self.hparams,\n",
    "                                         self.a_channels,\n",
    "                                         self.r_channels)\n",
    "                          for layer_num in range(self.n_layers)]\n",
    "        \n",
    "        # How to weight the errors\n",
    "        # 1 followed by zeros means just minimize error at lowest layer\n",
    "        self.layer_loss_weights = self.build_layer_loss_weights(\n",
    "            self.layer_loss_mode)\n",
    "        # How much to weight errors at each timestep\n",
    "        self.time_loss_weights = self.build_time_loss_weights()\n",
    "        \n",
    "    def build_layer_loss_weights(self, mode='first'):\n",
    "        if mode == 'first':\n",
    "            first = torch.zeros(self.n_layers, 1, device=self.device)\n",
    "            first[0][0] = 1\n",
    "            return first\n",
    "        elif mode == 'all':\n",
    "            return 1. / (self.n_layer-1) * torch.ones(self.n_layer, 1,\n",
    "                                                      device=self.device)\n",
    "        else:\n",
    "            raise Exception(f'Invalid layer loss mode \"{mode}\".')\n",
    "            \n",
    "    def build_time_loss_weights(self, time_steps=None):\n",
    "        time_steps = time_steps or self.time_steps\n",
    "        # How much to weight errors at each timestep\n",
    "        time_loss_weights = 1. / (time_steps-1) * torch.ones(time_steps, 1,\n",
    "                                                             device=self.device)\n",
    "        # Dont count first time step\n",
    "        time_loss_weights[0] = 0\n",
    "        return time_loss_weights\n",
    "    \n",
    "    def check_input_shape(self, input):\n",
    "        batch_size, time_steps, *input_size = input.shape\n",
    "        \n",
    "        # Reset batch_size-dependent things\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "            for cell in self.predcells:\n",
    "                cell.reset(self.batch_size)\n",
    "                \n",
    "        # Reset time_step-dependent things\n",
    "        if time_steps != self.time_steps:\n",
    "            self.time_steps = time_steps\n",
    "            self.time_loss_weights = self.build_time_loss_weights(\n",
    "                self.time_steps)\n",
    "            \n",
    "        return batch_size, time_steps, *input_size\n",
    "    \n",
    "    def top_down_pass(self, t):\n",
    "        # Loop backwards\n",
    "        for l, cell in reversed(list(enumerate(self.predcells))):\n",
    "            E, R = cell.E, cell.R\n",
    "            # First time step\n",
    "            if t == 0:\n",
    "                hx = (R, R)\n",
    "            else:\n",
    "                hx = cell.H\n",
    "\n",
    "            # If not in the last layer, upsample R and\n",
    "            if l < self.n_layers - 1:\n",
    "                E = torch.cat((E,  cell.upsample(self.predcells[l+1].R)), 2)\n",
    "\n",
    "            cell.R, cell.H = cell.recurrent(E, hx)\n",
    "            \n",
    "    def bottom_up_pass(self):\n",
    "        for cell in self.predcells:\n",
    "            # Go from R to A_hat\n",
    "            A_hat = cell.dense(cell.R)\n",
    "\n",
    "            # Convenience\n",
    "            if self.output_mode == 'prediction' and cell.layer_num == 0:\n",
    "                self.frame_prediction = A_hat\n",
    "\n",
    "            # Split to 2 Es\n",
    "            pos = F.relu(A_hat - self.A)\n",
    "            neg = F.relu(self.A - A_hat)\n",
    "            E = torch.cat([pos, neg], 2)\n",
    "            cell.E = E\n",
    "\n",
    "            # If not last layer, update stored A\n",
    "            if cell.layer_num < self.n_layers - 1:\n",
    "                self.A = cell.update_a(E)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        total_error = []\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            self.A = input[:,t,:].unsqueeze(0).to(self.device, torch.float)\n",
    "            \n",
    "            # Loop from top layer to update R and H\n",
    "            self.top_down_pass(t)\n",
    "            # Loop bottom up to get E and A\n",
    "            self.bottom_up_pass()\n",
    "            \n",
    "            if self.output_mode == 'error':\n",
    "                mean_error = torch.cat(\n",
    "                    [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                                1, keepdim=True)\n",
    "                     for cell in self.predcells], 1)\n",
    "                # batch x n_layers\n",
    "                total_error.append(mean_error)\n",
    "        \n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return self.frame_prediction\n",
    "\n",
    "    def timeit(method):\n",
    "        \"\"\"Combination of https://stackoverflow.com/questions/51503672/decorator-for-timeit-timeit-method/51503837#51503837,\n",
    "        and https://www.geeksforgeeks.org/python-program-to-convert-seconds-into-hours-minutes-and-seconds/\"\"\"\n",
    "        @wraps(method)\n",
    "        def _time_it(self, *args, **kwargs):\n",
    "            start = int(round(time.time() * 1000))\n",
    "            try:\n",
    "                return method(self, *args, **kwargs)\n",
    "            finally:\n",
    "                end_ = int(round(time.time() * 1000)) - start\n",
    "                if end_ > 1000:\n",
    "                    time_str = time.strftime(\"%H:%M:%S\",\n",
    "                                             time.gmtime(end_ // 1000))\n",
    "                    print(f\"Total execution time: {time_str}\", flush=True)\n",
    "                \n",
    "        return _time_it\n",
    "\n",
    "    @timeit\n",
    "    def prepare_data(self):\n",
    "        if self.ds is None:\n",
    "            print('Loading the i3d data from disk. This can take '\n",
    "                  'several minutes...', flush=True)\n",
    "        self.ds = self.ds or BreakfastI3DFVDataset()\n",
    "        self.ds_length = len(self.ds)\n",
    "        np.random.seed(self.hparams.seed)\n",
    "        self.indices = list(range(self.ds_length))\n",
    "        self.train_sampler = SubsetRandomSampler(\n",
    "            self.indices[self.hparams.n_val:])\n",
    "        self.val_sampler = SubsetRandomSampler(\n",
    "            self.indices[:self.hparams.n_val])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.train_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.val_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data, path = batch\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        self.logger.experiment.add_scalar(f'{prefix}loss', \n",
    "                                          errors, self.global_step)\n",
    "        return {f'{prefix}loss' : errors}\n",
    "\n",
    "    def validation_epoch_end(self, output):\n",
    "        out_dict = {}\n",
    "        out_dict['val_loss'] = np.mean([out['val_loss'].item()\n",
    "                                        for out in output])\n",
    "        out_dict['global_step'] = self.global_step\n",
    "        return out_dict\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'train')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'val')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Hidden State Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PredCellTracked(prednet.PredCell):\n",
    "    \"\"\"Organizational class.\"\"\"\n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(parent, layer_num, hparams, a_channels, r_channels,\n",
    "                         *args, **kwargs)\n",
    "        # Tracking\n",
    "        self.hidden_full_list = []\n",
    "        self.hidden_diff_list = []\n",
    "        self.previous_hidden = None\n",
    "        self.previous_error = None\n",
    "\n",
    "    def track_hidden(self, output_mode, R):\n",
    "        # Track hidden states if desired\n",
    "        if 'hidden_full' in self.parent.track and self.parent.output_mode == 'eval':\n",
    "            self.hidden_full_list.append(R.view(1, 0, 2))\n",
    "        if 'hidden_diff' in self.parent.track and self.parent.output_mode == 'eval':\n",
    "            diff = torch.mean(\n",
    "                (R.view(1, 0, 2) - self.R.view(1, 0, 2))**2,\n",
    "                2)\n",
    "            self.hidden_diff_list.append(diff)\n",
    "\n",
    "    def track_error(self, output_mode, E):\n",
    "        # Track hidden states if desired\n",
    "        if 'error_full' in self.parent.track and self.parent.output_mode == 'eval':\n",
    "            self.error_full_list.append(E.view(1, 0, 2))\n",
    "        if 'error_diff' in self.parent.track and self.parent.output_mode == 'eval':\n",
    "            diff = torch.mean(\n",
    "                (E.view(1, 0, 2) - self.E.view(1, 0, 2))**2,\n",
    "                2)\n",
    "            self.error_diff_list.append(diff)\n",
    "            \n",
    "class PredNetTracked(prednet.PredNet):\n",
    "    name = 'prednet_tracked'\n",
    "    def __init__(self, hparams, track=None, CellClass=PredCellTracked, *args,\n",
    "                 **kwargs):\n",
    "        self.track = track or ['hidden_diff', 'error_diff']\n",
    "        super().__init__(hparams, CellClass=CellClass, *args, **kwargs)\n",
    "        \n",
    "    def top_down_pass(self):\n",
    "        # Loop backwards\n",
    "        for l, cell in reversed(list(enumerate(self.predcells))):\n",
    "            # First time step\n",
    "            if self.t == 0:\n",
    "                hx = (cell.R, cell.R)\n",
    "            else:\n",
    "                hx = cell.H\n",
    "\n",
    "            # If not in the last layer, upsample R and\n",
    "            if l < self.n_layers - 1:\n",
    "                cell.E = torch.cat((cell.E,  cell.upsample(\n",
    "                    self.predcells[l+1].R)), 2)\n",
    "\n",
    "            # Update the values of R and H\n",
    "            R, H = cell.recurrent(cell.E, hx)\n",
    "\n",
    "            # Optional tracking\n",
    "            cell.track_hidden(self.output_mode, R)\n",
    "\n",
    "            # Update cell state\n",
    "            cell.R, cell.H = R, H\n",
    "            \n",
    "    def bottom_up_pass(self):\n",
    "        for cell in self.predcells:\n",
    "            # Go from R to A_hat\n",
    "            A_hat = cell.dense(cell.R)\n",
    "\n",
    "            # Convenience\n",
    "            if self.output_mode == 'prediction' and cell.layer_num == 0:\n",
    "                self.frame_prediction = A_hat\n",
    "\n",
    "            # Split to 2 Es\n",
    "            pos = F.relu(A_hat - self.A)\n",
    "            neg = F.relu(self.A - A_hat)\n",
    "            E = torch.cat([pos, neg], 2)\n",
    "            \n",
    "            # Optional Error tracking\n",
    "            cell.track_error(self.output_mode, E)\n",
    "\n",
    "            # Update cell error\n",
    "            cell.E = E\n",
    "\n",
    "            # If not last layer, update stored A\n",
    "            if cell.layer_num < self.n_layers - 1:\n",
    "                self.A = cell.update_a(E)\n",
    "            \n",
    "    def forward(self, input, output_mode=None, track=None):\n",
    "        self.output_mode = output_mode or self.output_mode\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        self.total_error = []\n",
    "        \n",
    "        for self.t in range(time_steps):\n",
    "            self.A = input[:,self.t,:].unsqueeze(0).to(self.device, torch.float)\n",
    "            # Loop from top layer to update R and H\n",
    "            self.top_down_pass()\n",
    "            # Loop bottom up to get E and A\n",
    "            self.bottom_up_pass()\n",
    "            # Track desired outputs\n",
    "            self.track_outputs()\n",
    "        \n",
    "        return self.return_output()\n",
    "        \n",
    "    def track_outputs(self):\n",
    "        if self.output_mode == 'error':\n",
    "            mean_error = torch.cat(\n",
    "                [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                            1, keepdim=True)\n",
    "                 for cell in self.predcells], 1)\n",
    "            # batch x n_layers\n",
    "            self.total_error.append(mean_error)\n",
    "            \n",
    "    def return_output(self):\n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(self.total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return self.frame_prediction\n",
    "        elif self.output_mode == 'eval':\n",
    "            return self.eval_outputs()\n",
    "\n",
    "    def eval_outputs(self):\n",
    "        outputs = {}\n",
    "        for tracked in self.track:\n",
    "            outputs[tracked] = [getattr(cell, tracked+'_list')\n",
    "                                for cell in self.predcells]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# model, trainer = None, None\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "res = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ModelClass = prednet.PredNetTracked\n",
    "hparams = const.DEFAULT_HPARAMS\n",
    "hparams.name = ModelClass.name\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / 'bk_i3d_{global_step:05d}_{epoch:03d}_{val_loss:.3f}'),\n",
    "    verbose=True,\n",
    "    save_top_k=3,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(default_save_path=str(index.DIR_CHECKPOINTS),\n",
    "                     checkpoint_callback=ckpt,\n",
    "                     max_epochs=150,\n",
    "                     logger=logger,\n",
    "                     gpus=1\n",
    "                     )\n",
    "\n",
    "# model = ModelClass(hparams)\n",
    "# model.ds = ds\n",
    "\n",
    "# model, trainer = None, None\n",
    "# train_dataloader, val_dataloader = None, None\n",
    "# errors, optimizer = None, None\n",
    "# ckpt = None\n",
    "# train_errors, val_errors = None, None\n",
    "# res = None\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# trainer = pl.Trainer(default_save_path=str(index.DIR_CHECKPOINTS),\n",
    "#                      max_epochs=1,\n",
    "#                      gpus=1,\n",
    "#                      logger=logger,\n",
    "#                     )\n",
    "\n",
    "model = ModelClass(hparams)\n",
    "model.ds = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa60f92489a486c939f49420907cf64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f218be4b43a4c818f00d09990b33d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fe83bf7fbe4fbfa175b6a9a2064b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e863c0ccb544b792e98eb54a702555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd3f62762c14c4895cfc89812dd0b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f207e79055b4ae087592009bbd226ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811aa14ba3ef4859b2bb917cc5bff8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6229d7b866460197335a2f2e528e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6914befead4e109f6a266174f8d11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0552ec5f3745c484674caa18407767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f24348c48cb44d1a0b3bd3d7930318b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aac3e92884e43a5be780276035e14cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce405979ad8448385831059097f3059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b0ff71d63c4a3a8de81fd156b804f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3533889355204189ba07e46fd595c367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ee6f9456154992b6c82b43c4413c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5953cad8e44fb6a167d53a43ab2599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Videos to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_summary = index.DIR_BK_META / 'i3d_fvs_meta.csv'\n",
    "path_summary.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>patient</th>\n",
       "      <th>action</th>\n",
       "      <th>camera</th>\n",
       "      <th>channel</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>23</td>\n",
       "      <td>milk</td>\n",
       "      <td>webcam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23_milk_webcam01</td>\n",
       "      <td>1246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>14</td>\n",
       "      <td>tea</td>\n",
       "      <td>webcam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14_tea_webcam01</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>18</td>\n",
       "      <td>cereals</td>\n",
       "      <td>webcam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18_cereals_webcam02</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>49</td>\n",
       "      <td>friedegg</td>\n",
       "      <td>webcam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49_friedegg_webcam01</td>\n",
       "      <td>5174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>17</td>\n",
       "      <td>tea</td>\n",
       "      <td>webcam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17_tea_webcam02</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  patient    action  \\\n",
       "0  /media/data_cifs2/apra/work/labwork/data/exter...       23      milk   \n",
       "1  /media/data_cifs2/apra/work/labwork/data/exter...       14       tea   \n",
       "2  /media/data_cifs2/apra/work/labwork/data/exter...       18   cereals   \n",
       "3  /media/data_cifs2/apra/work/labwork/data/exter...       49  friedegg   \n",
       "4  /media/data_cifs2/apra/work/labwork/data/exter...       17       tea   \n",
       "\n",
       "     camera  channel                    id  length  \n",
       "0  webcam01      NaN      23_milk_webcam01    1246  \n",
       "1  webcam01      NaN       14_tea_webcam01     397  \n",
       "2  webcam02      NaN   18_cereals_webcam02     461  \n",
       "3  webcam01      NaN  49_friedegg_webcam01    5174  \n",
       "4  webcam02      NaN       17_tea_webcam02     703  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coarse = pd.read_csv(str(path_summary))\n",
    "df_coarse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dups = df_coarse[df_coarse.duplicated(subset=['patient', 'action'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>action</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>20</td>\n",
       "      <td>milk</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>20</td>\n",
       "      <td>tea</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>21</td>\n",
       "      <td>coffee</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>21</td>\n",
       "      <td>friedegg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>54</td>\n",
       "      <td>cereals</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>54</td>\n",
       "      <td>friedegg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>54</td>\n",
       "      <td>juice</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>54</td>\n",
       "      <td>pancake</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>54</td>\n",
       "      <td>scrambledegg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient        action  counts\n",
       "161       20        coffee       5\n",
       "164       20          milk       5\n",
       "169       20           tea       5\n",
       "171       21        coffee       5\n",
       "172       21      friedegg       5\n",
       "..       ...           ...     ...\n",
       "493       54       cereals       5\n",
       "495       54      friedegg       5\n",
       "496       54         juice       5\n",
       "498       54       pancake       5\n",
       "501       54  scrambledegg       5\n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counts = df_coarse.groupby(['patient', 'action']).size().reset_index(name='counts')\n",
    "df_counts[df_counts.counts == df_counts.counts.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>patient</th>\n",
       "      <th>action</th>\n",
       "      <th>camera</th>\n",
       "      <th>channel</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>webcam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20_coffee_webcam02</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>cam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20_coffee_cam01</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>stereo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20_coffee_stereo_1</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>cam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20_coffee_cam02</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>webcam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20_coffee_webcam01</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  patient  action  \\\n",
       "78    /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "138   /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "326   /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "877   /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "1409  /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "\n",
       "        camera  channel                  id  length  \n",
       "78    webcam02      NaN  20_coffee_webcam02     689  \n",
       "138      cam01      NaN     20_coffee_cam01     689  \n",
       "326     stereo      1.0  20_coffee_stereo_1     689  \n",
       "877      cam02      NaN     20_coffee_cam02     689  \n",
       "1409  webcam01      NaN  20_coffee_webcam01     689  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p20_acoffee = df_coarse[(df_coarse.patient==20) & (df_coarse.action=='coffee')]\n",
    "df_p20_acoffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mats = []\n",
    "for path in df_p20_acoffee.path:\n",
    "    np_mats.append(np.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 689, 2048)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mats_cat = np.array(np_mats)\n",
    "np_mats_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20_coffee_webcam02',\n",
       " '20_coffee_cam01',\n",
       " '20_coffee_stereo_1',\n",
       " '20_coffee_cam02',\n",
       " '20_coffee_webcam01']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(df_p20_acoffee.id.values)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 689, 2048])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_test = torch.tensor(np_mats_cat, device='cuda')\n",
    "torch_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 19 21:25:41 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 34%   57C    P2   115W / 250W |   9331MiB / 12196MiB |     51%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 23%   31C    P8     9W / 250W |   8935MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 23%   30C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 43%   68C    P2    92W / 250W |   9493MiB / 12196MiB |      9%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN Xp            Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 23%   30C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN Xp            Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 23%   27C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN Xp            Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 26%   46C    P2    61W / 250W |    853MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN Xp            Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 23%   30C    P8     8W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4651      C   python                                      9321MiB |\n",
      "|    1     24831      C   ...data/conda/abdullah/envs/pes/bin/python  8925MiB |\n",
      "|    3      1518      C   python                                      9483MiB |\n",
      "|    6     14323      C   python                                       843MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "res = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = prednet.PredNetTracked.load_from_checkpoint(\n",
    "    str(index.DIR_CHECKPOINTS / \n",
    "        'prednet_6l_200e_all_llm_v0/bk_i3d_global_step=22679_epoch=134_val_loss=0.025.ckpt'),\n",
    ")\n",
    "model.ds = ds\n",
    "model.cuda()\n",
    "hparams = model.hparams\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name,\n",
    "                                     version=0)\n",
    "model.logger = logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model.forward(torch_test, output_mode='eval',\n",
    "                     run_num='20_coffee', tb_labels=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20_coffee_webcam02',\n",
       " '20_coffee_cam01',\n",
       " '20_coffee_stereo_1',\n",
       " '20_coffee_cam02',\n",
       " '20_coffee_webcam01']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>patient</th>\n",
       "      <th>action</th>\n",
       "      <th>camera</th>\n",
       "      <th>channel</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>18</td>\n",
       "      <td>cereals</td>\n",
       "      <td>webcam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18_cereals_webcam02</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>54</td>\n",
       "      <td>cereals</td>\n",
       "      <td>cam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54_cereals_cam01</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>34</td>\n",
       "      <td>cereals</td>\n",
       "      <td>stereo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34_cereals_stereo_1</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>13</td>\n",
       "      <td>cereals</td>\n",
       "      <td>cam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13_cereals_cam01</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>51</td>\n",
       "      <td>cereals</td>\n",
       "      <td>webcam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51_cereals_webcam02</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>36</td>\n",
       "      <td>pancake</td>\n",
       "      <td>webcam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36_pancake_webcam02</td>\n",
       "      <td>7053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>54</td>\n",
       "      <td>pancake</td>\n",
       "      <td>stereo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54_pancake_stereo_1</td>\n",
       "      <td>3344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>13</td>\n",
       "      <td>pancake</td>\n",
       "      <td>cam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13_pancake_cam01</td>\n",
       "      <td>4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>21</td>\n",
       "      <td>pancake</td>\n",
       "      <td>cam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21_pancake_cam01</td>\n",
       "      <td>5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>12</td>\n",
       "      <td>pancake</td>\n",
       "      <td>webcam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12_pancake_webcam01</td>\n",
       "      <td>2874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1712 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  patient   action  \\\n",
       "0     /media/data_cifs2/apra/work/labwork/data/exter...       18  cereals   \n",
       "1     /media/data_cifs2/apra/work/labwork/data/exter...       54  cereals   \n",
       "2     /media/data_cifs2/apra/work/labwork/data/exter...       34  cereals   \n",
       "3     /media/data_cifs2/apra/work/labwork/data/exter...       13  cereals   \n",
       "4     /media/data_cifs2/apra/work/labwork/data/exter...       51  cereals   \n",
       "...                                                 ...      ...      ...   \n",
       "1707  /media/data_cifs2/apra/work/labwork/data/exter...       36  pancake   \n",
       "1708  /media/data_cifs2/apra/work/labwork/data/exter...       54  pancake   \n",
       "1709  /media/data_cifs2/apra/work/labwork/data/exter...       13  pancake   \n",
       "1710  /media/data_cifs2/apra/work/labwork/data/exter...       21  pancake   \n",
       "1711  /media/data_cifs2/apra/work/labwork/data/exter...       12  pancake   \n",
       "\n",
       "        camera  channel                   id  length  \n",
       "0     webcam02      NaN  18_cereals_webcam02     465  \n",
       "1        cam01      NaN     54_cereals_cam01     747  \n",
       "2       stereo      1.0  34_cereals_stereo_1     765  \n",
       "3        cam01      NaN     13_cereals_cam01     679  \n",
       "4     webcam02      NaN  51_cereals_webcam02     711  \n",
       "...        ...      ...                  ...     ...  \n",
       "1707  webcam02      NaN  36_pancake_webcam02    7053  \n",
       "1708    stereo      1.0  54_pancake_stereo_1    3344  \n",
       "1709     cam01      NaN     13_pancake_cam01    4440  \n",
       "1710     cam01      NaN     21_pancake_cam01    5845  \n",
       "1711  webcam01      NaN  12_pancake_webcam01    2874  \n",
       "\n",
       "[1712 rows x 7 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_meta = pd.read_csv(str(index.DIR_BK_META / 'coarse_segmentations_meta.csv'))\n",
    "coarse_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>patient</th>\n",
       "      <th>action</th>\n",
       "      <th>camera</th>\n",
       "      <th>channel</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>webcam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20_coffee_webcam02</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>stereo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20_coffee_stereo_1</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>cam02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20_coffee_cam02</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>cam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20_coffee_cam01</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>/media/data_cifs2/apra/work/labwork/data/exter...</td>\n",
       "      <td>20</td>\n",
       "      <td>coffee</td>\n",
       "      <td>webcam01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20_coffee_webcam01</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  patient  action  \\\n",
       "1230  /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "1250  /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "1262  /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "1299  /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "1326  /media/data_cifs2/apra/work/labwork/data/exter...       20  coffee   \n",
       "\n",
       "        camera  channel                  id  length  \n",
       "1230  webcam02      NaN  20_coffee_webcam02     693  \n",
       "1250    stereo      1.0  20_coffee_stereo_1     693  \n",
       "1262     cam02      NaN     20_coffee_cam02     693  \n",
       "1299     cam01      NaN     20_coffee_cam01     693  \n",
       "1326  webcam01      NaN  20_coffee_webcam01     693  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_meta_id = coarse_meta[coarse_meta.id.isin(ids)]\n",
    "coarse_meta_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/data_cifs2/apra/work/labwork/data/external/breakfast/segmentation_coarse/coffee/P20_webcam02_P20_coffee.txt',\n",
       " '/media/data_cifs2/apra/work/labwork/data/external/breakfast/segmentation_coarse/coffee/P20_stereo01_P20_coffee.txt',\n",
       " '/media/data_cifs2/apra/work/labwork/data/external/breakfast/segmentation_coarse/coffee/P20_cam02_P20_coffee.txt',\n",
       " '/media/data_cifs2/apra/work/labwork/data/external/breakfast/segmentation_coarse/coffee/P20_cam01_P20_coffee.txt',\n",
       " '/media/data_cifs2/apra/work/labwork/data/external/breakfast/segmentation_coarse/coffee/P20_webcam01_P20_coffee.txt']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(coarse_meta_id.path.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/data_cifs2/apra/work/labwork/data/external/breakfast/segmentation_coarse/coffee/P20_webcam02_P20_coffee.txt\n",
      "1-1 SIL  \n",
      "\n",
      "2-119 take_cup  \n",
      "\n",
      "120-271 pour_coffee  \n",
      "\n",
      "272-388 pour_milk  \n",
      "\n",
      "389-556 spoon_sugar  \n",
      "\n",
      "557-686 stir_coffee  \n",
      "\n",
      "687-693 SIL  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path in list(coarse_meta_id.path.values):\n",
    "    with open(path, 'r') as txt:\n",
    "        print(path)\n",
    "        for t in txt:\n",
    "            print(t)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
