{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.1 Evaluating Hidden States\n",
    "\n",
    "Adding functionality to view hidden state activity through a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Wed Mar 18 2020 17:13:03 \n",
      "\n",
      "CPython 3.8.2\n",
      "IPython 7.13.0\n",
      "\n",
      "torch 1.4.0\n",
      "torchvision 0.5.0\n",
      "pytorch_lightning 0.7.1\n",
      "jupyterlab 2.0.1\n",
      "prevseg 0+untagged.11.g393f577.dirty\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-88-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "Git hash   : 393f5775d28aeec38742df7b2b394f0ae6179d2a\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and packages. Add more as necessary.\n",
    "%watermark -v -n -m -g -b -t -p torch,torchvision,pytorch_lightning,jupyterlab,prevseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from functools import wraps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F, GRU\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imports that may or may not be autoreloaded. This section contains things that will likely have to be re-imported multiple times, and have additions or subtractions made throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to be used throughout the package\n",
    "%aimport prevseg\n",
    "import prevseg as pes\n",
    "%aimport prevseg.index\n",
    "from prevseg import index\n",
    "# Import the data subdirectories\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as prednet\n",
    "%aimport prevseg.dataloaders.breakfast\n",
    "import prevseg.dataloaders.breakfast as bk\n",
    "%aimport prevseg.constants\n",
    "import prevseg.constants as const\n",
    "\n",
    "from prevseg.torch.lstm import LSTM\n",
    "from prevseg.torch.activations import SatLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the GPU\n",
    "\n",
    "Make sure we aren't greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 18 17:13:35 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 34%   57C    P2    84W / 250W |   9331MiB / 12196MiB |     14%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 26%   38C    P8     9W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 54%   84C    P2   246W / 250W |   8869MiB / 12196MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 44%   69C    P2    92W / 250W |   9493MiB / 12196MiB |      9%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN Xp            Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 53%   83C    P2   206W / 250W |  10425MiB / 12196MiB |     89%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN Xp            Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 35%   58C    P2    80W / 250W |   6405MiB / 12196MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN Xp            Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 46%   74C    P2   182W / 250W |   8875MiB / 12196MiB |     33%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN Xp            Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 54%   83C    P2   159W / 250W |  10473MiB / 12196MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4651      C   python                                      9321MiB |\n",
      "|    2     21522      C   python                                      8859MiB |\n",
      "|    3      1518      C   python                                      9483MiB |\n",
      "|    4     21522      C   python                                     10415MiB |\n",
      "|    5     14843      C   python                                      6395MiB |\n",
      "|    6     17508      C   python                                      8865MiB |\n",
      "|    7     17508      C   python                                     10463MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 8min 22s, total: 8min 36s\n",
      "Wall time: 15min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = bk.BreakfastI3DFVDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `wb-1.2.0` for the implementation at work, but below is the relevant portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "\n",
    "class PredCell(object):\n",
    "    \"\"\"Organizational class.\"\"\"\n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels, \n",
    "                 RecurrentClass=LSTM):\n",
    "        super().__init__()\n",
    "        self.parent = parent\n",
    "        self.layer_num = layer_num\n",
    "        self.hparams = hparams\n",
    "        self.a_channels = a_channels\n",
    "        self.r_channels = r_channels\n",
    "        self.RecurrentClass = RecurrentClass\n",
    "        \n",
    "        # Reccurent\n",
    "        self.recurrent = self.build_recurrent()\n",
    "        # Dense\n",
    "        self.dense = self.build_dense()\n",
    "        # Update\n",
    "        self.update_a = self.build_update()\n",
    "        # upsample - set at cell level for future\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        # Build E, R, and H\n",
    "        self.reset()\n",
    "        # Book-keeping\n",
    "        self.update_parent()\n",
    "            \n",
    "    def build_recurrent(self):\n",
    "        recurrent = self.RecurrentClass(\n",
    "            2 * (self.a_channels[self.layer_num] +\n",
    "                 self.r_channels[self.layer_num+1]),\n",
    "            #+ self.r_channels[self.layer_num+1],\n",
    "            self.r_channels[self.layer_num])\n",
    "        recurrent.reset_parameters()\n",
    "        return recurrent\n",
    "    \n",
    "    def build_dense(self):\n",
    "        dense = nn.Sequential(\n",
    "            nn.Linear(self.r_channels[self.layer_num],\n",
    "                      self.a_channels[self.layer_num]),\n",
    "            nn.ReLU())\n",
    "        if self.layer_num == 0:\n",
    "            dense.add_module('satlu', SatLU())\n",
    "        return dense\n",
    "        \n",
    "    def build_update(self):\n",
    "        if self.layer_num < self.hparams.n_layers - 1:\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    2 * self.a_channels[self.layer_num],\n",
    "                    self.a_channels[self.layer_num + 1]),\n",
    "                nn.ReLU())\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def reset(self, batch_size=None):\n",
    "        batch_size = batch_size or self.hparams.batch_size\n",
    "        # E, R, and H variables\n",
    "        self.E = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             2*self.a_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.R = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             self.r_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.H = None\n",
    "        \n",
    "    def update_parent(self):\n",
    "        self.modules = {'recurrent' : self.recurrent, 'dense' : self.dense}\n",
    "        if hasattr(self, 'update_a') and self.update_a is not None:\n",
    "            self.modules['update_a'] = self.update_a\n",
    "        # Hack to appease the pytorch-gods\n",
    "        for name, module in self.modules.items():\n",
    "            setattr(self.parent, f'predcell_{self.layer_num}_{name}', module)\n",
    "\n",
    "\n",
    "class PredNet(pl.LightningModule):\n",
    "    name = 'prednet'\n",
    "    def __init__(self, hparams, ds=None, CellClass=PredCell):\n",
    "        super().__init__()\n",
    "        # Attribute definitions\n",
    "        self.hparams = hparams\n",
    "        self.n_layers = self.hparams.n_layers\n",
    "        self.output_mode = self.hparams.output_mode\n",
    "        self.input_size = self.hparams.input_size\n",
    "        self.time_steps = self.hparams.time_steps\n",
    "        self.batch_size = self.hparams.batch_size\n",
    "        self.layer_loss_mode = self.hparams.layer_loss_mode\n",
    "        self.ds = ds\n",
    "        self.CellClass = CellClass\n",
    "        \n",
    "        if self.hparams.device == 'cuda' and torch.cuda.is_available():\n",
    "            print('Using GPU', flush=True)\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            print('Using CPU', flush=True)\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        # Put together the model\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):        \n",
    "        # Channel sizes\n",
    "        self.r_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)] + [0,] # Convenience\n",
    "        self.a_channels = [self.input_size // (2**i) \n",
    "                           for i in range(self.n_layers)]\n",
    "        \n",
    "        # Make sure everything checks out\n",
    "        default_output_modes = ['prediction', 'error']\n",
    "        assert self.output_mode in default_output_modes, \\\n",
    "            'Invalid output_mode: ' + str(output_mode)\n",
    "\n",
    "        # Make all the pred cells\n",
    "        self.predcells = [self.CellClass(self,\n",
    "                                         layer_num,\n",
    "                                         self.hparams,\n",
    "                                         self.a_channels,\n",
    "                                         self.r_channels)\n",
    "                          for layer_num in range(self.n_layers)]\n",
    "        \n",
    "        # How to weight the errors\n",
    "        # 1 followed by zeros means just minimize error at lowest layer\n",
    "        self.layer_loss_weights = self.build_layer_loss_weights(\n",
    "            self.layer_loss_mode)\n",
    "        # How much to weight errors at each timestep\n",
    "        self.time_loss_weights = self.build_time_loss_weights()\n",
    "        \n",
    "    def build_layer_loss_weights(self, mode='first'):\n",
    "        if mode == 'first':\n",
    "            first = torch.zeros(self.n_layers, 1, device=self.device)\n",
    "            first[0][0] = 1\n",
    "            return first\n",
    "        elif mode == 'all':\n",
    "            return 1. / (self.n_layer-1) * torch.ones(self.n_layer, 1,\n",
    "                                                      device=self.device)\n",
    "        else:\n",
    "            raise Exception(f'Invalid layer loss mode \"{mode}\".')\n",
    "            \n",
    "    def build_time_loss_weights(self, time_steps=None):\n",
    "        time_steps = time_steps or self.time_steps\n",
    "        # How much to weight errors at each timestep\n",
    "        time_loss_weights = 1. / (time_steps-1) * torch.ones(time_steps, 1,\n",
    "                                                             device=self.device)\n",
    "        # Dont count first time step\n",
    "        time_loss_weights[0] = 0\n",
    "        return time_loss_weights\n",
    "    \n",
    "    def check_input_shape(self, input):\n",
    "        batch_size, time_steps, *input_size = input.shape\n",
    "        \n",
    "        # Reset batch_size-dependent things\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "            for cell in self.predcells:\n",
    "                cell.reset(self.batch_size)\n",
    "                \n",
    "        # Reset time_step-dependent things\n",
    "        if time_steps != self.time_steps:\n",
    "            self.time_steps = time_steps\n",
    "            self.time_loss_weights = self.build_time_loss_weights(\n",
    "                self.time_steps)\n",
    "            \n",
    "        return batch_size, time_steps, *input_size\n",
    "    \n",
    "    def top_down_pass(self, t):\n",
    "        # Loop backwards\n",
    "        for l, cell in reversed(list(enumerate(self.predcells))):\n",
    "            E, R = cell.E, cell.R\n",
    "            # First time step\n",
    "            if t == 0:\n",
    "                hx = (R, R)\n",
    "            else:\n",
    "                hx = cell.H\n",
    "\n",
    "            # If not in the last layer, upsample R and\n",
    "            if l < self.n_layers - 1:\n",
    "                E = torch.cat((E,  cell.upsample(self.predcells[l+1].R)), 2)\n",
    "\n",
    "            cell.R, cell.H = cell.recurrent(E, hx)\n",
    "            \n",
    "    def bottom_up_pass(self):\n",
    "        for cell in self.predcells:\n",
    "            # Go from R to A_hat\n",
    "            A_hat = cell.dense(cell.R)\n",
    "\n",
    "            # Convenience\n",
    "            if self.output_mode == 'prediction' and cell.layer_num == 0:\n",
    "                self.frame_prediction = A_hat\n",
    "\n",
    "            # Split to 2 Es\n",
    "            pos = F.relu(A_hat - self.A)\n",
    "            neg = F.relu(self.A - A_hat)\n",
    "            E = torch.cat([pos, neg], 2)\n",
    "            cell.E = E\n",
    "\n",
    "            # If not last layer, update stored A\n",
    "            if cell.layer_num < self.n_layers - 1:\n",
    "                self.A = cell.update_a(E)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        total_error = []\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            self.A = input[:,t,:].unsqueeze(0).to(self.device, torch.float)\n",
    "            \n",
    "            # Loop from top layer to update R and H\n",
    "            self.top_down_pass(t)\n",
    "            # Loop bottom up to get E and A\n",
    "            self.bottom_up_pass()\n",
    "            \n",
    "            if self.output_mode == 'error':\n",
    "                mean_error = torch.cat(\n",
    "                    [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                                1, keepdim=True)\n",
    "                     for cell in self.predcells], 1)\n",
    "                # batch x n_layers\n",
    "                total_error.append(mean_error)\n",
    "        \n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return self.frame_prediction\n",
    "\n",
    "    def timeit(method):\n",
    "        \"\"\"Combination of https://stackoverflow.com/questions/51503672/decorator-for-timeit-timeit-method/51503837#51503837,\n",
    "        and https://www.geeksforgeeks.org/python-program-to-convert-seconds-into-hours-minutes-and-seconds/\"\"\"\n",
    "        @wraps(method)\n",
    "        def _time_it(self, *args, **kwargs):\n",
    "            start = int(round(time.time() * 1000))\n",
    "            try:\n",
    "                return method(self, *args, **kwargs)\n",
    "            finally:\n",
    "                end_ = int(round(time.time() * 1000)) - start\n",
    "                if end_ > 1000:\n",
    "                    time_str = time.strftime(\"%H:%M:%S\",\n",
    "                                             time.gmtime(end_ // 1000))\n",
    "                    print(f\"Total execution time: {time_str}\", flush=True)\n",
    "                \n",
    "        return _time_it\n",
    "\n",
    "    @timeit\n",
    "    def prepare_data(self):\n",
    "        if self.ds is None:\n",
    "            print('Loading the i3d data from disk. This can take '\n",
    "                  'several minutes...', flush=True)\n",
    "        self.ds = self.ds or BreakfastI3DFVDataset()\n",
    "        self.ds_length = len(self.ds)\n",
    "        np.random.seed(self.hparams.seed)\n",
    "        self.indices = list(range(self.ds_length))\n",
    "        self.train_sampler = SubsetRandomSampler(\n",
    "            self.indices[self.hparams.n_val:])\n",
    "        self.val_sampler = SubsetRandomSampler(\n",
    "            self.indices[:self.hparams.n_val])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.train_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=self.batch_size, \n",
    "                          sampler=self.val_sampler,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data, path = batch\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        self.logger.experiment.add_scalar(f'{prefix}loss', \n",
    "                                          errors, self.global_step)\n",
    "        return {f'{prefix}loss' : errors}\n",
    "\n",
    "    def validation_epoch_end(self, output):\n",
    "        out_dict = {}\n",
    "        out_dict['val_loss'] = np.mean([out['val_loss'].item()\n",
    "                                        for out in output])\n",
    "        out_dict['global_step'] = self.global_step\n",
    "        return out_dict\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'train')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, batch_idx, 'val')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Hidden State Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PredCellTracked(prednet.PredCell):\n",
    "    \"\"\"Organizational class.\"\"\"\n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(parent, layer_num, hparams, a_channels, r_channels,\n",
    "                         *args, **kwargs)\n",
    "        # Tracking\n",
    "        self.hidden_full_list = []\n",
    "        self.hidden_diff_list = []\n",
    "        self.previous_hidden = None\n",
    "        self.previous_error = None\n",
    "\n",
    "    def track_hidden(self, output_mode, R):\n",
    "        # Track hidden states if desired\n",
    "        if 'hidden_full' in self.parent.track and self.parent.output_mode == 'eval':\n",
    "            self.hidden_full_list.append(R.view(1, 0, 2))\n",
    "        if 'hidden_diff' in self.parent.track and self.parent.output_mode == 'eval':\n",
    "            diff = torch.mean(\n",
    "                (R.view(1, 0, 2) - self.R.view(1, 0, 2))**2,\n",
    "                2)\n",
    "            self.hidden_diff_list.append(diff)\n",
    "\n",
    "    def track_error(self, output_mode, E):\n",
    "        # Track hidden states if desired\n",
    "        if 'error_full' in self.parent.track and self.parent.output_mode == 'eval':\n",
    "            self.error_full_list.append(E.view(1, 0, 2))\n",
    "        if 'error_diff' in self.parent.track and self.parent.output_mode == 'eval':\n",
    "            diff = torch.mean(\n",
    "                (E.view(1, 0, 2) - self.E.view(1, 0, 2))**2,\n",
    "                2)\n",
    "            self.error_diff_list.append(diff)\n",
    "            \n",
    "class PredNetTracked(prednet.PredNet):\n",
    "    name = 'prednet_tracked'\n",
    "    def __init__(self, hparams, track=None, CellClass=PredCellTracked, *args,\n",
    "                 **kwargs):\n",
    "        self.track = track or ['hidden_diff', 'error_diff']\n",
    "        super().__init__(hparams, CellClass=CellClass, *args, **kwargs)\n",
    "        \n",
    "    def top_down_pass(self):\n",
    "        # Loop backwards\n",
    "        for l, cell in reversed(list(enumerate(self.predcells))):\n",
    "            # First time step\n",
    "            if self.t == 0:\n",
    "                hx = (cell.R, cell.R)\n",
    "            else:\n",
    "                hx = cell.H\n",
    "\n",
    "            # If not in the last layer, upsample R and\n",
    "            if l < self.n_layers - 1:\n",
    "                cell.E = torch.cat((cell.E,  cell.upsample(\n",
    "                    self.predcells[l+1].R)), 2)\n",
    "\n",
    "            # Update the values of R and H\n",
    "            R, H = cell.recurrent(cell.E, hx)\n",
    "\n",
    "            # Optional tracking\n",
    "            cell.track_hidden(self.output_mode, R)\n",
    "\n",
    "            # Update cell state\n",
    "            cell.R, cell.H = R, H\n",
    "            \n",
    "    def bottom_up_pass(self):\n",
    "        for cell in self.predcells:\n",
    "            # Go from R to A_hat\n",
    "            A_hat = cell.dense(cell.R)\n",
    "\n",
    "            # Convenience\n",
    "            if self.output_mode == 'prediction' and cell.layer_num == 0:\n",
    "                self.frame_prediction = A_hat\n",
    "\n",
    "            # Split to 2 Es\n",
    "            pos = F.relu(A_hat - self.A)\n",
    "            neg = F.relu(self.A - A_hat)\n",
    "            E = torch.cat([pos, neg], 2)\n",
    "            \n",
    "            # Optional Error tracking\n",
    "            cell.track_error(self.output_mode, E)\n",
    "\n",
    "            # Update cell error\n",
    "            cell.E = E\n",
    "\n",
    "            # If not last layer, update stored A\n",
    "            if cell.layer_num < self.n_layers - 1:\n",
    "                self.A = cell.update_a(E)\n",
    "            \n",
    "    def forward(self, input, output_mode=None, track=None):\n",
    "        self.output_mode = output_mode or self.output_mode\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        self.total_error = []\n",
    "        \n",
    "        for self.t in range(time_steps):\n",
    "            self.A = input[:,self.t,:].unsqueeze(0).to(self.device, torch.float)\n",
    "            # Loop from top layer to update R and H\n",
    "            self.top_down_pass()\n",
    "            # Loop bottom up to get E and A\n",
    "            self.bottom_up_pass()\n",
    "            # Track desired outputs\n",
    "            self.track_outputs()\n",
    "        \n",
    "        return self.return_output()\n",
    "        \n",
    "    def track_outputs(self):\n",
    "        if self.output_mode == 'error':\n",
    "            mean_error = torch.cat(\n",
    "                [torch.mean(cell.E.view(cell.E.size(1), -1),\n",
    "                            1, keepdim=True)\n",
    "                 for cell in self.predcells], 1)\n",
    "            # batch x n_layers\n",
    "            self.total_error.append(mean_error)\n",
    "            \n",
    "    def return_output(self):\n",
    "        if self.output_mode == 'error':\n",
    "            return torch.stack(self.total_error, 2) # batch x n_layers x nt\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return self.frame_prediction\n",
    "        elif self.output_mode == 'eval':\n",
    "            return self.eval_outputs()\n",
    "\n",
    "    def eval_outputs(self):\n",
    "        outputs = {}\n",
    "        for tracked in self.track:\n",
    "            outputs[tracked] = [getattr(cell, tracked+'_list')\n",
    "                                for cell in self.predcells]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# model, trainer = None, None\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "res = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ModelClass = prednet.PredNetTracked\n",
    "hparams = const.DEFAULT_HPARAMS\n",
    "hparams.name = ModelClass.name\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / 'bk_i3d_{global_step:05d}_{epoch:03d}_{val_loss:.3f}'),\n",
    "    verbose=True,\n",
    "    save_top_k=3,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(default_save_path=str(index.DIR_CHECKPOINTS),\n",
    "                     checkpoint_callback=ckpt,\n",
    "                     max_epochs=150,\n",
    "                     logger=logger,\n",
    "                     gpus=1\n",
    "                     )\n",
    "\n",
    "# model = ModelClass(hparams)\n",
    "# model.ds = ds\n",
    "\n",
    "# model, trainer = None, None\n",
    "# train_dataloader, val_dataloader = None, None\n",
    "# errors, optimizer = None, None\n",
    "# ckpt = None\n",
    "# train_errors, val_errors = None, None\n",
    "# res = None\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# trainer = pl.Trainer(default_save_path=str(index.DIR_CHECKPOINTS),\n",
    "#                      max_epochs=1,\n",
    "#                      gpus=1,\n",
    "#                      logger=logger,\n",
    "#                     )\n",
    "\n",
    "model = ModelClass(hparams)\n",
    "model.ds = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa60f92489a486c939f49420907cf64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f218be4b43a4c818f00d09990b33d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fe83bf7fbe4fbfa175b6a9a2064b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e863c0ccb544b792e98eb54a702555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd3f62762c14c4895cfc89812dd0b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f207e79055b4ae087592009bbd226ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811aa14ba3ef4859b2bb917cc5bff8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6229d7b866460197335a2f2e528e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6914befead4e109f6a266174f8d11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0552ec5f3745c484674caa18407767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f24348c48cb44d1a0b3bd3d7930318b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aac3e92884e43a5be780276035e14cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce405979ad8448385831059097f3059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b0ff71d63c4a3a8de81fd156b804f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3533889355204189ba07e46fd595c367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ee6f9456154992b6c82b43c4413c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5953cad8e44fb6a167d53a43ab2599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.logger = logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.loggers.tensorboard.TensorBoardLogger at 0x7fa43d878e20>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = model.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, path in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64, 2048])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 2048])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch = batch[:2,:,:]\n",
    "mini_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_num = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.forward(mini_batch, 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8889e+02, 5.0149e-02, 3.7198e-03, 1.2581e-03, 1.8696e-03, 1.2821e-03,\n",
       "         1.3875e-03, 2.8682e-03, 1.8658e-03, 2.4622e-03, 2.1080e-03, 1.1290e-03,\n",
       "         2.6420e-03, 1.4306e-03, 2.0050e-03, 6.8406e-04, 1.1928e-03, 7.5844e-04,\n",
       "         2.2347e-03, 1.2908e-03, 1.3033e-03, 2.2954e-03, 3.0578e-03, 1.8767e-03,\n",
       "         5.8039e-03, 1.8915e-03, 1.8540e-03, 2.0353e-03, 2.6830e-03, 1.2019e-03,\n",
       "         3.9745e-03, 2.0309e-03, 2.2514e-03, 1.8984e-03, 3.5779e-03, 1.6918e-03,\n",
       "         1.6891e-03, 7.3595e-04, 1.9989e-03, 1.5965e-03, 1.5693e-03, 1.7259e-03,\n",
       "         3.3160e-03, 1.2352e-03, 3.3798e-03, 1.2150e-03, 2.7234e-03, 1.1300e-03,\n",
       "         1.6021e-03, 2.1845e-03, 1.5845e-03, 2.6526e-03, 1.9591e-03, 2.2918e-03,\n",
       "         1.3289e-03, 1.3255e-03, 2.6525e-03, 1.4677e-03, 3.1222e-03, 1.9648e-03,\n",
       "         4.3290e-03, 1.4332e-03, 3.8543e-03, 8.6919e-04],\n",
       "        [3.3024e+02, 1.4147e-01, 8.1604e-02, 1.4242e-01, 2.3399e-01, 1.5287e-01,\n",
       "         1.6023e-01, 2.8309e-01, 1.7085e-01, 2.1056e-01, 2.1280e-01, 7.6300e-02,\n",
       "         1.7907e-01, 1.7616e-01, 3.8847e-01, 2.7733e-01, 1.5472e-01, 1.7498e-01,\n",
       "         1.9010e-01, 2.4707e-01, 2.6952e-01, 1.4627e-01, 2.7089e-01, 2.4397e-01,\n",
       "         2.8438e-01, 2.4043e-01, 3.7315e-01, 1.2154e-01, 7.1512e-02, 2.0325e-01,\n",
       "         4.0645e-01, 3.4300e-01, 2.7953e-01, 2.5430e-01, 3.0652e-01, 1.6042e-01,\n",
       "         2.2478e-01, 1.8394e-01, 2.6974e-01, 5.2439e-01, 8.6791e-01, 4.2280e-01,\n",
       "         5.7818e-01, 7.4867e-01, 1.1775e+00, 4.6187e-01, 3.3225e-01, 2.4811e-01,\n",
       "         4.3457e-01, 2.7973e-01, 3.5005e-01, 3.9536e-01, 2.3795e-01, 3.8897e-01,\n",
       "         2.0771e-01, 1.5693e-01, 1.7807e-01, 1.9253e-01, 2.6960e-01, 2.6135e-01,\n",
       "         1.8709e-01, 2.3234e-01, 2.8642e-01, 1.6726e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['error_diff'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in model.predcells:\n",
    "    cell.error_diff_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
