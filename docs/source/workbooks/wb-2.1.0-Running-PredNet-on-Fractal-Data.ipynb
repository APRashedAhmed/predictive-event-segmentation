{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.0 Running PredNet on Fractal Data\n",
    "\n",
    "Getting the fractal data to work with the implemented prednet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 2020 19:42:35 \n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.4.0-42-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : apra-x3\n",
      "Git hash   : 3a3dff83da3f7b5527060c5ee1d9569065b84bea\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and other non-code related info\n",
    "%watermark -n -m -g -b -t -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networkx          2.4\n",
      "torch             1.6.0\n",
      "numpy             1.19.1\n",
      "prevseg           0+untagged.47.g3a3dff8.dirty\n",
      "pytorch_lightning 0.8.5\n",
      "logging           0.5.1.2\n",
      "PIL.Image         7.2.0\n",
      "CPython 3.8.5\n",
      "IPython 7.16.1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "%aimport prevseg.constants\n",
    "import prevseg.constants as const\n",
    "%aimport prevseg.index\n",
    "import prevseg.index as index\n",
    "%aimport prevseg.dataloaders.schapiro\n",
    "import prevseg.dataloaders.schapiro as sch\n",
    "%aimport prevseg.schapiro\n",
    "from prevseg.schapiro import walk, graph\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as prednet\n",
    "\n",
    "# Keep track of versions of everything\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Fixed Path-Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '39', 1: '78', 2: '91', 3: '36', 4: '9', 5: '55', 6: '23', 7: '101', 8: '52', 9: '35', 10: '49', 11: '100', 12: '46', 13: '10', 14: '59'}\n",
      "0 torch.Size([2, 2, 128, 128])\n",
      "1 torch.Size([2, 2, 128, 128])\n",
      "2 torch.Size([2, 2, 128, 128])\n",
      "3 torch.Size([2, 2, 128, 128])\n",
      "4 torch.Size([2, 2, 128, 128])\n",
      "5 torch.Size([2, 2, 128, 128])\n",
      "6 torch.Size([2, 2, 128, 128])\n",
      "7 torch.Size([2, 2, 128, 128])\n",
      "8 torch.Size([2, 2, 128, 128])\n",
      "bad\n",
      "0 torch.Size([2, 2, 128, 128])\n",
      "1 torch.Size([2, 2, 128, 128])\n",
      "2 torch.Size([2, 2, 128, 128])\n",
      "3 torch.Size([2, 2, 128, 128])\n",
      "4 torch.Size([2, 2, 128, 128])\n",
      "5 torch.Size([2, 2, 128, 128])\n",
      "6 torch.Size([2, 2, 128, 128])\n",
      "7 torch.Size([2, 2, 128, 128])\n",
      "8 torch.Size([2, 2, 128, 128])\n",
      "bad\n"
     ]
    }
   ],
   "source": [
    "max_steps = 2\n",
    "epochs = 2\n",
    "batch_size = 2\n",
    "\n",
    "iter_ds = sch.ShapiroFractalsDataset(batch_size=batch_size, max_steps=max_steps)\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "for _ in range(epochs):\n",
    "    for i, batch in enumerate(loader):\n",
    "        print(i, batch.shape)\n",
    "        if i > max_steps+5:\n",
    "            print('bad')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '53', 1: '98', 2: '69', 3: '65', 4: '85', 5: '33', 6: '75', 7: '20', 8: '16', 9: '28', 10: '64', 11: '72', 12: '76', 13: '99', 14: '54'}\n",
      "0 torch.Size([2, 10, 128, 128])\n",
      "1 torch.Size([2, 10, 128, 128])\n",
      "2 torch.Size([2, 10, 128, 128])\n",
      "3 torch.Size([2, 10, 128, 128])\n",
      "4 torch.Size([2, 10, 128, 128])\n",
      "0 torch.Size([2, 10, 128, 128])\n",
      "1 torch.Size([2, 10, 128, 128])\n",
      "2 torch.Size([2, 10, 128, 128])\n",
      "3 torch.Size([2, 10, 128, 128])\n",
      "4 torch.Size([2, 10, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "class ShapiroFractalsDataset(IterableDataset):\n",
    "    modes = set(('random', 'euclidean', 'hamiltonian'))\n",
    "    def __init__(self, batch_size=32, n_pentagons=3, max_steps=128, n_paths=128, mapping=None, \n",
    "                 mode='random', debug=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_pentagons = n_pentagons\n",
    "        self.max_steps = max_steps\n",
    "        self.n_paths = n_paths\n",
    "        self.mapping = mapping\n",
    "        self.mode = mode\n",
    "        self.debug = debug\n",
    "        assert self.mode in self.modes\n",
    "        \n",
    "        self.G = graph.schapiro_graph(n_pentagons=n_pentagons)\n",
    "        \n",
    "        self.load_node_stimuli()\n",
    "        \n",
    "        self.mapping = {node : path.stem\n",
    "                        for node, path in zip(range(len(self.G.nodes)),\n",
    "                                              self.paths_data)}\n",
    "        print(f'Created mapping as follows:\\n{self.mapping}')\n",
    "        \n",
    "        if self.debug:\n",
    "            self.sample_transform = lambda sample : sample\n",
    "        else:\n",
    "            self.sample_transform = lambda sample : self.array_data[sample]            \n",
    "        \n",
    "    def load_node_stimuli(self):\n",
    "        # Load the fractal images into memory\n",
    "        assert index.DIR_SCH_FRACTALS.exists()\n",
    "        if self.mapping:\n",
    "            self.paths_data = [index.DIR_SCH_FRACTALS / (name+'.tiff')\n",
    "                               for name in self.mapping.values()]\n",
    "        else:\n",
    "            paths_data = list(index.DIR_SCH_FRACTALS.iterdir())\n",
    "            np.random.shuffle(paths_data)\n",
    "            self.paths_data = paths_data[:5*self.n_pentagons]\n",
    "        self.array_data = np.array(\n",
    "            [np.array(ImageOps.grayscale(Image.open(str(path))))\n",
    "             for path in self.paths_data])\n",
    "        \n",
    "    def iter_single_sample(self): \n",
    "        if self.mode == 'random':\n",
    "            iter_walk = walk.walk_random(self.G, steps=self.max_steps)\n",
    "        elif self.mode == 'euclidean':\n",
    "            iter_walk = walk.walk_euclidean(self.G)\n",
    "        elif self.mode == 'hamiltonian':\n",
    "            iter_walk = walk.walk_hamiltonian(self.G)\n",
    "        \n",
    "        for sample in iter_walk:\n",
    "            yield self.sample_transform(sample[0])\n",
    "        \n",
    "    def iter_batch_sample(self):\n",
    "        yield from zip(*[self.iter_single_sample() for _ in range(self.batch_size)])\n",
    "        \n",
    "    def iter_batch_dataset(self):       \n",
    "        for _ in range(self.n_paths):\n",
    "            yield np.moveaxis(np.array(list(self.iter_batch_sample())), 0, 1)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self.iter_batch_dataset()\n",
    "\n",
    "    \n",
    "max_steps = 10\n",
    "epochs = 2\n",
    "batch_size = 2\n",
    "n_paths = 5\n",
    "\n",
    "iter_ds = ShapiroFractalsDataset(batch_size=batch_size, max_steps=max_steps, n_paths=n_paths)\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "for _ in range(epochs):\n",
    "    for i, batch in enumerate(loader):\n",
    "        print(i, batch.shape)\n",
    "        if i > max_steps+5:\n",
    "            print('bad')\n",
    "            break\n",
    "            \n",
    "mapping = iter_ds.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '53', 1: '98', 2: '69', 3: '65', 4: '85', 5: '33', 6: '75', 7: '20', 8: '16', 9: '28', 10: '64', 11: '72', 12: '76', 13: '99', 14: '54'}\n",
      "0 torch.Size([2, 10, 2048])\n",
      "1 torch.Size([2, 10, 2048])\n",
      "2 torch.Size([2, 10, 2048])\n",
      "3 torch.Size([2, 10, 2048])\n",
      "4 torch.Size([2, 10, 2048])\n",
      "0 torch.Size([2, 10, 2048])\n",
      "1 torch.Size([2, 10, 2048])\n",
      "2 torch.Size([2, 10, 2048])\n",
      "3 torch.Size([2, 10, 2048])\n",
      "4 torch.Size([2, 10, 2048])\n"
     ]
    }
   ],
   "source": [
    "max_steps = 10\n",
    "epochs = 2\n",
    "batch_size = 2\n",
    "n_paths = 5\n",
    "\n",
    "class ShapiroResnetEmbeddingDataset(ShapiroFractalsDataset):\n",
    "    def load_node_stimuli(self):\n",
    "        # Load the fractal images into memory\n",
    "        assert index.DIR_SCH_FRACTALS.exists()\n",
    "        if self.mapping:\n",
    "            self.paths_data = [index.DIR_SCH_FRACTALS_EMB / (name+'.npy')\n",
    "                               for name in self.mapping.values()]\n",
    "        else:\n",
    "            paths_data = list(index.DIR_SCH_FRACTALS_EMB.iterdir())\n",
    "            np.random.shuffle(paths_data)\n",
    "            self.paths_data = paths_data[:5*self.n_pentagons]\n",
    "        self.array_data = np.array(\n",
    "            [np.array(np.load(str(path)))\n",
    "             for path in self.paths_data])    \n",
    "\n",
    "iter_ds = ShapiroResnetEmbeddingDataset(\n",
    "    batch_size=batch_size, \n",
    "    max_steps=max_steps, \n",
    "    n_paths=n_paths,\n",
    "    mapping=mapping,\n",
    ")\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "for _ in range(epochs):\n",
    "    for i, batch in enumerate(loader):\n",
    "        print(i, batch.shape)\n",
    "        if i > max_steps+5:\n",
    "            print('bad')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PredNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredNetTracked(prednet.PredNetTracked):\n",
    "    @prednet.PredNet.timeit\n",
    "    def prepare_data(self):\n",
    "        self.ds = self.ds or ShapiroResnetEmbeddingDataset(\n",
    "            batch_size=self.batch_size, \n",
    "            n_pentagons=self.hparams.n_pentagons, \n",
    "            max_steps=self.hparams.max_steps, \n",
    "            n_paths=self.hparams.n_paths,\n",
    "            debug=self.hparams.debug)\n",
    "        self.ds_val = ShapiroResnetEmbeddingDataset(\n",
    "            batch_size=self.batch_size, \n",
    "            n_pentagons=self.hparams.n_pentagons,\n",
    "            n_paths=1,\n",
    "            mapping=self.ds.mapping,\n",
    "            mode='euclidean',\n",
    "            debug=self.hparams.debug)\n",
    "        \n",
    "#         n_test, n_val = self.hparams.n_test, self.hparams.n_val\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds, \n",
    "                          batch_size=None,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, \n",
    "                          batch_size=None,\n",
    "                          num_workers=self.hparams.n_workers)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx, mode):\n",
    "        data = batch\n",
    "        errors = self.forward(data) # batch x n_layers x nt\n",
    "\n",
    "        loc_batch = errors.size(0)\n",
    "        errors = torch.mm(errors.view(-1, self.time_steps), \n",
    "                          self.time_loss_weights) # batch*n_layers x 1\n",
    "        errors = torch.mm(errors.view(loc_batch, -1), \n",
    "                          self.layer_loss_weights)\n",
    "        errors = torch.mean(errors, axis=0)\n",
    "        \n",
    "        if mode == 'train':\n",
    "            prefix = ''\n",
    "        else:\n",
    "            prefix = mode + '_'\n",
    "            \n",
    "        self.logger.experiment.add_scalar(f'{prefix}loss', \n",
    "                                          errors, self.global_step)\n",
    "        return {f'{prefix}loss' : errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "res = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ModelClass = PredNetTracked\n",
    "hparams = const.DEFAULT_HPARAMS\n",
    "hparams.n_layers = 2\n",
    "hparams.batch_size = 256 + 128\n",
    "hparams.max_steps = 128\n",
    "hparams.n_paths = 16\n",
    "hparams.n_pentagons = 3\n",
    "hparams.time_steps = hparams.max_steps\n",
    "hparams.exp_name = 'schapiro_test'\n",
    "hparams.name = f'{ModelClass.name}_{hparams.exp_name}'\n",
    "hparams.debug = False\n",
    "hparams.n_workers = 2\n",
    "hparams.lr = 0.001\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / (hparams.exp_name+'_{global_step:05d}_{epoch:03d}_{val_loss:.3f}')),\n",
    "    verbose=True,\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(checkpoint_callback=ckpt,\n",
    "                     max_epochs=20,\n",
    "                     logger=logger,\n",
    "                     gpus=1\n",
    "                     )\n",
    "\n",
    "model = ModelClass(hparams)\n",
    "model.ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                 | Type       | Params\n",
      "----------------------------------------------------\n",
      "0 | predcell_0_recurrent | LSTM       | 67 M  \n",
      "1 | predcell_0_dense     | Sequential | 4 M   \n",
      "2 | predcell_0_update_a  | Sequential | 4 M   \n",
      "3 | predcell_1_recurrent | LSTM       | 12 M  \n",
      "4 | predcell_1_dense     | Sequential | 1 M   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '1', 1: '60', 2: '95', 3: '100', 4: '14', 5: '2', 6: '63', 7: '58', 8: '96', 9: '55', 10: '99', 11: '50', 12: '7', 13: '89', 14: '12'}\n",
      "Created mapping as follows:\n",
      "{0: '1', 1: '60', 2: '95', 3: '100', 4: '14', 5: '2', 6: '63', 7: '58', 8: '96', 9: '55', 10: '99', 11: '50', 12: '7', 13: '89', 14: '12'}\n",
      "Epoch 1: : 32it [03:50,  7.19s/it, loss=0.157, v_num=47]              \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: : 33it [03:50,  7.00s/it, loss=0.157, v_num=47]\n",
      "Epoch 1: : 34it [03:51,  6.81s/it, loss=0.157, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00000: val_loss reached 0.15527 (best 0.15527), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00031_epoch=000_val_loss=0.155.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 34it [03:53,  6.88s/it, loss=0.157, v_num=47]\n",
      "Epoch 2: : 32it [03:49,  7.17s/it, loss=0.152, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: : 33it [03:50,  6.97s/it, loss=0.152, v_num=47]\n",
      "Epoch 2: : 34it [03:50,  6.79s/it, loss=0.152, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss reached 0.15085 (best 0.15085), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00063_epoch=001_val_loss=0.151.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 34it [03:53,  6.86s/it, loss=0.152, v_num=47]\n",
      "Epoch 3: : 32it [03:48,  7.15s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: : 33it [03:49,  6.96s/it, loss=0.149, v_num=47]\n",
      "Epoch 3: : 34it [03:50,  6.77s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss reached 0.14926 (best 0.14926), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00095_epoch=002_val_loss=0.149.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: : 34it [03:52,  6.84s/it, loss=0.149, v_num=47]\n",
      "Epoch 4: : 32it [03:48,  7.14s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: : 33it [03:49,  6.95s/it, loss=0.149, v_num=47]\n",
      "Epoch 4: : 34it [03:49,  6.76s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss reached 0.14920 (best 0.14920), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00127_epoch=003_val_loss=0.149.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: : 34it [03:52,  6.83s/it, loss=0.149, v_num=47]\n",
      "Epoch 5: : 32it [03:49,  7.16s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: : 33it [03:49,  6.96s/it, loss=0.149, v_num=47]\n",
      "Epoch 5: : 34it [03:50,  6.77s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: : 34it [03:50,  6.77s/it, loss=0.149, v_num=47]\n",
      "Epoch 6: : 32it [03:49,  7.16s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: : 33it [03:49,  6.97s/it, loss=0.149, v_num=47]\n",
      "Epoch 6: : 34it [03:50,  6.78s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: : 34it [03:50,  6.78s/it, loss=0.149, v_num=47]\n",
      "Epoch 7: : 32it [03:48,  7.15s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: : 33it [03:49,  6.96s/it, loss=0.149, v_num=47]\n",
      "Epoch 7: : 34it [03:50,  6.77s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: : 34it [03:50,  6.77s/it, loss=0.149, v_num=47]\n",
      "Epoch 8: : 32it [03:48,  7.15s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: : 33it [03:49,  6.96s/it, loss=0.149, v_num=47]\n",
      "Epoch 8: : 34it [03:50,  6.77s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: : 34it [03:50,  6.77s/it, loss=0.149, v_num=47]\n",
      "Epoch 9: : 32it [03:48,  7.15s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: : 33it [03:49,  6.95s/it, loss=0.149, v_num=47]\n",
      "Epoch 9: : 34it [03:49,  6.76s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss reached 0.14918 (best 0.14918), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00287_epoch=008_val_loss=0.149.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 34it [03:52,  6.84s/it, loss=0.149, v_num=47]\n",
      "Epoch 10: : 32it [03:47,  7.12s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: : 33it [03:48,  6.92s/it, loss=0.149, v_num=47]\n",
      "Epoch 10: : 34it [03:48,  6.74s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: : 34it [03:49,  6.74s/it, loss=0.149, v_num=47]\n",
      "Epoch 11: : 32it [03:48,  7.13s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: : 33it [03:49,  6.94s/it, loss=0.149, v_num=47]\n",
      "Epoch 11: : 34it [03:49,  6.75s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: : 34it [03:49,  6.75s/it, loss=0.149, v_num=47]\n",
      "Epoch 12: : 32it [03:48,  7.15s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: : 33it [03:49,  6.96s/it, loss=0.149, v_num=47]\n",
      "Epoch 12: : 34it [03:50,  6.77s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss reached 0.14911 (best 0.14911), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00383_epoch=011_val_loss=0.149.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: : 34it [03:52,  6.84s/it, loss=0.149, v_num=47]\n",
      "Epoch 13: : 32it [03:48,  7.14s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: : 33it [03:49,  6.95s/it, loss=0.149, v_num=47]\n",
      "Epoch 13: : 34it [03:49,  6.76s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss reached 0.14901 (best 0.14901), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00415_epoch=012_val_loss=0.149.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: : 34it [03:52,  6.83s/it, loss=0.149, v_num=47]\n",
      "Epoch 14: : 32it [03:48,  7.13s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: : 33it [03:49,  6.94s/it, loss=0.149, v_num=47]\n",
      "Epoch 14: : 34it [03:49,  6.75s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_loss reached 0.14899 (best 0.14899), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00447_epoch=013_val_loss=0.149.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: : 34it [03:52,  6.83s/it, loss=0.149, v_num=47]\n",
      "Epoch 15: : 32it [03:48,  7.13s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: : 33it [03:48,  6.94s/it, loss=0.149, v_num=47]\n",
      "Epoch 15: : 34it [03:49,  6.75s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: : 34it [03:49,  6.75s/it, loss=0.149, v_num=47]\n",
      "Epoch 16: : 32it [03:48,  7.13s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: : 33it [03:48,  6.93s/it, loss=0.149, v_num=47]\n",
      "Epoch 16: : 34it [03:49,  6.74s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss reached 0.14899 (best 0.14899), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v47/schapiro_test_global_step=00511_epoch=015_val_loss=0.149.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: : 34it [03:51,  6.82s/it, loss=0.149, v_num=47]\n",
      "Epoch 17: : 32it [03:48,  7.13s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: : 33it [03:48,  6.93s/it, loss=0.149, v_num=47]\n",
      "Epoch 17: : 34it [03:49,  6.74s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: : 34it [03:49,  6.75s/it, loss=0.149, v_num=47]\n",
      "Epoch 18: : 32it [03:48,  7.14s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: : 33it [03:49,  6.95s/it, loss=0.149, v_num=47]\n",
      "Epoch 18: : 34it [03:49,  6.76s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: : 34it [03:49,  6.76s/it, loss=0.149, v_num=47]\n",
      "Epoch 19: : 32it [03:49,  7.16s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: : 33it [03:49,  6.97s/it, loss=0.149, v_num=47]\n",
      "Epoch 19: : 34it [03:50,  6.78s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: : 34it [03:50,  6.78s/it, loss=0.149, v_num=47]\n",
      "Epoch 20: : 32it [03:48,  7.14s/it, loss=0.149, v_num=47]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: : 33it [03:49,  6.95s/it, loss=0.149, v_num=47]\n",
      "Epoch 20: : 34it [03:49,  6.76s/it, loss=0.149, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: : 34it [03:49,  6.76s/it, loss=0.149, v_num=47]\n",
      "Epoch 20: : 34it [03:49,  6.76s/it, loss=0.149, v_num=47]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best LR was 0.000333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical PredNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "res = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ModelClass = PredNetTracked\n",
    "hparams = const.DEFAULT_HPARAMS\n",
    "hparams.n_layers = 3\n",
    "hparams.batch_size = 256 + 32\n",
    "hparams.max_steps = 128\n",
    "hparams.n_paths = 16\n",
    "hparams.n_pentagons = 3\n",
    "hparams.time_steps = hparams.max_steps\n",
    "hparams.exp_name = 'schapiro_test'\n",
    "hparams.name = f'{ModelClass.name}_{hparams.exp_name}'\n",
    "hparams.debug = False\n",
    "hparams.n_workers = 2\n",
    "hparams.lr = 0.000333\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / (hparams.exp_name+'_{global_step:05d}_{epoch:03d}_{val_loss:.3f}')),\n",
    "    verbose=True,\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(checkpoint_callback=ckpt,\n",
    "                     max_epochs=25,\n",
    "                     logger=logger,\n",
    "                     gpus=1\n",
    "                     )\n",
    "\n",
    "model = ModelClass(hparams)\n",
    "model.ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                 | Type       | Params\n",
      "----------------------------------------------------\n",
      "0 | predcell_0_recurrent | LSTM       | 67 M  \n",
      "1 | predcell_0_dense     | Sequential | 4 M   \n",
      "2 | predcell_0_update_a  | Sequential | 4 M   \n",
      "3 | predcell_1_recurrent | LSTM       | 16 M  \n",
      "4 | predcell_1_dense     | Sequential | 1 M   \n",
      "5 | predcell_1_update_a  | Sequential | 1 M   \n",
      "6 | predcell_2_recurrent | LSTM       | 3 M   \n",
      "7 | predcell_2_dense     | Sequential | 262 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '1', 1: '60', 2: '95', 3: '100', 4: '14', 5: '2', 6: '63', 7: '58', 8: '96', 9: '55', 10: '99', 11: '50', 12: '7', 13: '89', 14: '12'}\n",
      "Created mapping as follows:\n",
      "{0: '1', 1: '60', 2: '95', 3: '100', 4: '14', 5: '2', 6: '63', 7: '58', 8: '96', 9: '55', 10: '99', 11: '50', 12: '7', 13: '89', 14: '12'}\n",
      "Epoch 1: : 32it [03:48,  7.13s/it, loss=0.116, v_num=52]              \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: : 33it [03:48,  6.94s/it, loss=0.116, v_num=52]\n",
      "Epoch 1: : 34it [03:49,  6.75s/it, loss=0.116, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00000: val_loss reached 0.11156 (best 0.11156), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v52/schapiro_test_global_step=00031_epoch=000_val_loss=0.112.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 34it [03:52,  6.83s/it, loss=0.116, v_num=52]\n",
      "Epoch 2: : 32it [03:50,  7.20s/it, loss=0.107, v_num=52]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: : 33it [03:51,  7.01s/it, loss=0.107, v_num=52]\n",
      "Epoch 2: : 34it [03:51,  6.82s/it, loss=0.107, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss reached 0.10622 (best 0.10622), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v52/schapiro_test_global_step=00063_epoch=001_val_loss=0.106.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 34it [03:54,  6.90s/it, loss=0.107, v_num=52]\n",
      "Epoch 3: : 32it [03:50,  7.20s/it, loss=0.106, v_num=52]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: : 33it [03:51,  7.00s/it, loss=0.106, v_num=52]\n",
      "Epoch 3: : 34it [03:51,  6.82s/it, loss=0.106, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss reached 0.10588 (best 0.10588), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v52/schapiro_test_global_step=00095_epoch=002_val_loss=0.106.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: : 34it [03:54,  6.90s/it, loss=0.106, v_num=52]\n",
      "Epoch 4: : 32it [03:51,  7.24s/it, loss=0.106, v_num=52]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: : 33it [03:52,  7.05s/it, loss=0.106, v_num=52]\n",
      "Epoch 4: : 34it [03:53,  6.85s/it, loss=0.106, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss  was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: : 34it [03:53,  6.86s/it, loss=0.106, v_num=52]\n",
      "Epoch 5: : 32it [03:52,  7.26s/it, loss=0.106, v_num=52]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: : 33it [03:53,  7.07s/it, loss=0.106, v_num=52]\n",
      "Epoch 5: : 34it [03:53,  6.87s/it, loss=0.106, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss reached 0.10575 (best 0.10575), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v52/schapiro_test_global_step=00159_epoch=004_val_loss=0.106.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: : 34it [03:56,  6.96s/it, loss=0.106, v_num=52]\n",
      "Epoch 6: : 32it [03:51,  7.24s/it, loss=0.106, v_num=52]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: : 33it [03:52,  7.05s/it, loss=0.106, v_num=52]\n",
      "Epoch 6: : 34it [03:53,  6.85s/it, loss=0.106, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss reached 0.10571 (best 0.10571), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v52/schapiro_test_global_step=00191_epoch=005_val_loss=0.106.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: : 34it [03:55,  6.94s/it, loss=0.106, v_num=52]\n",
      "Epoch 7: : 32it [03:51,  7.22s/it, loss=0.106, v_num=52]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: : 33it [03:51,  7.03s/it, loss=0.106, v_num=52]\n",
      "Epoch 7: : 34it [03:52,  6.84s/it, loss=0.106, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss reached 0.10567 (best 0.10567), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v52/schapiro_test_global_step=00223_epoch=006_val_loss=0.106.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: : 34it [03:55,  6.92s/it, loss=0.106, v_num=52]\n",
      "Epoch 8: : 32it [03:51,  7.22s/it, loss=0.106, v_num=52]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: : 33it [03:51,  7.02s/it, loss=0.106, v_num=52]\n",
      "Epoch 8: : 34it [03:52,  6.83s/it, loss=0.106, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss reached 0.10558 (best 0.10558), saving model to /home/apra/work/predictive-event-segmentation/models/checkpoints/prednet_tracked_schapiro_test_v52/schapiro_test_global_step=00255_epoch=007_val_loss=0.106.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: : 34it [03:55,  6.92s/it, loss=0.106, v_num=52]\n",
      "Epoch 9: : 24it [03:01,  7.55s/it, loss=0.106, v_num=52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apra/miniconda3/envs/g2/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/apra/miniconda3/envs/g2/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/apra/miniconda3/envs/g2/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/apra/miniconda3/envs/g2/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/apra/miniconda3/envs/g2/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/apra/miniconda3/envs/g2/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/apra/miniconda3/envs/g2/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/apra/miniconda3/envs/g2/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
