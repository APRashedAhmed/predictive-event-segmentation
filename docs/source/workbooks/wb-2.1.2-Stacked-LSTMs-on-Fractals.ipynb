{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2 Stacked LSTMs on Fractals\n",
    "\n",
    "PredNet representations match the ones of human fMRI. How about LSTMS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 07 2020 19:06:14 \n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.4.0-45-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : apra-x3\n",
      "Git hash   : fd56f033dc8b98d92ac6d31c2ea68f0df697413a\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and other non-code related info\n",
    "%watermark -n -m -g -b -t -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy             1.19.1\n",
      "logging           0.5.1.2\n",
      "networkx          2.4\n",
      "pytorch_lightning 0.8.5\n",
      "prevseg           0+untagged.85.gfd56f03.dirty\n",
      "torch             1.6.0\n",
      "PIL.Image         7.2.0\n",
      "CPython 3.8.5\n",
      "IPython 7.16.1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "%aimport prevseg.constants\n",
    "import prevseg.constants as const\n",
    "%aimport prevseg.index\n",
    "import prevseg.index as index\n",
    "%aimport prevseg.dataloaders.schapiro\n",
    "import prevseg.dataloaders.schapiro as sch\n",
    "%aimport prevseg.schapiro\n",
    "from prevseg.schapiro import walk, graph\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as pn\n",
    "%aimport prevseg.torch.lstm\n",
    "import prevseg.torch.lstm as lstm\n",
    "%aimport prevseg.torch.activations\n",
    "import prevseg.torch.activations as act\n",
    "\n",
    "\n",
    "# Keep track of versions of everything\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(pn.PredCellTracked):\n",
    "    name = 'lstmcell'\n",
    "    \n",
    "    def __init__(self, parent, layer_num, hparams, a_channels, r_channels, *args, **kwargs):\n",
    "        self.build_dense = lambda *args, **kwargs : None\n",
    "        self.build_update = lambda *args, **kwargs : None\n",
    "        super().__init__(parent, layer_num, hparams, a_channels, r_channels, *args, **kwargs)\n",
    "        \n",
    "    def build_recurrent(self):\n",
    "        recurrent = self.RecurrentClass(\n",
    "            self.a_channels[self.layer_num],\n",
    "            #+ self.r_channels[self.layer_num+1],\n",
    "            self.r_channels[self.layer_num])\n",
    "        recurrent.reset_parameters()\n",
    "        return recurrent\n",
    "        \n",
    "    def reset(self, batch_size=None):\n",
    "        batch_size = batch_size or self.hparams.batch_size\n",
    "        self.R = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             self.r_channels[self.layer_num],\n",
    "                             device=self.parent.dev)\n",
    "        self.H = (torch.zeros(1,                  # Single time step\n",
    "                              batch_size,\n",
    "                              self.r_channels[self.layer_num],\n",
    "                              device=self.parent.dev),\n",
    "                  torch.zeros(1,                  # Single time step\n",
    "                              batch_size,\n",
    "                              self.r_channels[self.layer_num],\n",
    "                              device=self.parent.dev))\n",
    "        self.hidden_full_list = []\n",
    "        self.hidden_diff_list = []\n",
    "        self.representation_full_list = []\n",
    "        self.representation_diff_list = []        \n",
    "        \n",
    "    def update_parent(self, module_names=('recurrent',)):\n",
    "        return super().update_parent(module_names=module_names)\n",
    "\n",
    "class LSTMStacked(pn.PredNetTrackedSchapiro):\n",
    "    name = 'lstmstacked'\n",
    "    def __init__(self, hparams, CellClass=LSTMCell, a_channels=None,\n",
    "                 r_channels=None, *args, **kwargs):\n",
    "        # Assertions for how it should be used\n",
    "        assert hparams.layer_loss_mode is None\n",
    "        \n",
    "        if a_channels is None:\n",
    "            a_channels = [hparams.input_size] * hparams.n_layers\n",
    "        if r_channels is None:\n",
    "            r_channels = list(a_channels) + [0,]\n",
    "        # Run the init and cleanup\n",
    "        super().__init__(hparams=hparams, CellClass=CellClass, r_channels=r_channels,\n",
    "                         a_channels=a_channels, *args, **kwargs)\n",
    "        # Add the last dense layer\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(self.r_channels[hparams.n_layers - 1],\n",
    "                      self.a_channels[0]),\n",
    "            nn.ReLU())\n",
    "        self.dense.add_module('satlu', act.SatLU())\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        total_output = []\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            self.frame = input[:,t,:].unsqueeze(0).to(self.dev, torch.float)\n",
    "            A = self.frame\n",
    "            for cell in self.cells:\n",
    "                # First time step\n",
    "                if t == 0:\n",
    "                    hx = (cell.R, cell.R)\n",
    "                else:\n",
    "                    hx = cell.H\n",
    "                    \n",
    "                cell.R, cell.H = cell.recurrent(A, hx)\n",
    "                # Optional tracking\n",
    "                cell.track_hidden(self.output_mode, hx)\n",
    "                cell.track_representation(self.output_mode, A)\n",
    "                A = cell.R\n",
    "                \n",
    "            A_hat = self.dense(A)\n",
    "            \n",
    "            if self.output_mode == 'error':\n",
    "                total_output.append(torch.abs(A_hat - self.frame))\n",
    "            elif self.output_mode == 'eval':\n",
    "                total_output.append(A_hat)\n",
    "        \n",
    "        if self.output_mode == 'prediction':\n",
    "            return A_hat\n",
    "        else:\n",
    "            return torch.stack(total_output, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/apra/miniconda3/envs/g2/lib/python3.8/site-packages/torch/cuda/__init__.py:102: UserWarning: \n",
      "    Found GPU1 GeForce GTX 670 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n",
      "/home/apra/miniconda3/envs/g2/lib/python3.8/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "GeForce GTX 670 with CUDA capability sm_30 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the GeForce GTX 670 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMStacked(\n",
       "  (lstmcell_0_recurrent): LSTM(\n",
       "    (i2h): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (h2h): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "  )\n",
       "  (lstmcell_1_recurrent): LSTM(\n",
       "    (i2h): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (h2h): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "  )\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (satlu): SatLU (min_val=0, max_val=255)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "res = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "hparams = const.DEFAULT_HPARAMS\n",
    "\n",
    "ModelClass = LSTMStacked\n",
    "hparams.layer_loss_mode = None\n",
    "hparams.n_layers = 2\n",
    "hparams.batch_size = 256 + 128 + 64\n",
    "hparams.max_steps = 128\n",
    "hparams.n_paths = 16\n",
    "hparams.n_pentagons = 3\n",
    "hparams.time_steps = hparams.max_steps\n",
    "hparams.exp_name = 'schapiro_test'\n",
    "hparams.name = f'{ModelClass.name}_{hparams.exp_name}'\n",
    "hparams.debug = False\n",
    "hparams.n_workers = 4\n",
    "hparams.lr = 0.001\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / (hparams.exp_name+'_{global_step:05d}_{epoch:03d}_{val_loss:.3f}')),\n",
    "    verbose=True,\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(checkpoint_callback=ckpt,\n",
    "                     max_epochs=20,\n",
    "                     logger=logger,\n",
    "                     gpus=1\n",
    "                     )\n",
    "\n",
    "model = ModelClass(hparams)\n",
    "model.ds = None\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                 | Type       | Params\n",
      "----------------------------------------------------\n",
      "0 | lstmcell_0_recurrent | LSTM       | 33 M  \n",
      "1 | lstmcell_1_recurrent | LSTM       | 33 M  \n",
      "2 | dense                | Sequential | 4 M   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '1', 1: '60', 2: '95', 3: '100', 4: '14', 5: '2', 6: '63', 7: '58', 8: '96', 9: '55', 10: '99', 11: '50', 12: '7', 13: '89', 14: '12'}\n",
      "Created mapping as follows:\n",
      "{0: '1', 1: '60', 2: '95', 3: '100', 4: '14', 5: '2', 6: '63', 7: '58', 8: '96', 9: '55', 10: '99', 11: '50', 12: '7', 13: '89', 14: '12'}\n",
      "Epoch 1: : 20it [02:28,  7.44s/it, loss=0.397, v_num=36]              "
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ds = ShapiroResnetEmbeddingDataset(\n",
    "    batch_size=1, \n",
    "    max_steps=hparams.max_steps, \n",
    "    n_paths=1,\n",
    "    mapping=model.ds.mapping,\n",
    "    mode='euclidean')\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "\n",
    "for data, nodes in loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = torch.cat((data, torch.flip(data, (0,1))[:,1:,:]), 1)\n",
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model.forward(data_all, output_mode='eval', run_num='fwd_rev', \n",
    "                     tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.array(nodes).reshape(30)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_all = np.concatenate((nodes, np.flip(nodes)[1:]))\n",
    "nodes_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(nodes_all):\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = [9, 19, 29, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph.schapiro_graph(n_pentagons=3)\n",
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_pe = model.forward(data_all, output_mode='error', run_num='fwd_rev', \n",
    "                        tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_array = outs_pe[0,:,:].cpu().detach().numpy()\n",
    "outs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs_array):\n",
    "    ax = fig.add_subplot(11 + i + len(outs_array)*100)\n",
    "    ax.plot(out)\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs_array)-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Error Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs['error_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(outs['error_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(59))\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs['error_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden State Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs['hidden_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(outs['hidden_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(59)[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs['hidden_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Within vs Between Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nodes = [6,8,9,\n",
    "              10,9,10,\n",
    "              13,12,14,\n",
    "              0,14,0,\n",
    "              1,2,4,\n",
    "              5,4,5]\n",
    "test_data = np.array([iter_ds.array_data[n] \n",
    "                      for n in test_nodes]).reshape((1,len(test_nodes),2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_outs = model.forward(torch.Tensor(test_data), \n",
    "                            output_mode='eval', \n",
    "                            run_num='border_walk_3', \n",
    "                            tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(border_outs['hidden_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(border_outs['hidden_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(len(test_nodes))[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    if i == len(border_outs['hidden_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
