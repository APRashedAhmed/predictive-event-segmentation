{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2 Stacked LSTMs on Fractals\n",
    "\n",
    "PredNet representations match the ones of human fMRI. How about LSTMS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 07 2020 16:24:10 \n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-112-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "host name  : serrep5\n",
      "Git hash   : 91cf962d479e31019f2f7d1cf3d2cfa3f0cdb83c\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and other non-code related info\n",
    "%watermark -n -m -g -b -t -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networkx          2.4\n",
      "torch             1.6.0\n",
      "numpy             1.19.1\n",
      "pytorch_lightning 0.8.5\n",
      "prevseg           0+untagged.82.g91cf962.dirty\n",
      "logging           0.5.1.2\n",
      "PIL.Image         7.2.0\n",
      "CPython 3.8.5\n",
      "IPython 7.16.1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "%aimport prevseg.constants\n",
    "import prevseg.constants as const\n",
    "%aimport prevseg.index\n",
    "import prevseg.index as index\n",
    "%aimport prevseg.dataloaders.schapiro\n",
    "import prevseg.dataloaders.schapiro as sch\n",
    "%aimport prevseg.schapiro\n",
    "from prevseg.schapiro import walk, graph\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as pn\n",
    "%aimport prevseg.torch.lstm\n",
    "import prevseg.torch.lstm as lstm\n",
    "%aimport prevseg.torch.activations\n",
    "import prevseg.torch.activations as act\n",
    "\n",
    "\n",
    "# Keep track of versions of everything\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Embedding Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '86', 1: '25', 2: '30', 3: '42', 4: '47', 5: '41', 6: '24', 7: '26', 8: '44', 9: '35', 10: '91', 11: '73', 12: '62', 13: '63', 14: '72'}\n",
      "0 torch.Size([2, 2, 2048]) [[9, 6], [6, 9]]\n",
      "1 torch.Size([2, 2, 2048]) [[10, 11], [13, 14]]\n",
      "0 torch.Size([2, 2, 2048]) [[12, 1], [13, 0]]\n",
      "1 torch.Size([2, 2, 2048]) [[5, 0], [8, 3]]\n"
     ]
    }
   ],
   "source": [
    "max_steps = 2\n",
    "epochs = 2\n",
    "batch_size = 2\n",
    "n_paths = 2\n",
    "\n",
    "iter_ds = sch.ShapiroResnetEmbeddingDataset(\n",
    "    batch_size=batch_size, \n",
    "    max_steps=max_steps, \n",
    "    n_paths=n_paths,\n",
    ")\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for i, batch in enumerate(loader):\n",
    "        print(i, batch[0].shape, batch[1])\n",
    "        if i == n_paths:\n",
    "            print('bad')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(pn.PredCellTracked):\n",
    "    name = 'lstmcell'\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.build_dense = lambda *args, **kwargs : None\n",
    "        self.build_update = lambda *args, **kwargs : None\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def build_recurrent(self):\n",
    "        recurrent = self.RecurrentClass(\n",
    "            self.a_channels[self.layer_num],\n",
    "            #+ self.r_channels[self.layer_num+1],\n",
    "            self.r_channels[self.layer_num])\n",
    "        recurrent.reset_parameters()\n",
    "        return recurrent\n",
    "        \n",
    "    def reset(self, batch_size=None):\n",
    "        batch_size = batch_size or self.hparams.batch_size\n",
    "        self.R = torch.zeros(1,                  # Single time step\n",
    "                             batch_size,\n",
    "                             self.r_channels[self.layer_num],\n",
    "                             device=self.parent.device)\n",
    "        self.H = None\n",
    "        self.hidden_full_list = []\n",
    "        self.hidden_diff_list = []\n",
    "        self.representation_full_list = []\n",
    "        self.representation_diff_list = []        \n",
    "        \n",
    "    def update_parent(self, module_names=('recurrent')):\n",
    "        return super().update_parent(module_names=module_names)\n",
    "\n",
    "class LSTMStacked(pn.PredNetTrackedSchapiro):\n",
    "    name = 'lstmstacked'\n",
    "    def __init__(self, hparams, CellClass=LSTMCell, a_channels=None,\n",
    "                 r_channels=None, *args, **kwargs):\n",
    "        # Assertions for how it should be used\n",
    "        assert hparams.layer_loss_mode is None\n",
    "        \n",
    "        if a_channels is None:\n",
    "            a_channels = [hparams.input_size] * hparams.n_layers\n",
    "        if r_channels is None:\n",
    "            r_channels = list(a_channels) + [0,]\n",
    "        # Run the init and cleanup\n",
    "        super().__init__(hparams=hparams, CellClass=CellClass, r_channels=r_channels,\n",
    "                         a_channels=a_channels, *args, **kwargs)\n",
    "        del self.top_down_pass\n",
    "        del self.bottom_up_pass\n",
    "        # Add the last dense layer\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(self.r_channels[hparams.n_layers - 1],\n",
    "                      self.a_channels[0]),\n",
    "            act.SatLU())\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, time_steps, *_ = self.check_input_shape(input)\n",
    "        \n",
    "        total_output = []\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            self.frame = input[:,t,:].unsqueeze(0).to(self.dev, torch.float)\n",
    "            A = self.frame\n",
    "            for cell in self.cells:\n",
    "                # First time step\n",
    "                if t == 0:\n",
    "                    hx = (cell.R, cell.R)\n",
    "                else:\n",
    "                    hx = cell.H\n",
    "                    \n",
    "                cell.R, cell.H = cell.recurrent(A, hx)\n",
    "                # Optional tracking\n",
    "                cell.track_hidden(self.output_mode, hx)\n",
    "                cell.track_representation(self.output_mode, A)\n",
    "                A = cell.R\n",
    "                \n",
    "            A_hat = self.dense(A)\n",
    "            \n",
    "            if self.output_mode == 'error':\n",
    "                total_output.append(torch.mean(A_hat - A))\n",
    "            elif self.output_mode == 'eval':\n",
    "                total_output.append(A_hat)\n",
    "        \n",
    "        if self.output_mode == 'prediction':\n",
    "            return A_hat\n",
    "        else:\n",
    "            return total_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nThe NVIDIA driver on your system is too old (found version 10010).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: https://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2f98628b436f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                      )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-51b6f3eb5839>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparams, CellClass, a_channels, r_channels, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mr_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_channels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Run the init and cleanup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         super().__init__(hparams=hparams, CellClass=CellClass, r_channels=r_channels,\n\u001b[0m\u001b[1;32m     45\u001b[0m                          a_channels=a_channels, *args, **kwargs)\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_down_pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/predictive-event-segmentation/prevseg/models/prednet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparams, track, CellClass, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m     def __init__(self, hparams, track=None, CellClass=PredCellTracked, *args,\n\u001b[1;32m    474\u001b[0m                  **kwargs):\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCellClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCellClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         self.track = track or ['hidden_diff',\n\u001b[1;32m    477\u001b[0m                                \u001b[0;34m'error_diff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/predictive-event-segmentation/prevseg/models/prednet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparams, ds, a_channels, r_channels, CellClass)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Put together the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/predictive-event-segmentation/prevseg/models/prednet.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m             self.layer_loss_mode) if self.layer_loss_mode else None\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# How much to weight errors at each timezstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_loss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_time_loss_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_layer_loss_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/predictive-event-segmentation/prevseg/models/prednet.py\u001b[0m in \u001b[0;36mbuild_time_loss_weights\u001b[0;34m(self, time_steps)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_steps\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# How much to weight errors at each timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         time_loss_weights = 1. / (time_steps-1) * torch.ones(time_steps, 1,\n\u001b[0m\u001b[1;32m    211\u001b[0m                                                              device=self.dev)\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# Dont count first time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/conda/abdullah/envs/sch/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m             raise RuntimeError(\n\u001b[1;32m    185\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m/media/data/conda/abdullah/envs/sch/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             raise AssertionError(\"\"\"\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtoo\u001b[0m \u001b[0mold\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfound\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0myour\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mby\u001b[0m \u001b[0mdownloading\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalling\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nThe NVIDIA driver on your system is too old (found version 10010).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: https://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver."
     ]
    }
   ],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "res = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ModelClass = LSTMStacked\n",
    "hparams = const.DEFAULT_HPARAMS\n",
    "hparams.n_layers = 2\n",
    "hparams.batch_size = 256 + 128\n",
    "hparams.max_steps = 128\n",
    "hparams.n_paths = 16\n",
    "hparams.n_pentagons = 3\n",
    "hparams.time_steps = hparams.max_steps\n",
    "hparams.exp_name = 'schapiro_test'\n",
    "hparams.name = f'{ModelClass.name}_{hparams.exp_name}'\n",
    "hparams.debug = False\n",
    "hparams.n_workers = 2\n",
    "hparams.layer_loss_mode = None\n",
    "hparams.lr = 0.001\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / (hparams.exp_name+'_{global_step:05d}_{epoch:03d}_{val_loss:.3f}')),\n",
    "    verbose=True,\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(checkpoint_callback=ckpt,\n",
    "                     max_epochs=20,\n",
    "                     logger=logger,\n",
    "                     gpus=0\n",
    "                     )\n",
    "\n",
    "model = ModelClass(hparams)\n",
    "model.ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ds = ShapiroResnetEmbeddingDataset(\n",
    "    batch_size=1, \n",
    "    max_steps=hparams.max_steps, \n",
    "    n_paths=1,\n",
    "    mapping=model.ds.mapping,\n",
    "    mode='euclidean')\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "\n",
    "for data, nodes in loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = torch.cat((data, torch.flip(data, (0,1))[:,1:,:]), 1)\n",
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model.forward(data_all, output_mode='eval', run_num='fwd_rev', \n",
    "                     tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.array(nodes).reshape(30)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_all = np.concatenate((nodes, np.flip(nodes)[1:]))\n",
    "nodes_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(nodes_all):\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = [9, 19, 29, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph.schapiro_graph(n_pentagons=3)\n",
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_pe = model.forward(data_all, output_mode='error', run_num='fwd_rev', \n",
    "                        tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_array = outs_pe[0,:,:].cpu().detach().numpy()\n",
    "outs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs_array):\n",
    "    ax = fig.add_subplot(11 + i + len(outs_array)*100)\n",
    "    ax.plot(out)\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs_array)-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Error Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs['error_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(outs['error_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(59))\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs['error_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden State Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs['hidden_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(outs['hidden_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(59)[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs['hidden_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Within vs Between Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nodes = [6,8,9,\n",
    "              10,9,10,\n",
    "              13,12,14,\n",
    "              0,14,0,\n",
    "              1,2,4,\n",
    "              5,4,5]\n",
    "test_data = np.array([iter_ds.array_data[n] \n",
    "                      for n in test_nodes]).reshape((1,len(test_nodes),2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_outs = model.forward(torch.Tensor(test_data), \n",
    "                            output_mode='eval', \n",
    "                            run_num='border_walk_3', \n",
    "                            tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(border_outs['hidden_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(border_outs['hidden_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(len(test_nodes))[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    if i == len(border_outs['hidden_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
