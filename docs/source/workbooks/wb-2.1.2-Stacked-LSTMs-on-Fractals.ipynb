{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2 Stacked LSTMs on Fractals\n",
    "\n",
    "PredNet representations match the ones of human fMRI. How about LSTMS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [watermark](https://github.com/rasbt/watermark) to see the state of the machine and environment that's running the notebook. To make sense of the options, take a look at the [usage](https://github.com/rasbt/watermark#usage) section of the readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 06 2020 17:31:06 \n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-112-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 16\n",
      "interpreter: 64bit\n",
      "host name  : serrep5\n",
      "Git hash   : 559e267c9765a31f726bd422b7937cc37ebde795\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "# Load `watermark` extension\n",
    "%load_ext watermark\n",
    "# Display the status of the machine and other non-code related info\n",
    "%watermark -n -m -g -b -t -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) which will always reload modules marked with `%aimport`.\n",
    "\n",
    "This behavior can be inverted by running `autoreload 2` which will set everything to be auto-reloaded *except* for modules marked with `%aimport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `autoreload` extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload behavior\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `matplotlib` in one of the more `jupyter`-friendly [rich-output modes](https://ipython.readthedocs.io/en/stable/interactive/plotting.html). Some options (that may or may not have worked) are `inline`, `notebook`, and `gtk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging           0.5.1.2\n",
      "numpy             1.19.1\n",
      "pytorch_lightning 0.8.5\n",
      "torch             1.6.0\n",
      "PIL.Image         7.2.0\n",
      "prevseg           0+untagged.75.g559e267.dirty\n",
      "networkx          2.4\n",
      "CPython 3.8.5\n",
      "IPython 7.16.1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "%aimport prevseg.constants\n",
    "import prevseg.constants as const\n",
    "%aimport prevseg.index\n",
    "import prevseg.index as index\n",
    "%aimport prevseg.dataloaders.schapiro\n",
    "import prevseg.dataloaders.schapiro as sch\n",
    "%aimport prevseg.schapiro\n",
    "from prevseg.schapiro import walk, graph\n",
    "%aimport prevseg.models.prednet\n",
    "import prevseg.models.prednet as prednet\n",
    "\n",
    "# Keep track of versions of everything\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Embedding Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping as follows:\n",
      "{0: '64', 1: '89', 2: '86', 3: '51', 4: '56', 5: '83', 6: '12', 7: '38', 8: '8', 9: '92', 10: '65', 11: '70', 12: '90', 13: '44', 14: '74'}\n",
      "0 torch.Size([2, 2, 2048]) [[9, 0], [10, 3]]\n",
      "1 torch.Size([2, 2, 2048]) [[1, 1], [0, 2]]\n",
      "0 torch.Size([2, 2, 2048]) [[13, 10], [11, 9]]\n",
      "1 torch.Size([2, 2, 2048]) [[7, 12], [8, 11]]\n"
     ]
    }
   ],
   "source": [
    "max_steps = 2\n",
    "epochs = 2\n",
    "batch_size = 2\n",
    "n_paths = 2\n",
    "\n",
    "iter_ds = sch.ShapiroResnetEmbeddingDataset(\n",
    "    batch_size=batch_size, \n",
    "    max_steps=max_steps, \n",
    "    n_paths=n_paths,\n",
    ")\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for i, batch in enumerate(loader):\n",
    "        print(i, batch[0].shape, batch[1])\n",
    "        if i == n_paths:\n",
    "            print('bad')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMStacked(pn.PredNetTrackedSchapiro):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Saved Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trainer = None, None\n",
    "train_dataloader, val_dataloader = None, None\n",
    "errors, optimizer = None, None\n",
    "ckpt = None\n",
    "train_errors, val_errors = None, None\n",
    "res = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ModelClass = LSTMStacked\n",
    "hparams = const.DEFAULT_HPARAMS\n",
    "hparams.n_layers = 2\n",
    "hparams.batch_size = 256 + 128\n",
    "hparams.max_steps = 128\n",
    "hparams.n_paths = 16\n",
    "hparams.n_pentagons = 3\n",
    "hparams.time_steps = hparams.max_steps\n",
    "hparams.exp_name = 'schapiro_test'\n",
    "hparams.name = f'{ModelClass.name}_{hparams.exp_name}'\n",
    "hparams.debug = False\n",
    "hparams.n_workers = 2\n",
    "hparams.lr = 0.001\n",
    "\n",
    "log_dir = Path(hparams.dir_logs) / f'{hparams.name}'\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)\n",
    "logger = pl.loggers.TensorBoardLogger(str(log_dir.parent), name=hparams.name)\n",
    "\n",
    "ckpt_dir = Path(hparams.dir_checkpoints) / f'{hparams.name}_v{logger.version}'\n",
    "if not ckpt_dir.exists():\n",
    "    ckpt_dir.mkdir(parents=True)\n",
    "    \n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=str(ckpt_dir / (hparams.exp_name+'_{global_step:05d}_{epoch:03d}_{val_loss:.3f}')),\n",
    "    verbose=True,\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(checkpoint_callback=ckpt,\n",
    "                     max_epochs=20,\n",
    "                     logger=logger,\n",
    "                     gpus=1\n",
    "                     )\n",
    "\n",
    "model = ModelClass(hparams)\n",
    "model.ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ds = ShapiroResnetEmbeddingDataset(\n",
    "    batch_size=1, \n",
    "    max_steps=hparams.max_steps, \n",
    "    n_paths=1,\n",
    "    mapping=model.ds.mapping,\n",
    "    mode='euclidean')\n",
    "loader = DataLoader(iter_ds, batch_size=None)\n",
    "\n",
    "for data, nodes in loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = torch.cat((data, torch.flip(data, (0,1))[:,1:,:]), 1)\n",
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model.forward(data_all, output_mode='eval', run_num='fwd_rev', \n",
    "                     tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.array(nodes).reshape(30)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_all = np.concatenate((nodes, np.flip(nodes)[1:]))\n",
    "nodes_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(nodes_all):\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = [9, 19, 29, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph.schapiro_graph(n_pentagons=3)\n",
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_pe = model.forward(data_all, output_mode='error', run_num='fwd_rev', \n",
    "                        tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_array = outs_pe[0,:,:].cpu().detach().numpy()\n",
    "outs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs_array):\n",
    "    ax = fig.add_subplot(11 + i + len(outs_array)*100)\n",
    "    ax.plot(out)\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs_array)-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Error Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs['error_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(outs['error_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(59))\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs['error_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden State Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(outs['hidden_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(outs['hidden_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(59)[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    [ax.axes.axvline(b, ls=':') for b in borders]\n",
    "    if i == len(outs['hidden_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Within vs Between Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nodes = [6,8,9,\n",
    "              10,9,10,\n",
    "              13,12,14,\n",
    "              0,14,0,\n",
    "              1,2,4,\n",
    "              5,4,5]\n",
    "test_data = np.array([iter_ds.array_data[n] \n",
    "                      for n in test_nodes]).reshape((1,len(test_nodes),2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_outs = model.forward(torch.Tensor(test_data), \n",
    "                            output_mode='eval', \n",
    "                            run_num='border_walk_3', \n",
    "                            tb_labels=['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_large = fig.add_subplot(111)\n",
    "\n",
    "for i, out in enumerate(border_outs['hidden_diff']):\n",
    "    ax = fig.add_subplot(11 + i + len(border_outs['hidden_diff'])*100)\n",
    "    ax.plot(np.array(out.cpu()).reshape(len(test_nodes))[1:])\n",
    "    ax.set_ylabel(f'Layer {i+1}')\n",
    "    if i == len(border_outs['hidden_diff'])-1:\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "ax_large.axes.xaxis.set_ticks([])\n",
    "ax_large.axes.yaxis.set_ticks([])\n",
    "gcf = plt.gcf()\n",
    "gcf.set_size_inches(16,9)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
